<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>操作系统7：磁盘存储器管理</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-7-ci-pan-cun-chu-qi-guan-li/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-7-ci-pan-cun-chu-qi-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="第八章-磁盘存储器管理"><a href="#第八章-磁盘存储器管理" class="headerlink" title="第八章 磁盘存储器管理"></a>第八章 磁盘存储器管理</h1><h3 id="8-1-磁盘结构和调度"><a href="#8-1-磁盘结构和调度" class="headerlink" title="8.1 磁盘结构和调度"></a>8.1 磁盘结构和调度</h3><h5 id="1-磁盘的结构"><a href="#1-磁盘的结构" class="headerlink" title="1. 磁盘的结构"></a>1. 磁盘的结构</h5><p>磁盘设备可包括一个或多个物理盘片，每个磁盘片分一个或两个<strong>存储面(Surface)</strong>。每个盘面对应一个磁头，所有的磁头都是连在同一个磁臂上的，因此所有磁头只能“共进退”，所有盘面中相对位置相同的磁道组成<strong>柱面</strong>。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第八章 磁盘存储器管理/1774310-20210820144739234-691416356.png" alt="img" style="zoom: 50%;"><br>每个盘面上有若干个<strong>磁道(Track)</strong>，磁道之间留有必要的间隙(Gap)。在每条磁道上可存储相同数目的二进制位，磁盘密度即每英寸中所存储的位数，显然是内层磁道的密度较外层磁道的密度高。每条磁道又被从逻辑上划分成若干个<strong>扇区(Sectors)</strong>，软盘大约为 8 至 32 个扇区，硬盘则可多达数百个。一个扇区称为一个盘块(或数据块)，各扇区之间保留一定的间隙(Gap)。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210820144654834-2046213350.png" alt="img" style="zoom: 50%;"><br>在磁盘中读/写数据时，需要把“磁头”移动到想要读/写的扇区所在的磁道，磁盘会转起来让目标扇区从磁头下面划过，才能完成对扇区的读/写操作。可用(柱面号，盘面号，扇区号)来定位任意一个“磁盘块”，读取的过程是：</p><ol><li>根据“柱面号”移动磁臂，让磁头指向指定柱面；</li><li>激活指定盘面对应的磁头；</li><li>磁盘旋转的过程中，指定的扇区会从磁头下面划过。</li></ol><h5 id="2-磁盘类型"><a href="#2-磁盘类型" class="headerlink" title="2. 磁盘类型"></a>2. 磁盘类型</h5><p>对于磁盘可以从不同的角度进行分类，最常见的有：将磁盘分成硬盘和软盘、单片盘和多片盘、固定头磁盘和活动头（移动头）磁盘等。</p><div class="table-container"><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>固定头磁盘</td><td>这种磁盘在每条磁道上都有一读/写磁头，所有的磁头都被装在一刚性磁臂中</td></tr><tr><td>移动头磁盘</td><td>每一个盘面仅配有一个磁头，也被装入磁臂中，该磁头必须能移动以进行寻道</td></tr></tbody></table></div><h5 id="3-磁盘的管理"><a href="#3-磁盘的管理" class="headerlink" title="3. 磁盘的管理"></a>3. 磁盘的管理</h5><p>1）磁盘初始化</p><p>为了在磁盘上存储数据，必须先将磁盘初始化，初始化的过程如下：</p><ol><li><strong>进行低级格式化(物理格式化)</strong>：将磁盘的各个磁道划分为扇区，一个扇区通常可分为头、数据区域(如 512B 大小)、尾三个部分组成。管理扇区所需要的各种数据结构一般存放在头、尾两个部分，包括扇区校验码；</li><li><strong>磁盘分区</strong>：每个分区由若干柱面组成，在逻辑上每个分区是一个独立的逻辑磁盘；</li><li><strong>逻辑格式化</strong>：创建文件系统，包括创建文件系统的根目录、初始化存储空间管理所用的数据结构(如位示图、空闲分区表）。</li></ol><p><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210820150136708-817307061.png" alt="img" style="zoom:67%;"><br>计算机开机时需要进行一系列初始化的工作，这些初始化工作是通过执行初始化程序完成的，初始化程序可以放在 ROM(只读存储器)中，开机时计算机先运行“自举装入程序”，通过执行该程序就可找到引导块，并将完整的“自举程序”读入内存完成初始化。</p><p>2）坏块的管理</p><p>坏了、无法正常使用的扇区就是<strong>坏块</strong>，属于硬件故障，操作系统是无法修复的。所以应该将坏块标记出来，以免错误地使用到它。对于简单的磁盘，可以在逻辑格式化时(建立文件系统时）对整个磁盘进行坏块检查，标明哪些扇区是坏扇区，比如在 FAT 表上标明。对于复杂的磁盘，磁盘控制器(磁盘设备内部的一个硬件部件）会维护一个坏块链表，在磁盘出厂前进行低级格式化时就将坏块链进行初始化。保留一些“备用扇区”，用于替换坏块，这种方案称为扇区备用，这种方式坏块对操作系统透明。</p><h5 id="4-磁盘访问时间"><a href="#4-磁盘访问时间" class="headerlink" title="4. 磁盘访问时间"></a>4. 磁盘访问时间</h5><p>磁盘设备在工作时以恒定速率旋转，为了读或写，磁头必须能移动到所指定的磁道上，并等待所指定的扇区的开始位置旋转到磁头下，然后再开始读或写数据。故可把对磁盘的访问时间分成以下三部分：<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220120150631451-567442561.png" alt="img" style="zoom:80%;"></p><p>1）寻道时间</p><p><strong>寻道时间 Ts</strong> 指把磁臂(磁头)移动到指定磁道上所经历的时间，该时间是启动磁臂的时间 s 与磁头移动 n 条磁道所花费的时间之和。其中 m 是一常数，与磁盘驱动器的速度有关，对一般磁盘 m = 0.2，对高速磁盘 m ≤ 0.1，磁臂的启动时间约为 2ms。对一般的磁盘，其寻道时间将随寻道距离的增大而增加。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220120145459442-1713600257.png" alt="img" style="zoom:67%;"><br>寻道有许多阶段，首先是磁盘臂移动时的加速阶段，然后随着磁盘臂全速移动而惯性滑动，然后随着磁盘臂减速而减速，最后在磁头小心地放置在正确的磁道上时停下来。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第八章 磁盘存储器管理/1774310-20220120150006972-378138323.png" alt="img" style="zoom: 50%;"></p><p>2）旋转延迟时间</p><p><strong>旋转延迟时间 Tr</strong> 是指定扇区移动到磁头下面所经历的时间，不同的磁盘类型中，旋转速度至少相差一个数量级，如软盘为 300 r/min，硬盘一般为 7200 r/min 到 15000 r/min 甚至更高。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220120145856925-1065129045.png" alt="img" style="zoom:67%;"><br>对于磁盘旋转延迟时间而言，如硬盘旋转速度为 15000 r/min，每转需时 4ms，平均旋转延迟时间 Tr = 2ms。而对于软盘，其旋转速度为 300 r/min 或 600 r/min，这样平均 Tr = 50 ~ 100 ms。</p><p>3）传输时间</p><p><strong>传输时间 Tt</strong>指把数据从磁盘读出或向磁盘写入数据所经历的时间，Tt 的大小与每次所读/写的字节数 b 和旋转速度有关。下面公式中，r 为磁盘每秒钟的转数，N 为一条磁道上的字节数。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210820151455795-213144419.png" alt="img" style="zoom: 50%;"><br>当一次读/写的字节数相当于半条磁道上的字节数时，Tt 与 Tr 相同，因此可将访问时间 Ta 表示为如下公式。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第八章 磁盘存储器管理/1774310-20210820151552917-2029325308.png" alt="img" style="zoom: 50%;"><br>由上式可以看出，在访问时间中，寻道时间和旋转延迟时间基本上都与所读/写数据的多少无关，而且它通常占据了访问时间中的大部分。例如假定寻道时间和旋转延迟时间平均为 20 ms，而磁盘的传输速率为 10 MB/s，如果要传输 10 KB，此时总的访问时间为 21 ms。当传输 100 KB 数据时，其访问时间也只是 30ms。可见适当地集中数据(不要太零散)传输，将有利于提高传输效率。</p><p>4）磁盘的时延</p><p>磁头读取一个扇区的内容后，需要一小段时间处理，而盘片又在不停地旋转。因此如果要读取的扇区相邻着排列，则读完一个扇区后无法连续不断地读入相邻的扇区，必须等盘片继续旋转使相邻扇区再次划过磁头，才能完扇区读入。可见：如果逻辑上相邻的扇区在物理上也相邻，则读入几个连续的逻辑扇区，可能需要很长的“延迟时间”。</p><h5 id="5-磁盘调度"><a href="#5-磁盘调度" class="headerlink" title="5. 磁盘调度"></a>5. 磁盘调度</h5><p>为了减少对文件的访问时间，应采用一种最佳的磁盘调度算法，以使各进程对磁盘的平均访问时间最小。由于在访问磁盘的时间中主要是寻道时间，因此磁盘调度的目标是使磁盘的平均寻道时间最少。</p><p>调度样例：某磁盘组共有 200 个柱面，由外至内依次编号为 0，1，…，199。输入输出请求以 10、100、191、31、20、150、32 的次序到达，假定引臂当前位于柱面 98 处，移动方向为由外向内。对先到先服务、最短查找时间优先扫描、扫描算法、循环扫描算法分别给出寻道示意图，并计算总移动量。对扫描算法，假定引臂当前移动方向为由外向内，对循环扫描算法假定回扫方向由内向外。</p><p>1）<strong>先来先服务</strong></p><p><strong>先来先服务(FCFS)</strong>是最简单的磁盘调度算法，它根据进程请求访问磁盘的先后次序进行调度。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20211225222959505-510141644.png" alt="img" style="zoom:67%;"></p><blockquote><p>总移动量<br>=（98-10）+（100-10）+（191-100）+（191-31）+（31-20）+（150-20）+ (150-32)<br>= 88 + 90 + 91 + 160 + 9 + 130 + 118<br>= 686。</p></blockquote><p>此算法的优点是公平、简单，且每个进程的请求都能依次地得到处理。但此算法由于未对寻道进行优化，致使平均寻道时间可能较长，故 FCFS 算法仅适用于请求磁盘 I/O 的进程数目较少的场合。</p><p>2）<strong>最短寻道时间优先</strong></p><p><strong>最短寻道时间优先(SSTF)</strong>算法是基于贪心算法来设计的，要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短，但这种算法不能保证平均寻道时间最短。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20211225223102894-1799130145.png" alt="img" style="zoom:67%;"></p><blockquote><p>总移动量<br>=（100-98）+（150-100）+（191-150）+（191-32）+（32-31）+（31-20）+ (20-10)<br>= 2 + 50 + 41 + 159 + 1 + 9 + 10<br>= 272</p></blockquote><p>SSTF 算法平均每次磁头移动的距离明显低于 FCFS 算法的距离，较之 FCFS 有更好的寻道性能。</p><p>3）<strong>扫描算法</strong></p><p>SSTF 算法会产生饥饿的原因在于，磁头有可能在一个小区域内来回来去地移动。<strong>扫描算法(SCAN)</strong>可以防止这个问题，可以规定只有磁头移动到最外侧磁道的时候才能往内移动，移动到最内侧磁道的时候才能往外移动。由于磁头移动的方式很像电梯，因此也叫电梯算法。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20211225223209562-1560048048.png" alt="img" style="zoom:67%;"></p><blockquote><p>总移动量<br>=（100-98）+（150-100）+（191-150）+（199-191）+（199-32）+（32-31）+ (31-20) + (20-10)<br>=2 + 50 + 41 + 8 + 167 + 1 + 9 + 10<br>=288</p></blockquote><p>扫描算法的优点是性能较好，平均寻道时间较短，不会产生饥饿现象。缺点是只有到达最边上的磁道时才能改变磁头移动方向，事实上有时并不需要到达最边上的磁道。同时当磁头刚从里向外移动而越过了某一磁道时，恰好又有一进程请求访问此磁道，这时该进程必须等待磁头继续从里向外，然后再从外向里扫描完处于外面的所有要访问的磁道后，才处理该进程的请求，致使该进程的请求被大大地推迟。</p><p>4）<strong>循环扫描算法</strong></p><p>SCAN 算法对于各个位置磁道的响应频率不平均，<strong>循环扫描(C-SCAN)算法</strong>可以解决这个问题。它规定只有磁头朝某个特定方向移动时才处理磁道访问请求，而返回时直接快速移动至起始端而不处理任何请求。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20211225223306567-1693325013.png" alt="img" style="zoom:67%;"></p><blockquote><p>总移动量<br>=（100-98）+（150-100）+（191-150）+（199-191）+（10-0）+（20-10）+ (31-20) + (32-31)<br>= 2 + 50 + 41 + 8 + 10 + 10 + 9 + 1<br>= 131</p></blockquote><p>C-SCAN 算法的优点是比起 SCAN，对于各个位置磁道的响应频率很平均。缺点是只有到达最边上的磁道时才能改变磁头移动方向，比起 SCAN 算法来平均寻道时间更长。</p><p>5）<strong>NStepSCAN算法</strong></p><p>在 SSTF、SCAN 及 CSCAN 几种调度算法中，都可能出现磁臂停留在某处不动的情况。例如有一个或几个进程反复请求对某一磁道的 I/O 操作，从而垄断了整个磁盘设备，这一现象称为<strong>磁臂粘着”(Armstickiness)</strong>。</p><p><strong>NStepSCAN 算法</strong>是将磁盘请求队列分成若干个长度为 N 的子队列，磁盘调度将按 FCFS 算法依次处理这些子队列。而每处理一个队列时又是按 SCAN 算法，对一个队列处理完后再处理其他队列。当正在处理某子队列时，如果又出现新的磁盘 I/O 请求，便将新请求进程放入其他队列，这样就可避免出现粘着现象。当 N 值取得很大时，会使 N 步扫描法的性能接近于 SCAN 算法的性能，当 N = 1时 N 步 SCAN算法便蜕化为 FCFS 算法。</p><p>6）<strong>FSCAN算法</strong></p><p><strong>FSCAN 算法</strong>是 N 步 SCAN 算法的简化，即 FSCAN 只将磁盘请求队列分成两个子队列，一个是由当前所有请求磁盘 I/O 的进程形成的队列，由磁盘调度按 SCAN 算法进行处理。另一个是在扫描期间，将新出现的所有请求磁盘 I/O 的进程放入等待处理的请求队列，这样所有的新请求都将被推迟到下一次扫描时处理。</p><h5 id="6-提高磁盘-I-O-速度"><a href="#6-提高磁盘-I-O-速度" class="headerlink" title="6. 提高磁盘 I/O 速度"></a>6. 提高磁盘 I/O 速度</h5><p>文件系统的性能可表现在多个方面，其中至关重要的一个方面是对文件的访问速度。提高对文件的访问速度可从三方面着手：</p><ol><li>改进文件的目录结构以及检索目录的方法来减少对目录的查找时间；</li><li>选取好的文件存储结构，以提高对文件的访问速度；</li><li>提高磁盘的 I/O 速度，能将文件中的数据快速地从磁盘传送到内存中，或者相反。</li></ol><p>目前磁盘的 I/O 速度远低于对内存的访问速度，通常要低上 4~6 个数量级，因此磁盘的 I/O 已成为计算机系统的瓶颈。</p><p>1）<strong>磁盘高速缓存</strong></p><p>提高磁盘 I/O 的速度其中最主要的技术便是采用<strong>磁盘高速缓存(Disk Cache)</strong>，是指在内存中为磁盘盘块设置的一个缓冲区，在缓冲区中保存了某些盘块的副本。当出现一个访问磁盘的请求时，由核心先去查看磁盘高速缓冲器，如果请求的盘块内容已在磁盘高速缓存中，便可从磁盘高速缓存中去获取。如果不在，才需要启动磁盘将所需要的盘块内容读入，并把所需盘块内容送给磁盘高速缓存。<br>在设计磁盘高速缓存时需要考虑的问题有：</p><ol><li>如何将磁盘高速缓存中的数据传送给请求进程；</li><li>采用什么样的置换策略；</li><li>已修改的盘块数据在何时被写回磁盘。</li></ol><p>（1）数据交付方式</p><p>数据交付就是指将磁盘高速缓存中的数据传送给请求者进程，系统可以采取两种方式将数据交付给请求进程。</p><div class="table-container"><table><thead><tr><th>交付方式</th><th>说明</th></tr></thead><tbody><tr><td>数据交付</td><td>直接将高速缓存中的数据传送到请求者进程的内存工作区中</td></tr><tr><td>指针交付</td><td>只将指向高速缓存中某区域的指针交付给请求者进程</td></tr></tbody></table></div><p>指针交付方式由于所传送的数据量少，因而节省了数据从磁盘高速缓存存储空间到进程的内存工作区的时间。</p><p>（2）置换算法</p><p>如同请求调页(段）一样，在将磁盘中的盘块数据读入高速缓存时，同样会出现因高速缓存中已装满盘块数据，而需要将其中某些盘块的数据先换出的问题。较常用的算法仍然是最近最久未使用算法 LRU、最近未使用算法 NRU 、最少使用算法 LFU 等。设计其高速缓存的置换算法时，除了考虑到最近最久未使用这一原则外，还考虑了以下几点：</p><div class="table-container"><table><thead><tr><th>考虑因素</th><th>说明</th></tr></thead><tbody><tr><td>访问频率</td><td>对联想存储器的访问频率远远高于对磁盘高速缓存的访问频率</td></tr><tr><td>可预见性</td><td>数据可能在较长时间内不会再被访问或很快就再被访问，会有相当一部分是可预知的</td></tr><tr><td>数据的一致性</td><td>当系统发生故障后，可能由于数据没有及时写回磁盘，造成数据的不一致性</td></tr></tbody></table></div><p>（3）周期性写回</p><p>在有的系统中便将磁盘高速缓存中的所有盘块数据拉成一条 <strong>LRU 链</strong>，对于那些会严重影响到数据一致性的盘块数据放在 LRU 链的头部，使它们能被优先写回磁盘。对于那些可能在不久之后便要再次使用的盘块数据，应挂在 LRU 链的尾部，以便在以后需要时便可直接从 LRU 链中找到它们。</p><p>根据 LRU 算法，那些经常要被访问的盘块数据可能会一直保留在高速缓存中，长期不会被写回磁盘。因为链中任一元素在被访问之后，又被挂到链尾而不被写回磁盘，只有一直未被访问的元素才有可能移到链首，而被写回磁盘。为了解决这一问题，在 UNIX 系统中专门增设了一个修改(update)程序。该程序周期性地调用一个系统调用 SYNC，其主要功能是强制性地将所有在高速缓存中已修改的盘块数据写回磁盘。</p><p>故障所造成的工作损失不会超过30s的工作量。</p><p>2）<strong>提高磁盘 I/O 速度的其它方法</strong></p><ul><li><p>提前读：如果是采用顺序访问方式对文件进行访问，便可以预知下一次要读的盘块。此时可采取<strong>预先读</strong>方式，即在读当前块的同时，还要求将下一个盘块(提前读的块)中的数据也读入<br>缓冲区。</p></li><li><p>延迟写：延迟写是指缓冲区 A 中的数据本应立即写回磁盘，但该缓冲区中的数据可能会在不久之后再被本进程或其它进程访问，因而并不立即将该缓冲区 A 中的数据写入磁盘，而是将它挂在空闲缓冲区队列的末尾。随着空闲缓冲区的使用，缓冲区也缓缓往前移动，直至移到空闲缓冲队列之首。</p></li><li><p>优化物理块的分布：在采用链接组织和索引组织方式时，可以将一个文件分散在磁盘的任意位置，但如果安排得过于分散，会增加磁头的移动距离。对文件盘块位置的优化，应在为文件分配盘块时进行。系统中的空白存储空间是采用位示图方式表示时，只要从位示图中找到一片相邻接的多个空闲盘块即可。当系统采用线性表(链）法来组织空闲存储空间时，要可以将在同一条磁道上的若干个盘块组成一簇，在分配存储空间时，以簇为单位进行分配。</p></li><li><p>虚拟盘：由于访问内存的速度远高于访问磁盘的速度，于是有人试图利用内存空间去仿真磁盘形成所谓虚拟盘。该盘的设备驱动程序也可以接受所有标准的磁盘操作，但这些操作的执行不是在磁盘上而是在内存中。这对用户都是透明的。虚拟盘的主要问题是它是易失性存储器，故一旦系统或电源发生故障或系统再启动时，原来保存在虚拟盘中的数据将会丢失，因此虚拟盘通常用于存放临时文件。</p></li></ul><p>3）<strong>廉价磁盘冗余阵列(RAID)</strong></p><p>如果使用一个组件对性能的改进受到了很大的限制，那么可通过使用多个相同的组件来获得性能的大幅度提高。可以由多个小磁盘组成一个大容量的<strong>廉价磁盘冗余阵列(Redundant Array of Inexpensive Disk，RAID)</strong>，系统利用一台磁盘阵列控制器来统一管理和控制一组(几台到几十台）磁盘驱动器，组成一个大型磁盘系统。RAID 不仅是大幅度地增加了磁盘的容量，而且也极大地提高了磁盘的 I/O 速度和整个磁盘系统的可靠性。</p><h3 id="8-2-磁盘组织和空间管理"><a href="#8-2-磁盘组织和空间管理" class="headerlink" title="8.2 磁盘组织和空间管理"></a>8.2 磁盘组织和空间管理</h3><h5 id="1-磁盘存储器管理"><a href="#1-磁盘存储器管理" class="headerlink" title="1. 磁盘存储器管理"></a>1. 磁盘存储器管理</h5><p>1）磁盘块</p><p>类似于内存分页，在外存管理中为了方便对文件数据的管理，文件的逻辑地址空间也被分为了一个一个的文件“块”。磁盘中的存储单元也称为“<strong>块/磁盘块/物理块</strong>”，很多操作系统中磁盘块的大小与内存块、页面的大小相同。内存与磁盘之间的数据交换(即读/写操作、磁盘 I/O)都是以“块”为单位进行的，即每次读入一块，或每次写出一块，于是文件的逻辑地址也可以表示为(逻辑块号，块内地址）的形式。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第八章 磁盘存储器管理/1774310-20210813165602507-1040988200.png" alt="img" style="zoom:67%;"><br>操作系统为文件分配存储空间都是以块为单位的，用户通过逻辑地址来操作自己的文件，操作系统要负责实现从逻辑地址到物理地址的映射。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813170024485-284364327.png" alt="img" style="zoom:67%;"></p><h5 id="2-磁盘管理的任务"><a href="#2-磁盘管理的任务" class="headerlink" title="2. 磁盘管理的任务"></a>2. 磁盘管理的任务</h5><p>磁盘存储器不仅容量大，存取速度快，而且可以实现随机存取，是当前实现虚拟存储器和存放文件最理想的外存。对磁盘存储器管理的主要任务和要求是：</p><ol><li>有效地利用存储空间：采取合理的文件分配方式，为文件分配必要的存储空间，并能有效地减少磁盘碎片，改善存储空间的利用率；</li><li>提高磁盘的 I/O 速度：通过各种途经来提高磁盘的I/O速度，以增加对文件的访问速度，从而改善文件系统的性能；</li><li>提高磁盘系统的可靠性：采取多种技术来提高磁盘系统的可靠性。</li></ol><h5 id="3-外存的组织方式"><a href="#3-外存的组织方式" class="headerlink" title="3. 外存的组织方式"></a>3. 外存的组织方式</h5><p>文件的物理结构直接与外存的组织方式有关，不同的外存组织方式将形成不同的文件物理结构。目前常用的外存组织方式有：</p><div class="table-container"><table><thead><tr><th>组织方式</th><th>说明</th></tr></thead><tbody><tr><td>连续组织方式</td><td>为每个文件分配一片连续的磁盘空间，形成顺序式的文件结构</td></tr><tr><td>链接组织方式</td><td>为每个文件分配不连续的磁盘空间，通过链接指针将一个文件的所有盘块链接在一起，形成链接式文件结构</td></tr><tr><td>索引组织方式</td><td>形成的将是索引式文件结构</td></tr></tbody></table></div><p>1）<strong>连续组织方式</strong></p><p><strong>连续组织方式</strong>又称连续分配方式，要求为每一个文件分配一组相邻接的盘块。例如第一个盘块的地址为 b，则第 i 个盘块的地址为 b + i。通常它们都位于一条磁道上，在进行读/写时不必移动磁头。采用这种方式可把逻辑文件中的记录顺序地存储到邻接的各物理盘块中，这样所形成的文件结构称为顺序文件结构，此时的物理文件称为顺序文件。为使系统能找到文件存放的地址，应在目录项的“文件物理地址”字段中记录该文件第一个记录所在的盘块号和文件长度(以盘块为单位)。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813200742133-1915669877.png" alt="img" style="zoom:67%;"><br>连续组织方式的顺序访问容易，系统可从目录中找到该顺序文件所在的第一个盘块号，逐个盘块地往下读/写。同时顺序访问速度快，由连续分配所装入的文件所占用的盘块可能是位于相同或相邻的磁道上，磁头的移动距离最少。</p><p>但是连续组织方式要求为一个文件分配连续的存储空间，会产生出许多外部碎片。如果是定期地利用紧凑方法来消除碎片，则又需花费大量的机器时间。分配时必须事先知道文件的长度，有时文件的大小只能靠估算，如果估计的文件大小比实际文件小，就会因存储空间不足而中止文件的拷贝，这就促使用户将文件长度估得比实际的大造成浪费。为保持文件的有序性，在删除和插入记录时，都需要对相邻的记录做物理上的移动，不灵活。对于那些动态增长的文件，由于事先很难知道文件的最终大小，因而很难为其分配空间。</p><p>2）<strong>链接组织方式</strong></p><p>如果可以将文件装到多个离散的盘块中，就可消除连续组织方式的缺点。在采用<strong>链接组织方式</strong>时，可为文件分配多个不连续的盘块，再通过每个盘块上的链接指针，将同属于一个文件的多个离散的盘块链接成一个链表，由此所形成的物理文件称为链接文件。链接组织方式消除了磁盘的外部碎片，对插入、删除和修改记录都非常容易，同时能适应文件的动态增长。链接方式又可分为隐式链接和显式链接两种形式。</p><p>（1）隐式链接</p><p><strong>隐式链接组织</strong>是在文件目录的每个目录项中，都须含有指向链接文件第一个盘块和最后一个盘块的指针。隐式链接组织方式只适合于顺序访问，如果要访问文件所在的第 i 个盘块，则必须先读出文件的第 i-1 个盘块。此外只通过链接指针将一大批离散的盘块链接起来的可靠性较差，因为只要其中的任何一个指针出现问题，都会导致整个链的断开。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813202925613-479438683.png" alt="img" style="zoom:67%;"><br>为了提高检索速度和减小指针所占用的存储空间，可以将几个盘块组成一个簇(cluster)。比如一个簇可包含 4 个盘块，在进行盘块分配时，是以簇为单位进行的。这样将会成倍地减小查找指定块的时间，但却增大了内部碎片。</p><p>（2）显式链接</p><p><strong>显式链接</strong>把用于链接文件各物理块的指针显式地存放在一张表中，即<strong>文件分配表(FAT，File Allocation Table)</strong>。用户给出要访问的逻辑块号 i，OS 找到该文件对应的目录项(FCB)。找到起始块号，若 i &gt; O 则查询内存中的文件分配表 FAT，往后找到 i 号逻辑块对应的物理块号。一个磁盘仅设置一张 FAT，开机时将FAT读入内存并常驻内存。FAT 的各个表项在物理上连续存储，且每一个表项长度相同，因此“物理块号”字段可以是隐含的。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813203945172-163452803.png" alt="img" style="zoom: 67%;"><br>显式链接方式的文件支持随机访问，且逻辑块号转换成物理块号的过程不需要读磁盘操作。查找记录的过程是在内存中进行的，不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但是链接方式不能支持高效的直接存取，如果文件较大则要在 FAT 中顺序地查找许多盘块号。同时 FAT 需占用较大的内存空间，只有将整个 FAT 调入内存，才能保证在 FAT 中找到一个文件的所有盘块号。</p><p>3）<strong>索引组织方式</strong></p><p>（1）单级索引组织方式</p><p>在打开某个文件时，只需把该文件占用的盘块的编号调入内存即可。为此应将每个文件所对应的盘块号集中地放在一起，在访问到某个文件时，将该文件所对应的盘块号一起调入内存。<strong>索引分配</strong>允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张<strong>索引表</strong>，记录文件的各个逻辑块对应的物理块。索引表存放的磁盘块称为索引块，文件数据存放的磁盘块称为数据块。在建立一个文件时，只须在为之建立的目录项中填上指向该索引块的指针。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813205149199-1315936343.png" alt="img" style="zoom: 67%;"><br>索引组织方式支持直接访问，当要读文件的第 i 个盘块时可以方便地从索引块中找到盘块号。索引分配方式也不会产生外部碎片，支持在在文件较大时使用。它的主要问题是对于中、小型文件，其本身通常只占有数个到数十个盘块，但仍须为之分配索引块。</p><p>（2）多级索引组织方式</p><p>在为一个大文件分配磁盘空间时，如果一个索引块不够记录所有盘块号，OS 须再为该文件分配多个索引块，再通过链指针将各索引块按序链接起来。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813205654058-360308373.png" alt="img" style="zoom: 67%;">            <img src="../../../../Download/文档/操作系统笔记/source/images/第八章 磁盘存储器管理/1774310-20210813210310380-771574188.png" alt="img" style="zoom:67%;"><br>显然当文件太大会导致索引块太多，此时应为这些索引块再建立一级索引。使第一层索引块指向第二层的索引块，还可根据文件大小的要求再建立第三层、第四层索引块。</p><p>多级索引大大加快了对大型文件的查找速度，但在访问一个盘块时，其所需启动磁盘的次数随着索引级数的增加而增多。</p><p>（4）<strong>混合索引方式</strong></p><p>为了能较全面地照顾到小、中、大及特大型作业，可以采取多种组织方式来构成文件的物理结构。<strong>混合索引</strong>是多种索引分配方式的结合，例如一个文件的顶级索引表中，既包含直接地址索引(直接指向数据块），又包含一级间接索引（指向单层索引表）、还包含两级间接索引（指向两层索引表）。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813210909051-1684421146.png" alt="img" style="zoom: 67%;"><br>对于小文件来说，访问一个数据块所需的读磁盘次数更少。</p><h5 id="4-文件存储空间管理"><a href="#4-文件存储空间管理" class="headerlink" title="4. 文件存储空间管理"></a>4. 文件存储空间管理</h5><p>为了实现前面任何一种文件组织方式，都需要为文件分配盘块，因此必须知道磁盘上哪些盘块是可用于分配的。故在为文件分配磁盘时，除了需要文件分配表外，系统还应为可分配存储空间设置相应的数据结构——<strong>磁盘分配表(Disk Allocation Table)</strong>，此外还应提供对盘块进行分配和回收的手段。</p><p>1）存储空间的划分</p><p>安装操作系统的时候，一个必经步骤是为磁盘分区，存储空间的划分是将物理磁盘划分为一个个文件卷（逻辑卷、逻辑盘），例如 C、D、E 盘等。存储空间的初始化将各个文件卷划分为目录区、文件区，目录区主要存放文件目录信息（FCB）、用于磁盘存储空间管理的信息，文件区用于存放文件数据。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813213003646-568702394.png" alt="img" style="zoom:67%;"></p><p>2）<strong>空闲表法</strong></p><p><strong>空闲表</strong>法属于连续分配方式，为每个文件分配一块连续的存储空间。系统也为外存上的所有空闲区建立一张<strong>空闲表</strong>，每个空闲区对应于一个空闲表项，其中包括表项序号、该空闲区的第一个盘块号、该区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列，形成空闲盘块表。</p><p>分配磁盘块与内存管理中的动态分区分配很类似，同样可采用首次适应、最佳适应、最坏适应等算法来决定要为文件分配哪个区间。在系统为某新创建的文件分配空闲盘块时，先顺序地检索空闲表的各表项，直至找到第一个其大小能满足要求的空闲区，再将该盘区分配给用户(进程)，同时修改空闲表。系统在对用户所释放的存储空间进行回收时，也采取类似于内存回收的方法，即要考虑回收区是否与空闲表中插入点的前区和后区相邻接，对相邻接者应予以合并。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813213931549-286776673.png" alt="img" style="zoom:67%;"><br>在内存分配上虽然较少采用连续分配方式，然而在外存的管理中。由于这种分配方式具有较高的分配速度，可减少访问磁盘的 I/O 频率，故它在诸多分配方式中仍然会使用。</p><p>2）<strong>空闲链表法</strong></p><p>空闲链表法是将所有空闲盘区拉成一条空闲链，根据构成链所用基本元素的不同，可把链表分成空闲盘块链和空闲盘区链。</p><p>（1）空闲盘块链</p><p>将磁盘上的所有空闲空间以盘块为单位拉成一条链，其中的每一个盘块都有指向后继盘块的指针。当用户因创建文件而请求分配存储空间时，系统从链首开始，依次摘下适当数目的空闲盘块分配给用户。当用户因删除文件而释放存储空间时，系统将回收的盘块依次挂在空闲盘块链的末尾。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813220129054-1471907085.png" alt="img" style="zoom:67%;"><br>这种方法的用于分配和回收一个盘块的过程非常简单，但在为一个文件分配盘块时，可能要重复操作多次，分配和回收的效率较低。又因为它是以盘块为单位，相应的空闲盘块链会很长。</p><p>（2）空闲盘区链</p><p><strong>空闲盘区链</strong>将磁盘上的所有空闲盘区(每个盘区可包含若干个盘块)拉成一条链，在每个盘区上除含有用于指示下一个空闲盘区的指针外，还应有能指明本盘区大小(盘块数)的信息。分配盘区的方法与内存的动态分区分配类似，在回收盘区时同样也要将回收区与相邻接的空闲盘区相合并。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813220542004-1429321375.png" alt="img" style="zoom:67%;"><br>这种方法的优点和缺点刚好与前一种方法的优缺点相反，即分配与回收的过程比较复杂，但分配和会收的效率可能较高，每次为文件分配多个连续的块，且空闲盘区链较短。</p><p>3）<strong>位示图法</strong></p><p>位示图是利用二进制的一位来表示磁盘中一个盘块的使用情况，当其值为 0 时表示对应的盘块空闲，为 1 时表示已分配也可以反过来。磁盘上的所有盘块都有一个二进制位与之对应，这样由所有盘块所对应的位构成一个矩阵。通常可用 <code>m x n</code> 个位数来构成位示图，并使 <code>m x n</code>等于磁盘的总块数，描述为一个二维数组 <code>map[m,n]</code>。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813225821004-902611304.png" alt="img" style="zoom:67%;"><br>根据位示图进行盘块分配时，可分三步进行：</p><ol><li>顺序扫描位示图，从中找出一个或一组其值为 0 的二进制位(“0”表示空闲时)；</li><li>将所找到的一个或一组二进制位转换成与之相应的盘块号，假定位于位示图的第 i 行、第 j 列，则其相应的盘块号应按<code>b = n × (i-1) + j</code>计算，其中 n 代表每行的位数；</li><li>修改位示图，令<code>map[i,j] = 1</code>。</li></ol><p>盘块的回收分两步，首先将回收盘块的盘块号转换成位示图中的行号和列号，转换公式为如下。第二步修改位示图，令<code>map[i,j] = 0</code>。</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">i</span> = (b-<span class="number">1</span>) DIV n + <span class="number">1</span></span><br><span class="line"><span class="attr">j</span> = (b-<span class="number">1</span>) MOD n + <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><p>这种方法的主要优点是从位示图中很容易找到一个或一组相邻接的空闲盘块，例如需要找到 n 个相邻接的空闲盘块，这只需在位示图中找出 n 个其值连续为 0 的位即可。由于位示图很小，占用空间少，因而可将它保存在内存中，进而使在每次进行盘区分配时，无需首先把盘区分配表读入内存。</p><p>4）<strong>成组链接法</strong></p><p>空闲表法、空闲链表法不适用于大型文件系统，因为空闲表或空闲链表可能过大，UNIX 系统中采用了成组链接法对磁盘空闲块进行管理。这是将上述两种方法相结合而形成的一种空闲盘块管理方法，它兼备了上述两种方法的优点而克服了两种方法均有的表太长的缺点。</p><p>文件卷的目录区中专门用一个磁盘块作为“超级块”，当系统启动时需要将超级块读入内存，并且要保证内存与外存中的“超级块”数据一致。超级块的第一个元素是下一组空闲盘块数 n，接下来跟着的是 n 个空闲块号。其中第一个空闲块指向保存下一个超级块的信息，仍然是空闲盘块数 n 和 n 个空闲块号。直到最后一个超级块的信息没有后续的空闲块号，它的第一个空闲块号为特殊值例如 -1。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813233619522-1639308306.png" alt="img" style="zoom:67%;"></p><p>当需要 i 个空闲块时，检查第一个分组的块数是否足够，如果 1 &lt; n 是足够的，就分配第一个分组中的 i 个空闲块，并修改相应数据。例如上图的成组链接，若需要 5 个空闲块，可以分配 201 ~ 205 号空闲块，并修改超级块的空闲块数量为 95。</p><p><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813233954307-875025750.png" alt="img" style="zoom:67%;"></p><p>如果 i ≥ n 刚好或不足够，则需要分配第一个分组中的全部空闲块，由于第一个空闲块存放了再下一组的信息，因此号块的数据需要复制到超级块中。例如上图的成组链接，若需要 95 个空闲块，可以分配 206 ~ 300 号空闲块，由于 300 号块内存放了再下一组的信息，因此 300 号块的数据需要复制到超级块中。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813234405161-1793763128.png" alt="img" style="zoom:67%;"></p><p>如果需要回收空闲块，则需要把空闲块号加入超级块中，修改空闲盘块数，并且进行相应的链接。如果回收空闲块后达到了超级块空闲盘块数的上限，需要将超级块中的数据复制到新回收的块中，并修改超级块的内容，让新回收的块成为第一个分组。例如上图的成组链接，若回收 1 个空闲块 300 号，进行修改后的状态如下。</p><p><img src="source/images/操作系统7：磁盘存储器管理/1774310-20210813234733287-87176607.png" alt="img" style="zoom:67%;"></p><h3 id="8-3-磁盘可靠性和一致性"><a href="#8-3-磁盘可靠性和一致性" class="headerlink" title="8.3 磁盘可靠性和一致性"></a>8.3 磁盘可靠性和一致性</h3><p><strong>磁盘容错技术</strong>是通过增加冗余的磁盘驱动器、磁盘控制器等方法来提高磁盘系统可靠性的一种技术。当磁盘系统的某部分出现缺陷或故障时，磁盘仍能正常工作，且不致造成数据的丢失或错误。目前广泛采用磁盘容错技术来改善磁盘系统的可靠性，也称为系统容错技术 SFT，可把它分成三个级别。</p><h5 id="第一级容错技术-SFT-1"><a href="#第一级容错技术-SFT-1" class="headerlink" title="第一级容错技术 SFT-1"></a>第一级容错技术 SFT-1</h5><p><strong>第一级容错技术（SFT-I）</strong>是最基本的一种磁盘容错技术，主要用于防止因磁盘表面缺陷所造成的数据丢失。它包含双份目录、双份文件分配表及写后读校验等措施：</p><ol><li><strong>双份目录和双份文件分配表</strong>：为了防止文件目录和文件分配表 FAT 被破坏，可在不同的磁盘上或在磁盘的不同区域中分别建立双份目录表和 FAT，另一份为备份目录及备份 FAT；</li><li><strong>热修复重定向</strong>：系统将磁盘容量的很小一部分作为热修复重定向区，用于存放当发现磁盘有缺陷时的待写数据，并对写入该区的所有数据进行登记，以便于以后对数据进行访问。</li><li><strong>写后读校验方式</strong>：在每次向磁盘中写入一个数据块后，又立即将它读出，并送至另一缓冲区中与内存缓冲区中在写后仍保留的数据进行比较。若两者一致便认为此次写入成功，否则再重写，若重写后两者仍不一致则认为该盘块有缺陷；</li></ol><h5 id="2-第二级容错技术-SFT-2"><a href="#2-第二级容错技术-SFT-2" class="headerlink" title="2. 第二级容错技术 SFT-2"></a>2. 第二级容错技术 SFT-2</h5><p>第二级容错技术主要用于防止由磁盘驱动器和磁盘控制器故障所导致的系统不能正常工作，它具体又可分为磁盘镜像与磁盘双工。</p><p>1）磁盘镜像功能</p><p>为了避免磁盘驱动器发生故障而丢失数据，便增设了<strong>磁盘镜像(Disk Mirroring)</strong>，也就是同一磁盘控制器下再增设一个完全相同的磁盘驱动器。在每次向主磁盘写入数据后，都需要将数据再写到备份磁盘上，使两个磁盘上具有完全相同的位像图。当主磁盘驱动器发生故障时，由于有备份磁盘的存在，在进行切换后，使主机仍能正常工作。</p><p><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220123161407640-598426039.png" alt="img" style="zoom: 80%;"></p><p>磁盘镜像虽然实现了容错功能，却使磁盘的利用率降至 50%，也未能使服务器的磁盘 I/O 速度得到提高。如果控制这两台磁盘驱动器的磁盘控制器发生故障，或主机到磁盘控制器之间的通道发生故障，磁盘镜像功能便起不到数据保护的作用。</p><p>2）磁盘双工</p><p>因此 SFT-2 又增加了<strong>磁盘双工(Disk Duplexing)</strong>，即将两台磁盘驱动器分别接到两个磁盘控制器上，同样使这两台磁盘机镜像成对。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220123161709760-1791792696.png" alt="img" style="zoom:80%;"></p><p>如果某个通道或控制器发生故障时，另一通道上的磁盘仍能正常工作，不会造成数据的丢失。在磁盘双工时，由于每一个磁盘都有自己的独立通道，故可同时（并行)地将数据写入磁盘或读出数据。</p><h5 id="3-集群技术"><a href="#3-集群技术" class="headerlink" title="3. 集群技术"></a>3. 集群技术</h5><p>为了进一步增强服务器的并行处理能力和可用性，采用了对称多台处理机 SMP 来实现集群系统的服务器功能。<strong>集群</strong>是指由一组互连的自主计算机组成统一的计算机系统，给人们的感觉是是一台机器。利用集群系统不仅可提高系统的并行处理能力，还可用于提高系统的可用性，其主要工作模式有三种。</p><p>1）双机热备份模式</p><p><strong>双机热备份模式</strong>的系统中备有两台服务器，两者的处理能力通常是完全相同的，一台作为主服务器，另一台作为备份服务器。一旦主服务器出现故障，备份服务器便立即接替主服务器的工作而成为系统中的主服务器，修复后的服务器再作为备份服务器。<br>为使在这两台服务器间能保持镜像关系，应在这两台服务器上各装入一块网卡，并通过一条镜像服务器链路 MSL（Mirrored Server Link)将两台服务器连接起来。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220123163145261-2004173769.png" alt="img" style="zoom:80%;"></p><p>2）双机互为备份模式</p><p><strong>双机互为备份模式</strong>中，两台服务器均为在线服务器，它们各自完成自己的任务。在两台服务器之间通过某种专线将其连接起来，再通过路由器将两台服务器互连起来，作为备份通信线路。每台服务器内都配置两台硬盘，一个用于装载系统程序和应用程序，另一个用于接收由另一台服务器发来的备份数据，作为该服务器的镜像盘。在正常运行时，镜像盘对本地用户是锁死的，这样就较易于保证在镜像盘中数据的正确性。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220123164434456-1086134779.png" alt="img" style="zoom:80%;"><br>双机互为备份模式检测故障并恢复的步骤如下：</p><ol><li>如果通过专线链接检查到某台服务器发生了故障，通过路由器去验证这台服务器是否真的发生了故障；</li><li>如果故障被证实，则由正常服务器向故障服务器的客户机发出广播信息，表明要进行切换；</li><li>在切换成功后，客户机无须重新登录便可继续使用网络提供的服务；</li><li>当故障服务器修复并重新连到网上后，已被迁移到无故障服务器上的服务功能将被返回，恢复正常工作。</li></ol><p>对于连接在非故障服务器上的客户机，则只会感觉到网络服务稍有减慢而已。如果仅有一个硬盘，则可用建立虚拟盘的方式或分区方式来分别存放。这种模式的优点是两台服务器都可用于处理任务，因而系统效率较高，现在已将这种模式从两台机器扩大到 4 台、8 台、16 台甚至更多。</p><p>3）公用磁盘模式</p><p>为了减少信息复制的开销，可以将多台计算机连接到一台<strong>公共的磁盘系统</strong>上去。公共磁盘被划分为若干个卷，每台计算机使用一个卷。如果某台计算机发生故障，此时系统将重新进行配置，根据某种调度策略来选择另一台替代机器，后者对发生故障的机器的卷拥有所有权，从而可接替故障计算机所承担的任务。<br>这种模式的优点是消除了信息的复制时间，因而减少了网络和服务器的开销。</p><h5 id="4-后备系统"><a href="#4-后备系统" class="headerlink" title="4. 后备系统"></a>4. 后备系统</h5><p>在一个完整的系统中必须配置后备系统，一方面是因为磁盘系统不够大，不可能将系统在运行过程中的所有数据都装在磁盘中，需要把暂时不用的数据存放在后备系统中。另一方面是为了防止系统发生故障或病毒的感染，导致系统中的数据弄错或丢失。</p><p>1）磁带机</p><p><strong>磁带机</strong>最早作为计算机系统的外存储器，由于它只适合存储顺序文件，故现在主要把它作为后备设备。磁主要优点是容量大，一般可达数 GB 至数十 GB，且价格便宜，故在许多大、中型系统中都配置了磁带机。其缺点是只能顺序存取且速度也较慢，为数百 KB 到数 MB，为了将一个大容量磁盘上的数据拷贝到磁带上很耗时。</p><p>2）硬盘</p><ul><li>移动硬盘</li></ul><p>对于小型系统和个人电脑而言，常用<strong>移动磁盘</strong>作为后备系统。最大的优点是速度高，脱机保存方便，而且保存时间也较长，可比磁带机长出 3～5 年。但单位容量的费用较高，近年来移动磁盘的价格已有明显下降，而且体积也非常小，应用也日益广泛。</p><ul><li>固定硬盘驱动器</li></ul><p>在大、中型系统中可利用大容量硬盘兼做后备系统，为此需要在一个系统中配置两个大容量硬盘系统。每个硬盘都被划分为数据区和备份区，可在每天某个时刻将硬盘 1 中的“数据 0”拷贝到硬盘 1 中的拷贝区中保存，同样也将硬盘 2 中的“数据 1”拷贝到硬盘 0 中的拷贝区中保存。<br><img src="source/images/操作系统7：磁盘存储器管理/1774310-20220124001005964-1782090118.png" alt="img" style="zoom:80%;"></p><p>这种后备系统不仅拷贝速度非常快，而且还具有容错功能，即当其中任何一个硬盘驱动器发生故障时，都不会引起系统瘫痪。</p><p>3）光盘驱动器</p><p>只读光盘驱动器 CD-ROM 和 DVD-ROM 主要用于播放音频和视频，由于它们都只能播放（读）不能写，故难于用它们作为后备设备。<strong>可读写光盘驱动器</strong>又称为刻录机，既能播放（读）又能刻录（写），故可将它们作为后备设备，存储计算机中的数字信息。</p><h5 id="5-数据一致性"><a href="#5-数据一致性" class="headerlink" title="5. 数据一致性"></a>5. 数据一致性</h5><p>1）<strong>事务</strong></p><p>在实际应用中，经常会在多个文件中都含有同一个数据。数据一致性问题是指，保存在多个文件中的同一数据，在任何情况下都必需能保证相同。为了保证数据的一致性，在现代 OS 中都配置了能保证数据一致性的软件。</p><p>（1）事务的定义</p><p><strong>事务</strong>是用于访问和修改各种数据项的一个程序单位，也可以被看做是一系列相关读和写操作。只有对分布在不同位置的同一数据所进行的读和写（含修改）操作全部完成时，才能以<strong>提交操作（Commit Operation）</strong>结束事务，确认事务的变化。但是只要这些操作中有一个读、写或修改操作失败，便必须执行<strong>回滚操作（Abort Operation)</strong>。</p><p>一个被天折的事务，通常已执行了一些操作，可能已对某些数据做了修改。为使天折的事务不会引起数据的不一致性，需将该事务内刚被修改的数据项恢复成原来的情况，使系统中各数据项与该事务未执行时的数据项内容完全相同。</p><p>（2）事务的属性</p><p>事务必须同时满足四个属性，即<strong>事务属性 ACID</strong>。</p><div class="table-container"><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>原子性（Atomic）</td><td>一个事务要么全部完成，要么一个也不修改</td></tr><tr><td>一致性（Consistent)</td><td>事务在完成时，必须使所有的数据都保持一致状态</td></tr><tr><td>隔离性（Isolated）</td><td>即对一个事务对数据所作的修改，必须与任何其它与之并发事务相隔离</td></tr><tr><td>持久性（Durable)</td><td>即事务完成之后，它对于系统的影响是永久性的</td></tr></tbody></table></div><p>（3）事务记录</p><p>为了实现上述的原子修改，通常须借助于称为事务记录的数据结构来实现。这些数据结构被放在一个非常可靠的存储器中，又称为<strong>运行记录（Log）</strong>。包括有下列字段：</p><div class="table-container"><table><thead><tr><th>字段</th><th>说明</th></tr></thead><tbody><tr><td>事务名</td><td>用于标识该事务的唯一名字</td></tr><tr><td>数据项名</td><td>它是被修改数据项的唯一名字</td></tr><tr><td>旧值</td><td>修改前数据项的值</td></tr><tr><td>新值</td><td>修改后数据项将具有的值</td></tr></tbody></table></div><p>在事务记录表中的每一记录描述了在事务运行中的重要事务操作，如修改操作、开始事务、托付事务或天折事务等。</p><p>（4）恢复算法</p><p>由于一组被事务 Ti 修改的数据，以及它们被修改前和修改后的值都能在事务记录表中找到，因此利用事务记录表系统能处理任何故障，而不致使故障造成非易失性存储器中信息的丢失。恢复算法可利用以下两个过程：</p><ol><li>undo〈Ti〉：把所有被事务 Ti 修改过的数据恢复为修改前的值。</li><li>redo〈Ti〉：把所有被事务 Ti 修改过的数据设置为新值。</li></ol><p>如果系统发生故障，系统应对以前所发生的事务进行清理。通过查找事务记录表，可以把尚未清理的事务分成两类。一类是其所包含的各类操作都已完成的事务，另一类是其所包含的各个操作并未全部完成的事务。</p><p>2）<strong>检查点</strong></p><p>当系统发生故障时，必须去检查整个 Log 表。由于在系统中可能存在着许多并发执行的事务，因而在事务记录表中就会有许多事务执行操作的记录。因此一旦系统发生故障，在事务记录表中的记录清理起来就非常费时。</p><p>引入<strong>检查点</strong>的主要目的是，使对事务记录表中事务记录的清理工作经常化，即每隔一定时间便做一次下述工作。如果一个事务在检查点前就做了托付，则在事务记录表中便会出现一个在检查点记录前的托付记录。在这种情况下，所有被该事务修改过的数据或者是在检查点前已写入稳定存储器，以后在系统出现故障时，就不必再执行 redo 操作了。</p><p>3）<strong>并发控制</strong></p><p>在多用户系统和计算机网络环境下，可能有多个用户在同时执行事务，把用于实现事务顺序性的技术称为并发控制。该技术在应用数据库系统中已被广泛采用，现也广泛应用于 OS 中，在数据库系统和文件服务器中应用得最多的同步机制——锁。</p><p>（1）互斥锁</p><p>实现顺序性的一种最简单的方法，是设置<strong>互斥锁（Exclusive Lock）</strong>。当某一事务 Ti 要去访问某对象时，应先获得该对象的互斥锁。若成功便用该锁将该对象锁住，于是事务 Ti 便可对该对象执行读或写操作，其它事务由于未能获得该锁不能访问该对象。但如果对象已被其它事务锁住，则此时 Ti 应对此前已被 Ti 锁住的其它对象进行开锁，宣布此次事务运行失败，但不致引起数据的变化。</p><p>（2）共享锁</p><p>利用互斥锁实现顺序性的方法简单易行，但这却存在着效率不高的问题。因为一个共享文件虽然只允许一个事务去写，但却允许多个事务同时去读，而在利用互斥锁来锁住文件后，则只允许一个事务去读。为了提高运行效率而又引入了<strong>共享锁（Shared Lock）</strong>，共享锁则允许多个事务对相应对象执行读操作，但不允许其中任何一个事务对对象执行写操作。</p><p>4）<strong>重复数据的一致性</strong></p><p>为了保证数据的安全性，最常用的做法是把关键文件或数据结构复制多份，当主文件失效时还有备份文件可以使用。显然主文件中的数据应与各备份文件中的对应数据相一致，同样应保证不同处的同一数据结构中数据的一致性。</p><p>（1）重复文件的一致性</p><p>在有重复文件时，如果一个文件拷贝被修改，则必须也同时修改其它几个文件拷贝，以保证各相应文件中数据的一致性。这可采用两种方法来实现：</p><ol><li>当一个文件被修改后可查找文件目录，以得到其它几个拷贝的索引结点号，再从这些索引结点中找到各拷贝的物理位置，然后对这些拷贝做同样的修改；</li><li>为新修改的文件建立几个拷贝，并用新拷贝去取代原来的文件拷贝。</li></ol><p>（2）链接数的一致性</p><p>在 UNIX 类型的文件目录中，其每个目录项内都含有一个索引结点号，用于指向该文件的索引结点。对于一个共享文件，其索引结点号会在目录中出现多次。另一方面在该共享文件的索引结点中有一个链接计数 count，用来指出共享本文件的用户（进程）数。在正常情况下这两个数据应该一致，否则就会出现数据不一致性差错。</p><p>为了检查这种数据不一致性差错，需要配置一张计数器表，为每个文件建立一个表项，其中含有该索引结点号的计数值。在进行检查时，从根目录开始查找，每当在目录中遇到该索引结点号时，便在该计数器表中相应文件的表项上加 1。当把所有目录都检查完后，便可将该计数器表中每个表项中的索引结点号计数值与该文件索引结点中的链接计数 count 值加以比较，如果两者一致表示是正确的，否则便是发生了链接数据不一致的错误。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统6：文件管理</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-6-wen-jian-guan-li/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-6-wen-jian-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="第七章-文件管理"><a href="#第七章-文件管理" class="headerlink" title="第七章 文件管理"></a>第七章 文件管理</h1><h3 id="7-1-文件和文件系统"><a href="#7-1-文件和文件系统" class="headerlink" title="7.1 文件和文件系统"></a>7.1 文件和文件系统</h3><p>现代OS几乎都是通过文件系统来组织和管理在计算机中所存储的大量程序和数据的。<strong>文件系统的管理功能是通过把它所管理的程序和数据组织成一系列文件的方法来实现</strong>的。而<strong>文件则是指具有文件名的若干相关元素的集合</strong>。<strong>元素通常是记录，而记录是一组有意义的数据项的集合</strong>。可以把数据组成分为数据项、记录、文件三级。</p><p><img src="source/images/操作系统6：文件管理/1774310-20210811164556661-531619553.png" alt="img" style="zoom:80%;"></p><h5 id="1-数据项、记录和文件"><a href="#1-数据项、记录和文件" class="headerlink" title="1. 数据项、记录和文件"></a>1. 数据项、记录和文件</h5><p>① <strong>数据项</strong>，数据项是最低级数据组织形式。分为基本数据项（用于描述一个对象某种属性的字符集，是数据组织中可以明明的最小逻辑数据单位，即原子数据，又称为数据元素或字段）和组合数据项（由若干个基本数据项组成）。</p><p>② <strong>记录</strong>，是一组相关数据项的集合，用于描述一个对象在某方面的属性，为了能够唯一标识一个记录，需要在记录中确定一个或集合数据项，把他们的集合称为关键字，关键字是能够唯一标识一个记录的数据项。</p><p>③ <strong>文件</strong>，文件是具有文件名的一组相关元素的集合，分为有结构文件和无结构文件。有结构文件由若干个相关记录组成，无结构文件则被看成一个字符流。文件是文件系统的最大数据单位。文件应该具有自己的属性，包括文件类型、文件长度、文件的物理位置和文件的建立时间。</p><div class="table-container"><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>文件类型</td><td>可以从不同的角度来规定文件的类型，如源文件、目标文件及可执行文件等</td></tr><tr><td>文件长度</td><td>指文件的当前长度，长度的单位可以是字节、字或块，也可能是最大允许的长度</td></tr><tr><td>文件的物理位置</td><td>通常用于指示文件所在的设备及所在设备中地址的指针</td></tr><tr><td>文件的建立时间</td><td>指最后一次的修改时间等</td></tr></tbody></table></div><p>一个文件可对应若干个记录，一个记录可对应若干个数据项。</p><h5 id="2-文件名和文件类型"><a href="#2-文件名和文件类型" class="headerlink" title="2. 文件名和文件类型"></a>2. 文件名和文件类型</h5><p>在不同的系统之间对<strong>文件名</strong>的规定是不同的，在一些老的系统中名字的长度受到限制，另外一些特殊字符也规定不能用于文件名。<strong>扩展名</strong>又称为后缀名，是添加在文件名后面的若干个附加字符，用于指示文件的类型。</p><p>为了便于管理和控制文件，将文件分成若干种类型。由于不同的系统对文件管理方式的不同，因此对文件的分类方法也有很大差异。</p><p>根据文件的性质和用途的不同，可将文件分为三类：</p><div class="table-container"><table><thead><tr><th>文件类型</th><th>说明</th></tr></thead><tbody><tr><td>系统文件</td><td>由系统软件构成的文件，大多数的系统文件只允许用户调用，不允许读和修改</td></tr><tr><td>用户文件</td><td>指由用户的源代码、目标文件、可执行文件或数据等所构成的文件</td></tr><tr><td>库文件</td><td>由标准子例程及常用的例程等所构成的文件，允许用户调用但不允许修改</td></tr></tbody></table></div><p>按文件中数据的形式分类，也可把文件分为三类：</p><div class="table-container"><table><thead><tr><th>文件类型</th><th>说明</th></tr></thead><tbody><tr><td>源文件</td><td>由源程序和数据构成的文件，由终端或输入设备输入的源程序和数据所形成的文件都属于源文件</td></tr><tr><td>目标文件</td><td>把源程序经过编译程序编译过，但尚未经过链接程序链接的目标代码所构成的文件，后缀名是“.obj”</td></tr><tr><td>可执行文件</td><td>把编译后所产生的目标代码经过链接程序链接后所形成的文件，后缀名是“.exe”</td></tr></tbody></table></div><p>根据系统管理员或用户所规定的存取控制属性，可将文件分为三类：</p><div class="table-container"><table><thead><tr><th>文件类型</th><th>说明</th></tr></thead><tbody><tr><td>只执行文件</td><td>只允许被核准的用户调用执行，不允许读和写</td></tr><tr><td>只读文件</td><td>只允许文件主及被核准的用户去读，不允许写</td></tr><tr><td>读写文件</td><td>允许文件主和被核准的用户去读或写的文件</td></tr></tbody></table></div><p>根据文件的组织形式和系统对其处理方式的不同，可将文件分为三类：</p><div class="table-container"><table><thead><tr><th>文件类型</th><th>说明</th></tr></thead><tbody><tr><td>普通文件</td><td>是由 ASCII 码或二进制码组成的字符文件</td></tr><tr><td>目录文件</td><td>是由文件目录组成的文件</td></tr><tr><td>特殊文件</td><td>特指系统中的各类 I/O 设备</td></tr></tbody></table></div><h5 id="3-文件系统的层次结构"><a href="#3-文件系统的层次结构" class="headerlink" title="3. 文件系统的层次结构"></a>3. 文件系统的层次结构</h5><p>由于计算机中的内存是易失性设备，所以要将系统和用户需要用到的大量程序和数据以文件的形式存放在外存中，需要时再随时将它们调入内存。在 OS 中又增加了文件管理功能，文件系统的管理功能是将其管理的程序和数据通过组织为一系列文件的方式实现的。它能专门管理在外存上的文件，并把对文件的存取、共享和保护等手段提供给用户。这不仅方便了用户，保证了文件的安全性，还可有效地提高系统资源的利用率。</p><p>文件系统的模型可分为三个层次，最底层是对象及其属性，中间层是对对象进行操纵和管理的软件集合，最高层是文件系统提供给用户的接口。<br><img src="source/images/操作系统6：文件管理/1774310-20210811170823843-1723792888.png" alt="img" style="zoom:80%;"></p><p>1）<strong>对象及其属性</strong></p><p>文件管理系统管理的对象有文件、目录和磁盘存储空间。<br><img src="source/images/操作系统6：文件管理/1774310-20210811172848848-99253181.png" alt="img" style="zoom:80%;"></p><div class="table-container"><table><thead><tr><th>对象</th><th>说明</th></tr></thead><tbody><tr><td>文件</td><td>在文件系统中有着各种不同类型的文件，都是文件管理的直接对象</td></tr><tr><td>目录</td><td>在目录的每个目录项中，含有文件名、对文件属性的说明，以及该文件所在的物理地址(或指针)</td></tr><tr><td>磁盘(磁带)存储空间</td><td>文件和目录必定占用存储空间</td></tr></tbody></table></div><p>2）<strong>对对象操纵和管理的软件集合</strong></p><p>该层是文件管理系统的核心部分，包含文件系统的大部分功能：</p><ol><li>对文件存储空间的管理；</li><li>对文件目录的管理；</li><li>用于将文件的逻辑地址转换为物理地址的机制；</li><li>对文件读和写的管理；</li><li>对文件的共享与保护等功能。</li></ol><p>在实现这些功能时，OS 通常都采取了层次组织结构，处于某个层次的软件只能调用同层或更低层次中的功能模块。一般地把与文件系统有关的软件分为四个层次：</p><div class="table-container"><table><thead><tr><th>层次</th><th>说明</th></tr></thead><tbody><tr><td>I/O 控制层</td><td>是文件系统的最低层，主要由磁盘驱动程序等组成</td></tr><tr><td>基本文件系统层</td><td>用于处理内存与磁盘之间数据块的交换</td></tr><tr><td>基本 I/O 管理程序</td><td>用于完成与磁盘 I/O 有关的事务</td></tr><tr><td>逻辑文件系统</td><td>用于处理与记录和文件相关的操作</td></tr></tbody></table></div><p>3）<strong>文件系统的接口</strong></p><p>为方便用户的使用，文件系统以接口的形式提供了一组对文件和记录操作的方法和手段。通常是下面两种类型的接口：</p><div class="table-container"><table><thead><tr><th>接口</th><th>说明</th></tr></thead><tbody><tr><td>命令接口</td><td>是指作为用户与文件系统直接交互的接口，用户可通过键盘终端键入命令取得文件系统的服务</td></tr><tr><td>程序接口</td><td>是指作为用户程序与文件系统的接口，用户程序可通过系统调用取得文件系统的服务</td></tr></tbody></table></div><h5 id="4-文件操作"><a href="#4-文件操作" class="headerlink" title="4. 文件操作"></a>4. 文件操作</h5><p>用户可以通过文件系统提供的系统调用实施对文件的操作，除了最基本的文件操作，一般的 OS 都提供了更多对文件的操作。</p><p>1）最基本的文件操作</p><div class="table-container"><table><thead><tr><th>文件操作</th><th>说明</th></tr></thead><tbody><tr><td>创建文件</td><td>为新文件分配必要的外存空间，并在文件目录中为之建立一个目录项，目录项中应记录新文件的属性</td></tr><tr><td>删除文件</td><td>先从目录中找到要删除文件的目录项，然后回收该文件所占用的存储空间</td></tr><tr><td>读文件</td><td>根据用户给出的文件名去查找目录，从中得到被读文件在外存中的位置</td></tr><tr><td>写文件</td><td>根据文件名查找目录，找到指定文件的目录项，再利用目录中的写指针进行写操作</td></tr><tr><td>设置文件的读/写位置</td><td>通过设置文件读/写指针的位置，以便读/写文件时从所设置的位置开始操作</td></tr></tbody></table></div><p>2）文件的“打开”和“关闭”操作</p><p>当用户要求对一个文件实施多次读/写或其它操作时，每次都要从检索目录开始。为了避免多次重复地检索目录，当用户第一次请求对某文件进行操作时，须先利用 open 系统调用将该文件打开。<strong>打开</strong>就是在用户和指定文件之间建立起一个连接，具体指系统将指名文件的属性（包括该文件在外存上的物理位置)，从外存拷贝到内存打开文件表的一个表目中，并将该表目的编号(或称为索引号）返回给用户。</p><p>如果用户已不再需要对该文件实施相应的操作，可利用<strong>关闭(close)</strong>系统调用来关闭此文件，即断开此连接，OS 将会把该文件从打开文件表中的表目上删除掉。</p><p>3）其它文件操作</p><p>OS 为用户都提供了一系列文件操作的系统调用，其中最常用的一类是有关对文件属性的操作，即允许用户直接设置和获得文件的属性另一类是有关目录的操作，如创建一个目录，删除一个目录，改变当前目录和工作目录等。此外，还有用于实现文件共享的系统调用，以及用于对文件系统进行操作的系统调用等。</p><h3 id="7-2-文件的逻辑结构"><a href="#7-2-文件的逻辑结构" class="headerlink" title="7.2 文件的逻辑结构"></a>7.2 文件的逻辑结构</h3><p>对任何的文件，都存在以下两种形式的结构：</p><p>① <strong>文件的逻辑结构</strong>，这是从用户观点出发所观察到的文件组织形式，是用户可以直接处理的数据及其结构，独立于文件的物理特性，又称为文件组织。</p><p>② <strong>文件的物理结构</strong>，又称为文件的存储结构，是指文件在外存上的存储组织形式，不仅与存储介质有关，还与外存分配方式有关。</p><p>文件的<strong>逻辑结构(File Logical Structure)</strong>是从用户观点出发所观察到的文件组织形式，即文件是由一系列的逻辑记录组成的，用户可以直接处理的数据及其结构。与之对应的是文件的<strong>物理结构</strong>或存储结构，指系统将文件存储在外存上所形成的一种存储组织形式，是用户不能看见的。</p><h5 id="1-文件逻辑结构的类型"><a href="#1-文件逻辑结构的类型" class="headerlink" title="1. 文件逻辑结构的类型"></a>1. 文件逻辑结构的类型</h5><p>对文件逻辑结构首先是有助于提高对文件的检索速度，其次是该结构应方便对文件进行修改，第三是尽量减少文件占用的存储空间，不要求大片的连续存储空间。文件的逻辑结构从是否有结构来分，可分为有结构文件和另一类是无结构文件。从文件的组织方式来分，可以分为顺序文件、索引文件和索引顺序文件几种。</p><p>1）按文件是否有结构分类</p><p><strong>有结构文件</strong>也称记录式文件，每个记录都用于描述实体集中的一个实体，记录的长度可分为定长和不定长两类。<strong>定长记录</strong>是指文件中所有记录的长度都是相同的，文件的长度用记录数目表示。定长记录能有效地提高检索记录的速度和效率，能方便对文件进行处理和修改，所以这是目前较常用的一种记录格式。</p><p><strong>变长记录</strong>是指文件中各记录的长度不相同，可能是由于一个记录中所包含的数据项数目并不相同，也可能是数据项本身的长度不定。不论是哪一种，在处理前每个记录的长度都是可知的。对变长记录的检索速度慢，也不便于对文件进行处理和修改。但由于变长记录很适合于某些场合的需要，所以也是较常用的一种记录格式。</p><p><strong>无结构文件</strong>是文件内部的数据就是一系列二进制流或字符流组成的文件，又称“流式文件”。流式文件的长度是以字节为单位的，访问时是利用读、写指针来指出下一个要访问的字符。</p><p>2）按文件的组织方式分类</p><p>根据文件的组织方式，可把有结构文件分为三类：</p><div class="table-container"><table><thead><tr><th>文件分类</th><th>说明</th></tr></thead><tbody><tr><td>顺序文件</td><td>指由一系列记录按某种顺序排列所形成的文件，其中的记录可以是定长记录或可变长记录。</td></tr><tr><td>索引文件</td><td>指为可变长记录文件建立一张索引表，为每个记录设置一个表项以加速对记录的检索速度。</td></tr><tr><td>索引顺序文件</td><td>将顺序文件和索引文件相结合</td></tr></tbody></table></div><h5 id="2-顺序文件"><a href="#2-顺序文件" class="headerlink" title="2. 顺序文件"></a>2. 顺序文件</h5><p>1）顺序文件的排列方式</p><p>在顺序文件中的记录，可以按照各种不同的顺序进行排列。一般地可分为两种情况，第一种是<strong>串结构</strong>，在串结构文件中的记录通常是按存入时间的先后进行排序的，各记录之间的顺序与关键字无关。在对串结构文件进行检索时必须从头开始，直到找到指定的记录或查完所有的记录为止，显然对串结构文件检索是比较费时的。<br><img src="source/images/操作系统6：文件管理/1774310-20210812031058939-382942562.png" alt="img" style="zoom:80%;"></p><p>第二种是<strong>顺序结构</strong>，由用户指定一个字段作为关键字唯一地标识记录，关键字值在文件中具有唯一性。文件中的所有记录就可以按关键字来排序，可以利用某种有效的查找算法提高检索效率。顺序文件常用于每次要读或写一大批记录时，在所有逻辑文件中它的存取效率是最高的。对于顺序存储设备(如磁带)，只能使用顺序存储。在交互应用的场合，如果用户(程序)要求查找、删除或修改单个记录，系统需要在文件的记录中逐个地查找，性能就被降低了。</p><p>2）顺序文件的寻址</p><p>访问顺序文件中的一条记录需要先找到该记录的地址，查找记录地址的方法有隐式寻址和显式寻址方式两种。</p><p><strong>隐式寻址方式</strong>是对于定长记录的顺序文件，如果已知当前记录的逻辑地址，可以设置一个读指针<code>ptr</code>。每当读写完一个记录时，便执行 <code>ptr = ptr + L</code> 操作就可以指向下一个记录的首地址，其中的 L 为记录长度。对于变长记录的顺序文件，每次都需要从正在读写的记录中读出该记录的长度 Li，然后执行 <code>ptr = ptr + Li</code> 操作。主要问题是访问一个指定记录 i，必须扫描或读取前面第 <code>0 ~ i-1</code>个记录，访问速度是比较慢的。</p><script type="math/tex; mode=display">A_{i}=\sum_{i=0}^{i-1}L_{i}+1</script><p><strong>显式寻址方式</strong>可用于对定长记录的文件实现直接或随机访问，而对于可变长度记录的文件须增加适当的支持机构实现。在文件中的每一个记录都可以用一个整数来唯一地标识一个记录，对于定长记录文件如果要查找第 i 个记录，可直接根据下式计算获得第 i 个记录相对于第一个记录首址的地址。</p><script type="math/tex; mode=display">A_{i} = i × L</script><p><img src="source/images/操作系统6：文件管理/1774310-20210812151519155-367250065.png" alt="img" style="zoom:80%;"><br>显式寻址也可以利用关键字，当用户给出要检索记录的关键字时，系统将利用该关键字顺序地与每一个记录的关键字进行比较，直到找到匹配的记录。</p><h5 id="3-索引文件"><a href="#3-索引文件" class="headerlink" title="3. 索引文件"></a>3. 索引文件</h5><p>对于可变长记录文件，要找到第 i 个记录，必须先顺序第查找前 i-1 个记录，搜索效率较低。为了解决这个问题，可以为变长记录文件建立一张<strong>索引表</strong>，为主文件中的每个记录在索引表中分别设置一个表项，记录指向记录的指针以及记录的长度 L。索引表本身是定长记录的顺序文件，因此可以快速找到第 i 个记录对应的索引项。<br><img src="source/images/操作系统6：文件管理/1774310-20210812153715959-1612807919.png" alt="img" style="zoom:80%;"></p><p>可将关键字作为索引号内容，若按关键字顺序排列，则还可以支持按照关键字折半查找。每当要增加/删除一个记录时，需要对索引表进行修改。由于索引文件有很快的检索速度，因此主要用于对信息处理的及时性要求比较高的场合。同时实际应用中不同的用户，希望能按不同的属性(或不同的关键字)来检索一条记录。此时需要为顺序文件建立多个索引表，即为每一种可能成为检索条件的属性或关键字都配置一张索引表。</p><h5 id="4-索引顺序文件"><a href="#4-索引顺序文件" class="headerlink" title="4. 索引顺序文件"></a>4. 索引顺序文件</h5><p>1）一级索引顺序文件</p><p>索引文件的每个记录对应一个索引表项，因此索引表可能会很大。比如文件的每个记录平均只占 8B，而每个索引表项占 32 个字节，那么索引表都要比文件内容本身大 4 倍。<strong>索引顺序文件(Index Sequential File)</strong>是索引文件和顺序文件思想的结合，它同样会为文件建立一张索引表，一组记录对应一个索引表项。<br><img src="source/images/操作系统6：文件管理/1774310-20210812155028444-1872285073.png" alt="img" style="zoom:80%;"></p><p>2）检索效率分析</p><p>若一个顺序文件有 10000 个记录，则根据关键字检索只能从头开始顺序查找，平均须查找 5000 个记录。若采用索引顺序文件结构，可把 10000 个记录分为 100 组，每组 100 个记录。则需要先顺序查找索引表找到分组(平均需要查 50 次），找到分组后再在分组中顺序查找记录（平均需要查 50 次），采用索引顺序文件结构后平均查找次数减少为 50 + 50 = 100次。</p><p>3）两级索引顺序文件</p><p>对于一个非常大的文件，为找到一个记录而须查找的记录数目仍然很多。例如对于一个含有 10^6 个记录的顺序文件，找到一个记录平均须查找 1000 个记录。为了进一步提高检索效率，可以为顺序文件建立多级索引，即为索引文件再建立一张索引表，从而形成<strong>两级索引表</strong>。</p><h5 id="5-直接文件和哈希文件"><a href="#5-直接文件和哈希文件" class="headerlink" title="5. 直接文件和哈希文件"></a>5. 直接文件和哈希文件</h5><p>采用前述几种文件结构对记录进行存取时，都须利用给定的记录键值，对线性表进行检索以找到指定记录的物理地址。对于<strong>直接文件</strong>则可根据关键字直接获得指定记录的物理地址，关键字本身就决定了记录的物理地址，这种由关键字到记录物理地址的转换被称为键值转换。<br><strong>哈希(Hash)文件</strong>是目前应用最为广泛的一种直接文件，它利用 Hash 函数（或称散列函数）可将关键字转换为相应记录的地址。但为了能实现文件存储空间的动态分配，通常由Hash函数所求得的并非是相应记录的地址，而是指向某一目录表相应表目的指针。</p><h3 id="7-3-文件目录"><a href="#7-3-文件目录" class="headerlink" title="7.3 文件目录"></a>7.3 文件目录</h3><h5 id="1-目录管理的要求"><a href="#1-目录管理的要求" class="headerlink" title="1. 目录管理的要求"></a>1. 目录管理的要求</h5><p>为了能对计算机系统中的大量文件实施有效的管理，必须对它们加以妥善组织，这主要是通过文件目录实现的。<strong>文件目录</strong>是一种数据结构，用于标识系统中的文件及其物理地址，供检索时使用。对目录管理的要求如下：</p><div class="table-container"><table><thead><tr><th>要求</th><th>说明</th></tr></thead><tbody><tr><td>实现“按名存取”</td><td>用户向系统提供所需访问文件的名字，能快速准确地找到指定文件在外存上的存储位置</td></tr><tr><td>提高对目录的检索速度</td><td>通过合理地组织目录结构加快对目录的检索速度，从而提高对文件的存取速度</td></tr><tr><td>文件共享</td><td>允许多个用户共享一个文件，节省大量的存储空间并方便用户和提高文件利用率</td></tr><tr><td>允许文件重名</td><td>允许不同用户对不同文件采用相同的名字</td></tr></tbody></table></div><h5 id="2-目录的构成"><a href="#2-目录的构成" class="headerlink" title="2. 目录的构成"></a>2. 目录的构成</h5><p>1）<strong>文件控制块</strong></p><p>为了能对一个文件进行正确的存取，必须为文件设置用于描述和控制文件的数据结构，称之为<strong>文件控制块 FCB(File Control Block)</strong>。文件管理程序可借助于文件控制块中的信息对文件施以各种操作，文件与文件控制块一一对应，把文件控制块的有序集合称为文件目录。</p><p>为了能对系统中的大量文件施以有效的管理，在文件控制块中，通常应含有三类信息：基本信息、存取控制信息及使用信息。基本信息类包括文件名、文件物理位置、文件逻辑结构和文件的物理结构，存取控制信息类包括文件的存取权限，使用信息类包括文件的建立日期和时间、文件上一次修改的日期和时间，以及当前使用信息。<br><img src="source/images/操作系统6：文件管理/1774310-20210812213944766-1413288636.png" alt="img" style="zoom:80%;"></p><p>2）<strong>索引结点</strong></p><p>文件目录通常是存放在磁盘上的，当文件很多时，文件目录可能要占用大量的盘块。在查找目录的过程中，必须先将存放目录文件的第一个盘块中的目录调入内存，然后将被搜索的文件名与目录项中的文件名逐一比较。若未找到指定文件，还需要将下一盘块的目录项调入内存。假设目录文件所占用的盘块数为 N，则查找一个目录项平均需要调入盘块 (N + 1) / 2 次。</p><p>在检索目录文件的过程中，只用到了文件名，仅当找到一个目录项时，才需从该目录项中读出该文件的物理地址。为此在有的系统中，把文件名与文件描述信息分开，使文件描述信息单独形成一个称为<strong>索引结点</strong>的数据结构，在文件目录中的每个目录项仅由文件名和指向该文件所对应的索引结点。<br><img src="source/images/操作系统6：文件管理/1774310-20210812214957541-2144758029.png" alt="img" style="zoom:80%;"></p><h5 id="3-对目录的操作"><a href="#3-对目录的操作" class="headerlink" title="3. 对目录的操作"></a>3. 对目录的操作</h5><div class="table-container"><table><thead><tr><th>操作</th><th>说明</th></tr></thead><tbody><tr><td>搜索</td><td>当用户要使用一个文件时，系统要根据文件名搜索目录，找到该文件对应的目录项</td></tr><tr><td>创建文件</td><td>创建一个新文件时，需要在其所属的目录中增加一个目录项</td></tr><tr><td>删除文件</td><td>当删除一个文件时，需要在目录中删除相应的目录项</td></tr><tr><td>显示目录</td><td>用户可以请求显示目录的内容，如显示该目录中的所有文件及相应属性</td></tr><tr><td>修改目录</td><td>某些文件属性保存在目录中，因此这些属性变化时需要修改相应的目录项</td></tr></tbody></table></div><h5 id="4-简单文件目录"><a href="#4-简单文件目录" class="headerlink" title="4. 简单文件目录"></a>4. 简单文件目录</h5><p>最简单的文件目录形式是单级目录和两级目录。</p><p>1）单级文件目录</p><p><strong>单级文件目录</strong>是最简单的文件目录，在整个文件系统中只建立一张目录表，每个文件占一个目录项，目录项中含文件名、文件扩展名、文件长度、文件类型、文件物理地址以及其它文件属性。为表明每个目录项是否空闲，又设置了一个状态位。每当要建立一个新文件时，必须保证新文件名在目录中是唯一的，然后再从目录表中找出一个空白目录项，填入新文件的文件名及其它说明信息，并置状态位为 1。删除文件时先从目录中找到该文件的目录项，回收该文件所占用的存储空间，然后再清除该目录项。<br><img src="source/images/操作系统6：文件管理/1774310-20210812215639323-1324335540.png" alt="img" style="zoom:80%;"></p><p>单级文件目录的优点是简单，但它只能实现目录管理中最基本的功能——按名存取，具有查找速度慢、不允许重名、不便于实现文件共享的缺点。</p><p>2）两级文件目录</p><p>为了克服单级文件目录所存在的缺点，可以为每一个用户再建立一个单独的<strong>用户文件目录 UFD(User File Directory)</strong>，这些文件目录由用户所有文件的 FCB 组成。此外在系统中再建立一个主文件目录 MFD(Master File Directory)，每个用户目录文件都占有一个目录项，其目录项中包括用户名和指向该用户目录文件的指针。</p><p>如果用户希望有自己的用户文件目录 UFD，可以请求系统为自己建立一个用户文件目录，如果自己不再需要 UFD，也可以请求系统管理员将它撤消。UFD 用户可以根据自己的需要在 UFD 创建新文件，OS 只需检查该用户的 UFD 判定是否已有同名的另一个文件。若有用户必须为新文件重新命名，若无便在 UFD 中建立一个新目录项，将新文件名及其有关属性填入目录项中，并置其状态位为“1”。当用户要删除一个文件时，OS 也只需查找该用户的 UFD，在回收该文件所占用的存储空间后，将该目录项删除。</p><p><img src="source/images/操作系统6：文件管理/1774310-20210812221448672-328471544.png" alt="img" style="zoom:80%;"><br>两级文件目录提高了检索目录的速度，在不同的用户目录中，可以使用相同的文件名，不同用户还可使用不同的文件名访问系统中的同一个共享文件。但是该结构虽然能有效地将多个用户隔开，当一用户需去访问其他用户的文件时，这种隔离会使诸用户之间不便于共享文件。</p><h5 id="5-树形结构目录"><a href="#5-树形结构目录" class="headerlink" title="5. 树形结构目录"></a>5. 树形结构目录</h5><p>在现代 OS 中，最通用且实用的文件目录是<strong>树形结构目录(Tree-Structured Directory)</strong>。主目录在这里被称为根目录，在每个文件目录中，只能有一个根目录，每个文件和每个目录都只能有一个父目录。把数据文件称为树叶，其它的目录均作为树的结点，或称为子目录。<br><img src="source/images/操作系统6：文件管理/1774310-20210812221707779-442162773.png" alt="img" style="zoom:80%;"><br>在树形结构目录中，从根目录到任何数据文件都只有一条唯一的通路。在该路径上从树的根(即主目录）开始，把全部目录文件名与数据文件名依次地用“/”连接起来，即构成该数据文件唯一的<strong>路径名(path name)</strong>。如果每访问一个文件都要使用从树根开始，这是相当麻烦的事，同时由于一个进程运行时所访问的文件大多仅局限于某个范围，因而非常不便。可为每个进程设置一个<strong>“当前目录”(Current Directory)</strong>，又称为“工作目录”，进程对各文件的访问都相对于“当前目录”而进行。</p><p>树形结构目录的查询速度更快，同时层次结构更加清晰，能够更加有效地进行文件的管理和保护。不同性质、不同用户的文件，可以构成不同的目录子树，不同层次、不同用户的文件，分别呈现在系统目录树中的不同层次或不同子树中，可以容易地赋予不同的存取权限。但是查找一个文件，需要按路径名逐级访问中间节点，增加了磁盘访问次数。</p><h3 id="7-4-文件共享"><a href="#7-4-文件共享" class="headerlink" title="7.4 文件共享"></a>7.4 文件共享</h3><p>系统应允许多个用户(进程)共享，这样在系统中只需保留该共享文件的一份副本。如果系统不能提供文件共享功能，就意味着凡是需要该文件的用户，都须各自备有此文件的副本，显然这会造成对存储空间的极大浪费。</p><h5 id="1-基于有向无循环图实现文件共享"><a href="#1-基于有向无循环图实现文件共享" class="headerlink" title="1. 基于有向无循环图实现文件共享"></a>1. 基于有向无循环图实现文件共享</h5><p>1）有向无循环图DAG</p><p>在严格的树形结构目录中，每个文件只允许有一个父目录，其它用户要想访问它必须经过其属主目录来访问该文件。树形结构目录是不适合文件共享的，如果允许一个文件可以有多个父目录，这些用户可用对称的方式实现文件共享，而不必再通过其属主目录来访问，此时的结构是<strong>有向无循环图 DAG(Directed Acyclic Graph)</strong>。当有多个用户要共享一个子目录或文件时，必须将共享文件或子目录链接到多个用户的父目录中。<br><img src="source/images/操作系统6：文件管理/1774310-20210812223310446-610760785.png" alt="img" style="zoom:80%;"></p><p>2）索引结点</p><p>将文件的物理地址及其它的文件属性等信息放在索引结点中，在文件目录中只设置文件名及指向相应索引结点的指针。索引结点中设置一个链接计数变量 count，用于表示链接到本索引结点上的用户目录项数。若某个用户决定“删除”该文件，则只是要把用户目录中与该文件对应的目录项删除，且索引结点的 count 值减 1。若 count &gt; 0 说明还有别的用户要使用该文件，暂时不能把文件数据删除，当 count = 0 时系统负责删除文件。<br><img src="source/images/操作系统6：文件管理/1774310-20210812224038619-121372676.png" alt="img" style="zoom:80%;"></p><h5 id="2-利用符号链接实现文件共享"><a href="#2-利用符号链接实现文件共享" class="headerlink" title="2. 利用符号链接实现文件共享"></a>2. 利用符号链接实现文件共享</h5><p>利用<strong>符号链接(Symbolic Linking)</strong>实现文件共享的基本思想，是允许一个文件或子目录有多个父目录，但其中仅有一个作为主(属主）父目录，其它的几个父目录都是通过符号链接方式与之相链接的（简称链接父目录)。当用户访问被链接的文件且正要读 LINK 类新文件时，OS 根据新文件中的路径名去找到被连接文件，然后对它进行读写。在利用符号链方式实现文件共享时，只是文件主才拥有指向其索引结点的指针，而共享该文件的其他用户则只有该文件的路径名。这样不会发生在文件主删除一共享文件后留下一悬空指针的情况，如果其他用户又试图通过符号链去访问一个已被删除的共享文件，则会因系统找不到该文件而使访问失败，此时再将符号链删除。</p><p>但是当其他用户去读共享文件时，系统是根据给定的文件路径名逐个分量(名）地去查找目录，因此在每次访问共享文件时都可能要多次地读盘。同时每增加一条链接，就增加一个文件名，当试图去遍历(traverse)整个文件系统时将会多次遍历到该共享文件。</p><h3 id="7-5-文件保护"><a href="#7-5-文件保护" class="headerlink" title="7.5 文件保护"></a>7.5 文件保护</h3><h5 id="1-文件安全性的影响因素"><a href="#1-文件安全性的影响因素" class="headerlink" title="1. 文件安全性的影响因素"></a>1. 文件安全性的影响因素</h5><p>影响文件安全性的主要因素有：</p><div class="table-container"><table><thead><tr><th>因素</th><th>说明</th></tr></thead><tbody><tr><td>人为因素</td><td>人们有意或无意的行为，会使文件系统中的数据遭到破坏或丢失</td></tr><tr><td>系统因素</td><td>由于系统的某部分出现异常情况，而造成数据的破坏或丢失</td></tr><tr><td>自然因素</td><td>随着时间的推移，存放在磁盘上的数据会逐渐消失</td></tr></tbody></table></div><p>为了确保文件系统的安全性，可针对上述原因而采取三方面的措施：</p><div class="table-container"><table><thead><tr><th>措施</th><th>说明</th></tr></thead><tbody><tr><td>通过存取控制机制</td><td>防止由人为因素所造成的文件不安全性</td></tr><tr><td>采取系统容错技术</td><td>防止系统部分的故障所造成的文件的不安全性</td></tr><tr><td>建立后备系统</td><td>防止由自然因素所造成的不安全性</td></tr></tbody></table></div><h5 id="2-保护域"><a href="#2-保护域" class="headerlink" title="2. 保护域"></a>2. 保护域</h5><p>在现代 OS 中，几乎都配置了用于对系统中资源进行保护的保护机制，并引入了“保护域”和“访问权”的概念。规定每一个进程仅能在保护域内执行操作，而且只允许进程访问它们具有“访问权”的对象。<strong>访问权(Access right)</strong>是一个进程能对某对象执行操作的权力。<strong>保护域</strong>是进程对一组对象访问权的集合，进程只能在指定域内执行操作。</p><h5 id="3-文件的保护方式"><a href="#3-文件的保护方式" class="headerlink" title="3. 文件的保护方式"></a>3. 文件的保护方式</h5><p>可以为文件设置一个“<strong>口令</strong>”，用户请求访问该文件时必须提供“口令”。口令一般存放在文件对应的 FCB 或索引结点中，OS 会将用户提供的口令与 FCB 中存储的口令进行对比，如果正确，则允许该用户访问文件。优点是保存口令的空间开销不多，验证口令的时间开销也很小。缺点是正确的“口令”存放在系统内部，不够安全。</p><p>可以使用某个“<strong>密码</strong>”对文件进行加密，在访问文件时需要提供正确的“密码”才能对文件进行正确的解密。优点是保密性强，不需要在系统中存储“密码”，缺点是加密/解密要花费一定时间。</p><p>也可以在每个文件的 FCB(或索引结点)中增加一个<strong>访问控制列表(Acce ss-Control List,ACL)</strong>，该表中记录了各个用户可以对该文件执行哪些操作。精简的访问列表以组为单位，标记各组用户可以对文件执行哪些操作。当某用户想要访问文件时，系统会检查该用户所属的分组是否有相应的访问权限。访问权限一般有：</p><div class="table-container"><table><thead><tr><th>访问权限</th><th>说明</th></tr></thead><tbody><tr><td>读</td><td>从文件中读数据</td></tr><tr><td>写</td><td>向文件中写数据</td></tr><tr><td>执行</td><td>将文件装入内存并执行</td></tr><tr><td>添加</td><td>将新信息添加到文件结尾部分</td></tr><tr><td>删除</td><td>删除文件，释放空间</td></tr><tr><td>列表清单</td><td>列出文件名和文件属性</td></tr></tbody></table></div>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统5：I/O系统</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-5-i-o-xi-tong/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-5-i-o-xi-tong/</url>
      
        <content type="html"><![CDATA[<h1 id="第六章-输入输出系统"><a href="#第六章-输入输出系统" class="headerlink" title="第六章 输入输出系统"></a>第六章 输入输出系统</h1><blockquote><p>I/O系统是OS的重要组成部分，用于管理诸如打印机和扫描仪等I/O设备，以及用于存储数据，如磁盘驱动器和磁带机等各种存储设备。由于I/O系统所含设备类型繁多，差异又非常大，致使I/O系统成为操作系统中最繁杂且与硬件最紧密相关的部分。</p></blockquote><h3 id="6-1-I-O系统的功能、模型和接口"><a href="#6-1-I-O系统的功能、模型和接口" class="headerlink" title="6.1 I/O系统的功能、模型和接口"></a>6.1 I/O系统的功能、模型和接口</h3><p>I/O 系统管理的主要对象是 I/O 设备和相应的设备控制器。其最主要的任务是，完成用户提出的 I/O 请求，提高 I/O 速率，以及提高设备的利用率，并能为更高层的进程方便地使用这些设备提供手段。</p><h5 id="1-I-O系统的基本功能"><a href="#1-I-O系统的基本功能" class="headerlink" title="1. I/O系统的基本功能"></a>1. I/O系统的基本功能</h5><p>为了满足系统和用户的要求，I/O 系统应具有下述几方面的基本功能。</p><div class="table-container"><table><thead><tr><th>功能</th><th>说明</th></tr></thead><tbody><tr><td>隐藏物理设备的细节</td><td>I/O 设备的类型非常多，I/O 系统通过对设备加以适当的抽象，以隐藏掉物理设备的实现细节，仅向上层进程提供少量的、抽象的读/写命令</td></tr><tr><td>与设备的无关性</td><td>用户不仅可以使用抽象的I/O命令，还可使用抽象的逻辑设备名来使用设备</td></tr><tr><td>提高处理机和 I/O 设备的利用率</td><td>尽可能地让处理机和 I/O 设备并行操作，处理机能快速响应用户的 I/O 请求，并尽量减少在 I/O 设备运行时处理机的干预时间</td></tr><tr><td>对 I/O设备进行控制</td><td>目前对 I/O 设备有四种控制方式：采用轮询的可编程 I/O 方式、采用中断的可编程 I/O 方式、直接存储器访问方式、I/O 通道方式</td></tr><tr><td>确保对设备的正确共享</td><td>进程应互斥地访问独占设备，共享设备可以在一段时间内允许多个进程同时访问</td></tr><tr><td>错误处理</td><td>低层软件能够解决的错误就不向上层报告，只有低层软件解决不了的错误才向上层报告，请求高层软件解决</td></tr></tbody></table></div><h5 id="2-I-O软件的层次结构"><a href="#2-I-O软件的层次结构" class="headerlink" title="2. I/O软件的层次结构"></a>2. I/O软件的层次结构</h5><p>通常把 I/O 软件组织成四个层次。<br><img src="source/images/操作系统5：I-O系统/1774310-20210817021013300-701608735.png" alt="img"></p><div class="table-container"><table><thead><tr><th>层次</th><th>说明</th></tr></thead><tbody><tr><td>用户层 I/O 软件</td><td>实现与用户交互的接口，用户可以直接调用该层提供的库函数对设备进行操作</td></tr><tr><td>设备独立性软件</td><td>实现用户程序与设备驱动器的统一接口、设备命名、设备的保护以及设备的分配与释放等，为设备管理和数据传送提供必要的存储空间</td></tr><tr><td>设备驱动程序</td><td>用于具体实现系统对设备发出的操作指令，驱动 I/O 设备工作的驱动程序</td></tr><tr><td>中断处理程序</td><td>用于保存被中断进程的 CPU 环境，转入相应的中断处理程序进行处理，处理完毕再恢复被中断进程的现场后，返回到被中断的进程</td></tr></tbody></table></div><h5 id="3-I-O系统模型"><a href="#3-I-O系统模型" class="headerlink" title="3. I/O系统模型"></a>3. I/O系统模型</h5><p>与前面所述的 I/O 软件组织的层次结构相对应，I/O 系统本身也可分为三个层次。</p><div class="table-container"><table><thead><tr><th>层次</th><th>说明</th></tr></thead><tbody><tr><td>中断处理程序</td><td>处于 I/O 系统的底层，直接与硬件进行交互。当有 I/O 设备发来中断请求信号时，中断处理程序首先保存被中断进程的 CPU 环境，然后转入相应设备的中断处理程序进行处理，在处理完成后又恢复被中断进程的 CPU 环境，返回断点继续运行</td></tr><tr><td>设备驱动程序</td><td>处于 I/O 系统的次底层，是进程和设备控制器之间的通信程序，将上层发来的抽象 I/O 请求转换为对 I/O 设备的具体命令和参数，并把它装入到设备控制器中的命令和参数寄存器中</td></tr><tr><td>设备独立性软件</td><td>实现了与设备无关性，内容包括设备命名、设备分配、数据缓冲和数据高速缓冲一类软件等</td></tr></tbody></table></div><p><img src="source/images/操作系统5：I-O系统/1774310-20210817021649826-170223562.png" alt="img" style="zoom:80%;"><br>由于设备之间的差异很大，每类设备的驱动程序都不相同，故必须由设备制造厂商提供。每当在系统中增加一个新设备时，都需要由安装厂商提供新的驱动程序。这些层次之间有 I/O 系统接口和软件/硬件接口。</p><div class="table-container"><table><thead><tr><th>接口</th><th>说明</th></tr></thead><tbody><tr><td>I/O 系统接口</td><td>I/O 系统与上层系统之间的接口，向上层提供对设备进行操作的抽象 I/O 命令，一些 OS 在用户层提供了与 I/O 操作有关的库函数</td></tr><tr><td>软件/硬件(RW/HW)接口</td><td>在它的上面是中断处理程序和用于不同设备的设备驱动程序，在它的下面是各种设备的控制器</td></tr></tbody></table></div><h5 id="4-I-O系统接口"><a href="#4-I-O系统接口" class="headerlink" title="4. I/O系统接口"></a>4. I/O系统接口</h5><p>在 I/O 系统与高层之间的接口中，根据设备类型的不同，又进一步分为若干个接口，例如块设备接口、流设备接口和网络接口。</p><p>1）块设备接口</p><p><strong>块设备接口</strong>是块设备管理程序与高层之间的接口，用于控制该类设备的输入或输出。块设备是指数据的存取和传输都是以数据块为单位的设备，典型的块设备是磁盘。该设备的基本特征是传输速率较高，并且可寻址。块设备接口将磁盘上的所有扇区从 0 到 n-1 依次编号，n 是磁盘中的扇区总数。这样编号后把磁盘的二维结构改变为一种线性序列，使块设备接口隐藏了磁盘地址是二维结构的情况。块设备接口支持上层发来的对文件或设备的打开、读、写和关闭等抽象命令，将上述命令映射为设备能识别的较低层具体操作。</p><p>虚拟存储器系统也需要使用块设备接口，因为在进程运行期间若所访问的页面不在内存时会发生缺页中断，此时就需要利用 I/O 系统，通过块设备接口从磁盘存储器中将所缺之页面调入内存。</p><p>2）流设备接口</p><p><strong>流设备接口</strong>是流设备管理程序与高层之间的接口，用于控制字符设备的输入或输出。字符设备指数据的存取和传输是以字符为单位的设备，如键盘、打印机等，基本特征是传输速率较低，并且不可寻址，因而对它只能采取顺序存取方式，用户程序获取或输出字符的方法是采用 get 和 put 操作。由于大多数流设备都属于独占设备，必须采取互斥方式实现共享，为此流设备接口提供了打开和关闭操作。</p><p>3）网络通信接口</p><p>在现代 OS 中都提供了面向网络的功能，首先需要通过某种方式把计算机连接到网络上，同时操作系统也必须提供相应的网络软件和<strong>网络通信接口</strong>，使计算机能通过网络与网络上的其它计算机进行通信或上网浏览。</p><h3 id="6-2-I-O设备和设备控制器"><a href="#6-2-I-O设备和设备控制器" class="headerlink" title="6.2 I/O设备和设备控制器"></a>6.2 I/O设备和设备控制器</h3><h5 id="1-I-O设备"><a href="#1-I-O设备" class="headerlink" title="1. I/O设备"></a>1. I/O设备</h5><p>1）I/O设备的概念</p><p>I/O 就是<strong>输入/输出(Input/Output)</strong>，I/O 设备就是可以将数据输入到计算机，或者可以接收计算机输出数据的外部设备，属于计算机中的硬件部件。I/O 设备一般是由执行 I/O 操作的机械部分和执行控制 I/O 的电子部件组成，I/O 设备的<strong>机械部件</strong>主要用来执行具体 I/O 操作，例如鼠标/键盘的按钮、显示器的 LED 屏和移动硬盘的磁臂、磁盘盘面。</p><p>CPU 无法直接控制 I/O 设备的机械部件，因此 I/O 设备还要有一个<strong>电子部件</strong>作为 CPU 和 I/O 设备机械部件之间的“中介”，用于实现 CPU 对设备的控制。这个电子部件就是 I/O 控制器，又称设备控制器，通常是一块插入主板扩充槽的印刷电路板。CPU 可控制 I/O 控制器，又由 I/O 控制器来控制设备的机械部件。</p><p>2）I/O设备的类型</p><p>I/O 设备的类型繁多，除了能将它们分为块设备和字符设备、独占设备和共享设备外，还可按使用特性分类和按传输速率分类。按使用特性分类的第一类是存储设备，也称外存、辅存，用以存储信息，存取速度较内存慢但容量大且价格便宜。第二类就是 I/O 设备，它又可分为输入设备、输出设备和交互式设备。</p><div class="table-container"><table><thead><tr><th>设备类型</th><th>说明</th></tr></thead><tbody><tr><td>输入设备</td><td>用来接收外部信息，如键盘、鼠标、扫描仪、视频摄像等</td></tr><tr><td>输出设备</td><td>用于将计算机处理后的信息送向处理机外部的设备，如打印机、绘图仪等</td></tr><tr><td>交互式设备</td><td>则是指集成的上述两类设备，用于同步显示用户命令以及命令执行的结果</td></tr></tbody></table></div><p>按传输速度的高低，可将 I/O 设备分为三类。</p><div class="table-container"><table><thead><tr><th>设备类型</th><th>说明</th></tr></thead><tbody><tr><td>低速设备</td><td>传输速率仅为每秒钟几个字节至数百个字节，例如键盘、鼠标器</td></tr><tr><td>中速设备</td><td>传输速率在每秒钟数千个字节至数十万个字节，例如行式打印机、激光打印机等</td></tr><tr><td>高速设备</td><td>传输速率在数十万字节至千兆字节，例如磁带机、磁盘机、光盘机等</td></tr></tbody></table></div><p>3）设备与控制器之间的接口</p><p>通常设备并不是直接与 CPU 进行通信，而是与设备控制器通信，因此在 I/O 设备中应含有与设备控制器间的接口.<br><img src="source/images/操作系统5：I-O系统/1774310-20210816154944836-57335558.png" alt="img"><br>在该接口中有三种类型的信号，各对应一条信号线。</p><div class="table-container"><table><thead><tr><th>信号线</th><th>说明</th></tr></thead><tbody><tr><td>数据信号线</td><td>在设备和设备控制器之间传送数据信号</td></tr><tr><td>控制信号线</td><td>由设备控制器向 I/O 设备发送控制信号时的通路，信号规定了设备将要执行的操作，如读操作、写操作或执行磁头移动等操作</td></tr><tr><td>状态信号线</td><td>该信号线用于传送指示设备当前状态的信号，状态有正在读(或写)、设备已读(写)完成</td></tr></tbody></table></div><h5 id="2-设备控制器"><a href="#2-设备控制器" class="headerlink" title="2. 设备控制器"></a>2. 设备控制器</h5><p>设备控制器的主要功能是控制一个或多个 I/O 设备，以实现 I/O 设备和计算机之间的数据交换。它接收从 CPU 发来的命令，去控制 I/O 设备工作。设备控制器是一个可编址的设备，当它仅控制一个设备时只有一个唯一的设备地址，若控制器可连接多个设备则含有多个设备地址，每一个设备地址对应一个设备。可把设备控制器分成两类：一类是用于控制字符设备的控制器，另一类是用于控制块设备的控制器。</p><p>1）设备控制器的基本功能</p><div class="table-container"><table><thead><tr><th>功能</th><th>说明</th></tr></thead><tbody><tr><td>接收和识别命令</td><td>接收并识别处理机发来的多种命令，利用控制寄存器存放接收的命令和参数，并对所接收的命令进行译码</td></tr><tr><td>数据交换</td><td>实现 CPU 与控制器之间、控制器与设备之间的数据交换，前者通过数据总线，后者是通过数据寄存器</td></tr><tr><td>标识和报告设备的状态</td><td>控制器应记下设备的状态供 CPU 了解，在控制器中应设置状态寄存器，用其中的一位反映设备的状态</td></tr><tr><td>地址识别</td><td>系统中的每一个设备都有一个地址，设备控制器必须能够识别其所控制的每个设备的地址，应配置地址译码器</td></tr><tr><td>数据缓冲区</td><td>由于 I/O 设备的速率较低，而 CPU 和内存的速率却很高，故在控制器中必须设置缓冲区</td></tr><tr><td>差错控制</td><td>对于由 I/O 设备传送来的数据，若发现传送中出现了错误，通常是将差错检测码置位并向 CPU 报告</td></tr></tbody></table></div><p>2）设备控制器的组成</p><p>设备控制器位于 CPU 与设备之间，既要与 CPU 通信又要与设备通信，还应具有按照 CPU 所发来的命令去控制设备工作的功能。<br><img src="source/images/操作系统5：I-O系统/1774310-20210816235322808-130950127.png" alt="img"></p><div class="table-container"><table><thead><tr><th>组件</th><th>说明</th></tr></thead><tbody><tr><td>设备控制器与处理机的接口</td><td>用于实现 CPU 与设备控制器之间的通信，在该接口中共有三类信号线：数据线、地址线和控制线</td></tr><tr><td>设备控制器与设备的接口</td><td>设备控制器上可以连接多个设备，便有多个设备接口。在每个接口中都存在数据、控制和状态三种类型的信号</td></tr><tr><td>I/O 逻辑</td><td>用于实现对设备的控制，它通过一组控制线与处理机交互，处理机利用该逻辑向控制器发送 I/O 命令。</td></tr></tbody></table></div><p>数据线通常与两类寄存器相连接，第一类是数据寄存器，用于存放从设备送来的数据(输入)或从 CPU 送来的数据(输出)。第二类是控制/状态寄存器，用于存放从CPU送来的控制信息或设备的状态信息。</p><h5 id="3-内存映像I-O"><a href="#3-内存映像I-O" class="headerlink" title="3. 内存映像I/O"></a>3. 内存映像I/O</h5><p>驱动程序将抽象 I/O 命令转换出的一系列具体的命令、参数等数据装入设备控制器的相应寄存器，由控制器来执行这些命令实施对 I/O 设备的控制。这一工作在早期的计算机中利用特定的 I/O 指令实现，为每个控制寄存器分配一个 I/O 端口并设置了一些特定的 I/O 指令。该方法的主要缺点是，访问内存和访问设备需要两种不同的指令。</p><p>现在采用的是<strong>内存映像I/O</strong>，这种方式中在编址上不再区分内存单元地址和设备控制器中的寄存器地址，而是设置一个 k 值。当 k 值处于 0 ~ n-1 范围时被认为是内存地址，若 k ≥ n 时被认为是某个控制器的寄存器地址。内存映像 I/O 方式统一了对内存和对控制器的访问方法，简化 I/O 的编程。<br><img src="source/images/操作系统5：I-O系统/1774310-20210817001517776-1573851700.png" alt="img" style="zoom:80%;"></p><h5 id="4-I-O通道"><a href="#4-I-O通道" class="headerlink" title="4. I/O通道"></a>4. I/O通道</h5><p>1）I/O通道设备的引入</p><p>虽然在 CPU 与 I/O 设备之间增加了设备控制器后能减少 CPU 对 I/O 的干预，但当主机所配置的外设很多时 CPU 的负担仍然很重。为此在 CPU 和设备控制器之间又增设了<strong>I/O 通道(I/O Channel)</strong>。主要目的是使一些原来由 CPU 处理的 I/O 任务转由通道来承担，从而把 CPU 从繁杂的 I/O 任务中解脱出来。</p><p>在设置了通道后，CPU 只需向通道发送一条 I/O 指令，通道从内存中取出本次要执行的通道程序然后执行。仅当通道完成了规定的 I/O 任务后，才向 CPU 发中断信号。实际上 I/O 通道是一种特殊的处理机，它具有执行 I/O 指令的能力，通过执行通道 I/O 程序来控制 I/ O操作。但 I/O 通道的指令类型单一，且没有自己的内存。</p><p>2）通道类型</p><p>外围设备的类型较多，传输速率相差甚大，因而使通道具有多种类型。根据信息交换方式的不同，可把通道分成以下三种类型。</p><div class="table-container"><table><thead><tr><th>通道</th><th>说明</th></tr></thead><tbody><tr><td>字节多路通道(Byte Multiplexor Channel)</td><td>按字节交叉方式工作的通道，通常都含有许多非分配型子通道，按时间片轮转方式共享主通道，当第一个子通道控制其 I/O 设备完成一个字节的交换后，便立即腾出主通道让给第二个子通道使用</td></tr><tr><td>数组选择通道(Block Selector Channel)</td><td>按数组方式进行数据传送的数组选择通道，可以连接多台高速设备，但它只含有一个分配型子通道，在一段时间内只能执行一道通道程序</td></tr><tr><td>数组多路通道(Block Multiplexor Channel)</td><td>将数组选择通道传输速率高和字节多路通道能使各子通道（设备）分时并行操作的优点相结合，它含有多个非分配型子通道，既具有很高的数据传输速率，又能获得令人满意的通道利用率</td></tr></tbody></table></div><p>3）瓶颈问题</p><p>由于通道价格昂贵，致使机器中所设置的通道数量势必较少，这往往又使它成了 I/O 的瓶颈，进而造成整个系统吞吐量的下降。例如在图中如果要使用设备 1 需要占用通道 1 和控制器 1，但此时如果还要使用设备 2，会因为通道和控制器数量不足而无法使用。<br><img src="source/images/操作系统5：I-O系统/1774310-20210817212744859-1038958435.png" alt="img" style="zoom:80%;"><br>解决“瓶颈”的方法是增加设备到主机间的通路而不增加通道，也就是把一个设备连接到多个控制器上，而一个控制器又连接到多个通道上。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第六章 输入输出系统/1774310-20210817213147966-1693788286.png" alt="img" style="zoom:80%;"></p><h3 id="6-3-中断机构和中断处理程序"><a href="#6-3-中断机构和中断处理程序" class="headerlink" title="6.3 中断机构和中断处理程序"></a>6.3 中断机构和中断处理程序</h3><p>中断在操作系统是多道程序得以实现的基础，，因为进程之间的切换是通过中断来完成的。中断也是设备管理的基础，为了提高处理机的利用率和实现 CPU 与 I/O 设备并行执行，也必需有中断的支持。<br><img src="source/images/操作系统5：I-O系统/1774310-20210819164220325-1254783628-16617400062634.png" alt="img" style="zoom:80%;"></p><h5 id="1-中断简介"><a href="#1-中断简介" class="headerlink" title="1. 中断简介"></a>1. 中断简介</h5><p>1）中断和陷入</p><p><strong>中断</strong>是指 CPU 对 I/O 设备发来的中断信号的一种响应，CPU 暂停正在执行的程序，保留 CPU 环境后，自动地转去执行该 I/O 设备的中断处理程序。执行完后再回到断点，继续执行原来的程序。I/O 设备可以是字符设备，也可以是块设备、通信设备等。由于中断是由外部设备引起的，故又称外中断。</p><p>另外还有一种由 CPU 内部事件所引起的中断，通常把这类中断称为内中断或<strong>陷入(trap)</strong>。若系统发现了有陷入事件，CPU 也将暂停正在执行的程序，转去执行该陷入事件的处理程序。中断和陷入的主要区别是信号的来源，即是来自 CPU 外部还是 CPU 内部。</p><p>2）中断向量表</p><p>为了处理上的方便，通常是为每种设备配以相应的中断处理程序，并把该程序的入口地址放在<strong>中断向量表</strong>的一个表项中。每一个设备的中断请求规定一个中断号，它直接对应于中断向量表的一个表项中。当 I/O 设备发来中断请求信号时，由中断控制器确定该请求的中断号，根据中断号去查找中断向量表取得中断处理程序的入口地址。经常会有多个中断信号源，每个中断源对服务要求的紧急程度并不相同，为此系统就需要为它们分别规定不同的优先级。</p><p>3）对多中断源的处理方式</p><p>当处理机正在处理一个中断时，如果又来了一个新的中断请求，可有两种处理方式：屏蔽(禁止)中断与嵌套中断。<strong>屏蔽(禁止)中断</strong>当处理机正在处理一个中断时，将屏蔽掉所有的中断，即处理机对任何新到的中断请求，都暂时不予理睬，而让它们等待。其优点是简单，但不能用于对实时性要求较高的中断请求。<br><strong>嵌套中断</strong>是在设置了中断优先级的系统中，通常按这样的规则来进行优先级控制：</p><ol><li>当同时有多个不同优先级的中断请求时，CPU 优先响应最高优先级的中断请求；</li><li>高优先级的中断请求可以抢占正在运行的低优先级中断的处理机。</li></ol><h5 id="2-中断处理程序"><a href="#2-中断处理程序" class="headerlink" title="2. 中断处理程序"></a>2. 中断处理程序</h5><p>当一个进程请求 I/O 操作时，该进程将被挂起，直到 I/O 设备完成 I/O 操作后，设备控制器便向 CPU 发送一个中断请求，CPU 响应后便转向中断处理程序执行相应的处理，处理完后解除相应进程的阻塞状态。中断处理程序的处理过程可分成以下几个步骤：</p><ol><li>测定是否有未响应的中断信号：若没有继续执行下一条指令，若有则停止原有进程的执行，准备转去执行中断处理程序；</li><li>保护被中断进程的 CPU 环境：先保护被中断进程的 CPU 环境，以便以后能恢复运行；</li><li>转入相应的设备处理程序：确定引起本次中断的 I/O 设备，并向提供中断信号的设备发送确认信号；</li><li>中断处理：对不同的设备，有不同的中断处理程序；</li><li>恢复 CPU 的现场并退出中断：当中断处理完成以后，需要恢复 CPU 的现场，退出中断。</li></ol><p>I/O 操作完成后，驱动程序必须检查本次 I/O 操作中是否发生了错误，最终向调用者报告本次 I/O 的执行情况。</p><h3 id="6-4-设备驱动程序"><a href="#6-4-设备驱动程序" class="headerlink" title="6.4 设备驱动程序"></a>6.4 设备驱动程序</h3><p><strong>设备处理程序</strong>通常又称为设备驱动程序，它是 I/O 系统的高层与设备控制器之间的通信程序。其主要任务是接收上层软件发来的抽象 I/O 要求，再把它转换为具体要求后，发送给设备控制器启动设备执行。同时它也将由设备控制器发来的信号传送给上层软件。</p><p><img src="source/images/操作系统5：I-O系统/1774310-20210819164237263-506181890.png" alt="img" style="zoom:80%;"></p><h5 id="1-设备驱动程序的功能"><a href="#1-设备驱动程序的功能" class="headerlink" title="1. 设备驱动程序的功能"></a>1. 设备驱动程序的功能</h5><p>为了实现 I/O 系统的高层与设备控制器之间的通信，设备驱动程序应具有以下功能：</p><ol><li>接收由与设备无关的软件发来的命令和参数，并将命令中的抽象要求转换为与设备相关的低层操作序列。</li><li>检查用户 I/O 请求的合法性，了解 I/O 设备的工作状态，传递与 I/O 设备操作有关的参数，设置设备的工作方式。</li><li>发出 I/O 命令，如果设备空闲便立即启动 I/O 设备并执行，如果设备忙碌则将请求者的请求块挂在设备队列上等待。</li><li>及时响应由设备控制器发来的中断请求，并根据其中断类型，调用相应的中断处理程序进行处理。</li></ol><h5 id="2-设备驱动程序的特点"><a href="#2-设备驱动程序的特点" class="headerlink" title="2. 设备驱动程序的特点"></a>2. 设备驱动程序的特点</h5><p>设备驱动程序属于低级的系统例程，它与一般的应用程序及系统程序之间有下述明显差异：</p><ol><li>实现在与设备无关的软件和设备控制器之间通信和转换的程序；</li><li>对于不同类型的设备，应配置不同的驱动程序，但可以为相同的多个终端设置终端驱动程序。</li><li>驱动程序与 I/O 设备所采用的 I/O 控制方式紧密相关；</li><li>其中的一部分必须用汇编语言书写，目前很多驱动程序的基本部分固化在 ROM 中；</li><li>一个正在运行的驱动程序常会在一次调用完成前被再次调用。</li></ol><h5 id="3-设备处理方式"><a href="#3-设备处理方式" class="headerlink" title="3. 设备处理方式"></a>3. 设备处理方式</h5><p>在不同的操作系统中，所采用的设备处理方式并不完全相同。设备处理方式分成以下三类，目前来说第三类用的比较多。</p><ol><li>为每一类设备设置一个进程，专门用于执行这类设备的 I/O 操作；</li><li>在整个系统中设置一个 I/O 进程，专门用于执行系统中所有各类设备的 I/O 操作；</li><li>不设置专门的设备处理进程，而只为各类设备设置相应的设备驱动程序，供用户或系统进程调用。</li></ol><h5 id="4-设备驱动程序的处理过程"><a href="#4-设备驱动程序的处理过程" class="headerlink" title="4. 设备驱动程序的处理过程"></a>4. 设备驱动程序的处理过程</h5><p>设备驱动程序的主要任务是启动指定设备，完成上层指定的 I/O 工作。以下是设备驱动程序的处理过程：</p><ol><li>将抽象要求转换为具体要求；</li><li>对服务请求进行校验：驱动程序在启动 I/O 设备之前，必须先检查该用户的I/O请求是不是该设备能够执行的；</li><li>检查设备的状态：启动某个设备进行 I/O 操作，其前提条件应是该设备正处于就绪状态；</li><li>传送必要的参数：可向控制器的相应寄存器传送数据及与控制本次数据传输有关的参数；</li><li>启动 I/O 设备：在完成上述各项准备工作后，驱动程序便可以向控制器中的命令寄存器传送相应的控制命令。</li></ol><p>在多道程序系统中，驱动程序一旦发出 I/O 命令，启动了一个 I/O 操作后，驱动程序便把控制返回给 I/O 系统把自己阻塞起来，直到中断到来时再被唤醒。具体的 I/O 操作是在设备控制器的控制下进行的，因此在设备忙于传送数据时，处理机又可以去干其它的事情。</p><h5 id="5-对I-O设备的控制方式"><a href="#5-对I-O设备的控制方式" class="headerlink" title="5. 对I/O设备的控制方式"></a>5. 对I/O设备的控制方式</h5><p>在 I/O 控制方式的整个发展过程中，始终贯穿着这样一条宗旨：尽量减少主机对 I/O 控制的干预，把主机从繁杂的 I/O 控制事务中解脱。</p><p>1）<strong>使用轮询的可编程I/O方式</strong></p><p>对设备的控制，早期是<strong>轮询的可编程 I/O 方式</strong>。在处理机向控制器发出一条 I/O 指令，启动输入设备输入数据时，要同时把状态寄存器中的忙/闲标志 busy 置为 1，然后便不断地循环测试 busy(称为轮询)。当 busy = 1 时表示输入机尚未输完一个字(符)，处理机应继续对该标志进行测试。直至 busy = 0，表明输入机已将输入数据送入控制器的数据寄存器中。于是处理机将数据寄存器中的数据取出，送入内存指定单元中，这样便完成了一个字(符)的 I/O。</p><p><img src="source/images/操作系统5：I-O系统/1774310-20220120141847017-486559252.png" alt="img" style="zoom: 67%;"><br>使用轮询的可编程 I/O 方式的优点是实现简单，在读/写指令之后，加上实现循环检查的一系列指令即可。缺点是 CPU 和 I/O 设备只能串行工作，CPU 需要一直轮询检查，长期处于“忙等”状态，CPU 利用率低。</p><p>2）<strong>使用中断的可编程I/O方式</strong></p><p>当前对 I/O 设备的控制，广泛采用<strong>中断的可编程 I/O 方式</strong>。当某进程要启动某个 I/O 设备工作时，便由 CPU 向相应的设备控制器发出一条 I/O 命令，然后立即返回继续执行原来的任务。设备控制器于是按照该命令的要求去控制指定 I/O 设备，此时 CPU 与 I/O 设备并行操作。<br><img src="source/images/操作系统5：I-O系统/1774310-20210819210356073-1831600656.png" alt="img" style="zoom: 67%;"><br>仅当输完一个数据时，才需 CPU 花费极短的时间去做些中断处理。这样可使 CPU 和 I/O 设备都处于忙碌状态，从而提高了整个系统的资源利用率及吞吐量。例如，从终端输入一个字符的时间约为 100ms，而将字符送入终端缓冲区的时间小于 0.1ms。若采用程序 I/O 方式，CPU 约有 99.9ms 的时间处于忙一等待中。但采用中断驱动方式后，CPU 可利用这 99.9ms 的时间去做其它的事情。该方法的缺点是每个字在 I/O 设备与内存之间的传输，都需要经过 CPU，频繁的中断处理会消耗较多的 CPU 时间。</p><p>3）轮询和中断的比较</p><p>中断令 CPU 不再需要不断轮询设备，而是向设备发出一个请求，然后就可以让对应进程睡眠，切换执行其他任务。当设备完成了自身操作，会抛出一个硬件中断，引发 CPU 跳转执行操作系统预先定义好的中断处理程序（interrupt handler)。中断允许计算与 I/O 重叠（overlap），这是提高 CPU 利用率的关键，操作系统可以令 CPU 在 I/O 操作时去做其他事情。</p><p>但使用中断并非总是最佳方案，假如有一个非常高性能的设备，它处理请求很快，通常在 CPU 第一次轮询时就可以返回结果。此时如果使用中断，反而会使系统变慢：切换到其他进程处理中断，再切换回之前的进程代价不小。另一个最好不要使用中断的场景是网络，网络端收到大量数据包，如果每一个包都发生一次中断，那么有可能导致操作系统发生活锁。</p><p><img src="source/images/操作系统5：I-O系统/1774310-20220120142134639-175952445.png" alt="img" style="zoom:80%;"></p><p>因此如果设备非常快，那么最好的办法反而是轮询，如果设备比较慢，那么采用允许发生重叠的中断更好。如果设备的速度未知，或者时快时慢，可以考虑使用<strong>混合（hybrid）策略</strong>，先尝试轮询一小段时间，如果设备没有完成操作，此时再使用中断。另一个基于中断的优化就是<strong>合并（coalescing)</strong>，设备在抛出中断之前往往会等待一小段时间，在此期间，其他请求可能很快完成，因此多次中断可以合并为一次中断抛出，从而降低处理中断的代价。</p><p>4）<strong>直接存储器访问方式</strong></p><p>虽然中断驱动 I/O 比程序 I/O 方式更有效，但它仍是以字(节)为单位进行 I/O 的。采用中断驱动 I/O 方式时的 CPU，是以字(节)为单位进行干预的。如果将这种方式用于块设备的 I/O，显然是极其低效的。与中断驱动方式相比，<strong>DMA (Direct Memory Access)直接存储器存取方式</strong>有这样几个改进：</p><ol><li>数据的传送单位是“块”,不再是一个字、一个字的传送；</li><li>数据的流向是从设备直接放入内存，或者从内存直接到设备，不再需要经过 CPU；</li><li>仅在传送一个或多个数据块的开始和结束时，才需要 CPU 干预。</li></ol><p>当给 I/O 模块发送命令时，CPU 指明此次要进行的操作，并说明要读入多少数据、数据要存放在内存的什么位置数据在外部设备上的地址。控制器会根据 CPU 提出的要求完成数据的读/写工作，整块数据的传输完成后，才向 CPU 发出中断信号。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第六章 输入输出系统/1774310-20210819225213642-1022344760.png" alt="img" style="zoom:80%;"><br>DMA 控制器由三部分组成：主机与 DMA 控制器的接口、DMA 控制器与块设备的接口、I/O 控制逻辑。<br><img src="source/images/操作系统5：I-O系统/1774310-20210820022350493-1904886397.png" alt="img" style="zoom:80%;"></p><div class="table-container"><table><thead><tr><th>组件</th><th>说明</th></tr></thead><tbody><tr><td>DR(Data Register，数据寄存器)</td><td>暂存从设备到内存，或从内存到设备的数据</td></tr><tr><td>MAR(Memory Address Register，内存地址寄存器)</td><td>在输入时 MAR 表示数据应放到内存中的什么位置，输出时 MAR 表示要输出的数据放在内存中的什么位置</td></tr><tr><td>DC(Data Counter，数据计数器)</td><td>表示剩余要读/写的字节数。</td></tr><tr><td>CR(Command Register，命令/状态寄存器)</td><td>用于存放 CPU 发来的 I/O 命令，或设备的状态信息</td></tr></tbody></table></div><p>DMA 的优点是数据传输以“块”为单位，CPU 介入频率进一步降低。数据的传输不再需要先经过C PU 再写入内存，数据传输效率进一步增加，CPU 和 I/O 设备的并行性得到提升。缺点是 CPU 每发出一条 I/O 指令，只能读/写一个或多个连续的数据块。</p><p>5）I/O通道控制方式</p><p><strong>I/O 通道方式</strong>是 DMA 方式的发展，它把对一个数据块的读（或写）为单位的干预，减少为对一组数据块的读（或写）及有关的控制和管理为单位的干预。同时，又可实现 CPU、通道和 I/O 设备三者的并行操作，从而更有效地提高整个系统的资源利用率。不过实现复杂，需要专门的通道硬件支持。<br>例如当 CPU 要完成一组相关的读(或写)操作及有关控制时，只需向 I/O 通道发送一条 I/O 指令，以给出其所要执行的通道程序的首址和要访问的 I/O 设备。通道接到该指令后，通过执行通道程序便可完成 CPU 指定的 I/O 任务。</p><h3 id="6-5-与设备无关的I-O软件"><a href="#6-5-与设备无关的I-O软件" class="headerlink" title="6.5 与设备无关的I/O软件"></a>6.5 与设备无关的I/O软件</h3><p>为了方便用户和提高 OS 的可适应性与可扩展性，在现代 OS 的 I/O 系统中都增加了与设备无关的 I/O 软件，以实现<strong>设备独立性(设备无关性)</strong>。其基本含义是：应用程序中所用的设备，不局限于使用某个具体的物理设备。为了实现设备独立性，必须再在设备驱动程序之上设置一层软件，称为与<strong>设备无关的 I/O 软件(设备独立性软件)</strong>。<br><img src="source/images/操作系统5：I-O系统/1774310-20210819204141426-699152094.png" alt="img" style="zoom:80%;"></p><h5 id="1-引入设备独立性软件的动机"><a href="#1-引入设备独立性软件的动机" class="headerlink" title="1. 引入设备独立性软件的动机"></a>1. 引入设备独立性软件的动机</h5><p>在早期 OS 中，应用程序在使用 I/O 设备时都使用设备的<strong>物理名称</strong>，这使应用程序与系统中的物理设备直接相关。当应用进程运行时，如果所请求的物理设备(独占设备类型)已分配给其它进程，系统无法将另外相同的设备(物理设备名不同)分配给它，致使该应用进程请求 I/O 失败而被阻塞。当应用程序所需要的设备在系统中已经被更新时，该应用程序将再也无法在该系统上运行。可见应用程序直接与物理设备相关是不灵活的，I/O 设备的利用率低。</p><p>为了实现与设备的无关性而引入了逻辑设备和物理设备两个概念，<strong>逻辑设备</strong>是抽象的设备名，并没有指定具体的设备。只要系统中有一台该类设备未被分配，进程就不会被阻塞。与设备的无关软件还可实现 <strong>I/O 重定向</strong>，是指用于 I/O 操作的设备可以更换，而不必改变应用程序。</p><h5 id="2-与设备无关的软件实现"><a href="#2-与设备无关的软件实现" class="headerlink" title="2. 与设备无关的软件实现"></a>2. 与设备无关的软件实现</h5><p>在与设备无关的软件中，包括了执行所有设备公有操作的软件，具体有如下几项。</p><div class="table-container"><table><thead><tr><th>功能</th><th>说明</th></tr></thead><tbody><tr><td>设备驱动程序的统一接口</td><td>要求每个设备驱动程序与 OS 之间都有着相同或者相近的接口，使添加一个新的设备驱动程序变得很容易</td></tr><tr><td>缓冲管理</td><td>为了缓和 CPU 和 I/O 设备之间的速率矛盾，需要为设备配置相应的缓冲区</td></tr><tr><td>差错控制</td><td>设备中的机械和电气部分比主机更容易出现故障，因此需要对差错进行处理</td></tr><tr><td>对独立设备的分配与回收</td><td>为了避免诸进程对独占设备的争夺，必须由系统来统一分配，不允许进程自行使用</td></tr><tr><td>独立于设备的逻辑数据块</td><td>不同类型的设备的数据交换单位和读取、传输速率相同，设备独立性软件应能够隐藏这些差异</td></tr></tbody></table></div><p>其中设备的错误可分为如下两类：</p><div class="table-container"><table><thead><tr><th>设备错误</th><th>说明</th></tr></thead><tbody><tr><td>暂时性错误</td><td>因发生暂时性事件引起的，如电源的波动，可以通过重试操作来纠正</td></tr><tr><td>持久性错误</td><td>由持久性故障引起的，如电源掉电、磁盘上有划痕或者在计算中发生除以零的情况等</td></tr></tbody></table></div><h5 id="3-设备分配"><a href="#3-设备分配" class="headerlink" title="3. 设备分配"></a>3. 设备分配</h5><p>“设备、控制器、通道”之间的关系是一个通道可控制多个设备控制器，每个设备控制器可控制多个设备。<br><img src="source/images/操作系统5：I-O系统/1774310-20210820025132931-942813006.png" alt="img" style="zoom:80%;"></p><p>1）设备分配中的数据结构</p><p>系统为实现对独占设备的分配，必须在系统中配置相应的数据结构，记录了对设备或控制器进行控制所需的信息。系统为每一个设备都配置了一张<strong>设备控制表 DCT</strong>，用于记录设备的情况。<br><img src="source/images/操作系统5：I-O系统/1774310-20210820025621379-341731087.png" alt="img" style="zoom: 67%;"></p><div class="table-container"><table><thead><tr><th>字段</th><th>说明</th></tr></thead><tbody><tr><td>设备队列队首指针</td><td>凡因请求本设备而未得到满足的进程，应将其 PCB 按照一定的策略排成一个设备请求队列</td></tr><tr><td>忙/闲标志</td><td>用于表示当前设备的状态是忙或闲</td></tr><tr><td>与设备连接的控制器表指针</td><td>指向该设备所连接的控制器的控制表</td></tr><tr><td>重复执行次数</td><td>设备在工作中发生错误时应重复执行的次数</td></tr></tbody></table></div><p>系统为每一个控制器都设置了用于记录控制器情况的控制器控制表 COCT。<br><img src="source/images/操作系统5：I-O系统/1774310-20210820030046214-1979827491.png" alt="img" style="zoom: 67%;"><br>每个通道都有一张通道控制表 CHCT。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第六章 输入输出系统/1774310-20210820030032898-1238913160.png" alt="img" style="zoom: 67%;"><br>系统设备表 SDT 是系统范围的数据结构，记录了系统中全部设备的情况，每个设备占一个表目，其中包括有设备类型、设备标识符、设备控制表及设备驱动程序的入口等项。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第六章 输入输出系统/1774310-20210820030227616-1370170149.png" alt="img" style="zoom: 67%;"></p><h5 id="4-设备名映射"><a href="#4-设备名映射" class="headerlink" title="4. 设备名映射"></a>4. 设备名映射</h5><p>当应用程序请求使用 I/O 设备时应当用逻辑设备名。但系统只识别物理设备名，因此在系统中需要配置一张逻辑设备表，用于将逻辑设备名映射为物理设备名。<strong>逻辑设备表 LUT(Logical Unit Table)</strong>的每个表目中包含了三项：逻辑设备名、物理设备名和设备驱动程序的入口地址。当进程用逻辑设备名请求分配 I/O 设备时，系统为它分配一台相应的物理设备，并在逻辑设备表上建立一个表目。当以后进程再利用该逻辑设备名请求 I/O 操作时，系统通过查找 LUT 可找到该逻辑设备所对应的物理设备和该设备的驱动程序。<br><img src="source/images/操作系统5：I-O系统/1774310-20210819181247236-1307404576.png" alt="img" style="zoom: 80%;"></p><p>在系统中可采取两种方式设置逻辑设备表，第一种方式是在整个系统中只设置一张 LUT。由于系统中所有进程的设备分配情况都记录在同一张 LUT 中，因而不允许在 LUT 中具有相同的逻辑设备名，在多用户环境下这通常是难以做到的。第二种方式是为每个用户设置一张 LUT，每当用户登录时，系统便为该用户建立一个进程，同时也为之建立一张 LUT 放入进程的 PCB 中。</p><h3 id="6-6-用户层的I-O软件"><a href="#6-6-用户层的I-O软件" class="headerlink" title="6.6 用户层的I/O软件"></a>6.6 用户层的I/O软件</h3><p>大部分的 I/O 软件都放在操作系统内部，但仍有一小部分在用户层，其中包括与用户程序链接在一起的库函数和假脱机系统。<br><img src="source/images/操作系统5：I-O系统/1774310-20210819204210423-1198590960.png" alt="img" style="zoom:80%;"></p><h5 id="1-系统调用与库函数"><a href="#1-系统调用与库函数" class="headerlink" title="1. 系统调用与库函数"></a>1. 系统调用与库函数</h5><p>为使诸进程能有条不紊地使用 I/O 设备，且能保护设备的安全性，不允许运行在用户态的应用进程去直接调用运行在核心态（系统态）的 OS 过程。但另一方面，应用进程在运行时，又必须取得 OS 所提供的服务。为了解决此矛盾，OS 在用户层中引入了<strong>系统调用</strong>，应用程序可以通过它间接调用 OS 中的 I/O 过程。</p><p>当应用程序需要执行某种 I/O 操作时，在应用程序中必须使用相应的系统调用。当 OS 捕获到应用程序中的该系统调用后，便将 CPU 的状态从用户态转换到核心态，然后转向操作系统中相应过程，由该过程完成所需的 I/O 操作。执行完成后，系统又将 CPU 状态从核心态转换到用户态，返回到应用程序继续执行。<br><img src="source/images/操作系统5：I-O系统/1774310-20210819182231142-822961341.png" alt="img" style="zoom:80%;"></p><p>在早期的操作中，系统调用是以汇编语言形式提供的，所以只有在用汇编语言编写的程序中，才能直接使用系统调用。后来在 C 语言中，首先提供了与系统调用相对应的<strong>库函数</strong>。库函数对于 I/O 方面，主要是对文件和设备进行读/写的库函数，以及控制/检查设备状态的库函数。</p><h5 id="2-假脱机-Spooling-系统"><a href="#2-假脱机-Spooling-系统" class="headerlink" title="2. 假脱机(Spooling)系统"></a>2. 假脱机(Spooling)系统</h5><p>通过SPOOLing技术可将<strong>一台物理I/O设备虚拟为多台逻辑I/O设备</strong>，允许多个用户共享一台物理I/O设备。</p><p>为了缓和CPU的高速性和I/O设备的低速性间的矛盾而引入的脱机输入、脱机输出技术，该技术是利用专门的外围控制机，将低速I/O设备上的数据传送到高速磁盘上，或者相反。事实上，当系统中引入了多道程序技术后，可以利用其中的一道程序，来模拟脱机输入时的外围控制机的功能，把低速I/O设备上的数据传送到高速磁盘上，再利用另一道程序来模拟脱机输出时外围控制机的功能，把数据从磁盘上传送到低速输出设备上，这样，便可在主机的直接控制下，实现脱机输入、输出的功能。此时的外围操作与CPU对数据的处理同时进行，我们把这种在联机情况下实现的同时外围操作称为SPOOLing，或称为假脱机操作。</p><p><strong>假脱机(SPOOLing)技术</strong>，则可将一台物理 I/O 设备虚拟为多台逻辑 I/O 设备，这样就允许多个用户共享一台物理 I/O 设备。SPOOLing 的系统组成如下：<br><img src="source/images/操作系统5：I-O系统/1774310-20210819190316452-1196316619.png" alt="img" style="zoom:80%;"></p><div class="table-container"><table><thead><tr><th>组成部分</th><th>说明</th></tr></thead><tbody><tr><td>输入井</td><td>在磁盘上开辟出来的存储区域，输入井模拟脱机输入时的磁盘，用于收容 I/O 设备输入的数据</td></tr><tr><td>输出井</td><td>在磁盘上开辟出来的存储区域，输出井模拟脱机输出时的磁盘，用于收容用户程序的输出数据</td></tr><tr><td>输入缓冲区</td><td>在内存上开辟出来的存储区域，用于暂存由输入设备传送的数据，之后再传送到输入井</td></tr><tr><td>输出缓冲区</td><td>在内存上开辟出来的存储区域，用于暂存从输出井传送的数据，之后再传送到输出设备</td></tr><tr><td>输入进程</td><td>用于模拟脱机输入时的外围控制机，将用户要求的数据从输入设备传送到输入缓冲区</td></tr><tr><td>输出进程</td><td>用于模拟脱机输出时的外围控制机，将输出井中的数据经过输出缓冲区输出至输出设备上</td></tr><tr><td>井管理程序</td><td>用于控制作业与磁盘井之间信息的交换</td></tr></tbody></table></div><p>SPOOLing 系统有以下特点：</p><ol><li>提高了 I/O 的速度：从对低速 I/O 设备执行的 I/O 操作演变为对磁盘缓冲区中数据的存取；</li><li>将独占设备改造为共享设备；</li><li>实现了虚拟设备功能：宏观上虽然是多个进程在同时使用一台独占设备，而对于每一个进程而言，它们都会认为自己是独占了一个设备。</li></ol><p>假脱机打印机系统：</p><p>打印机是经常用到的输出设备，属于独占设备，利用假脱机技术可将它改造为一台可供多个用户共享的打印设备。假脱机打印系统主要有以下三部分：</p><div class="table-container"><table><thead><tr><th>部分</th><th>说明</th></tr></thead><tbody><tr><td>磁盘缓冲区</td><td>在磁盘上开辟的一个存储空间，用于暂存用户程序的输出数据</td></tr><tr><td>打印缓冲区</td><td>设置在内存中，暂存从磁盘缓冲区送来的数据，以后再传送给打印设备进行打印</td></tr><tr><td>假脱机管理进程</td><td>为每个要求打印的用户数据建立一个假脱机文件，并把它放入假脱机文件队列中</td></tr><tr><td>假脱机打印进程</td><td>依次对队列中的文件进行打印</td></tr></tbody></table></div><p>当多个用户进程提出输出打印的请求时，系统会答应它们的请求，但是并不是真正把打印机分配给他们，而是由假脱机管理进程为每个进程做两件事：</p><ol><li>在磁盘输出井中为进程申请一个空闲缓冲区，并将要打印的数据送入其中；</li><li>为用户进程申请一张空白的打印请求表，并将用户的打印请求填入表中，再将该表挂到假脱机文件队列上。</li></ol><p>由此可见，利用假脱机系统向用户提供共享打印机的概念是：对每个用户而言，系统并非即时执行其程序输出数据的真实打印操作，而只是即时将数据输出到缓冲区，这时的数据并未真正被打印，只是让用户感觉系统已为他打印。真正的打印操作，是在打印机空闲且该打印任务在等待队列中已排到队首时进行的，而且打印操作本身也是利用 CPU 的一个时间片，没有使用专门的外围机。以上的过程是对用户屏蔽的，用户是不可见的。</p><h3 id="6-7-缓冲区管理"><a href="#6-7-缓冲区管理" class="headerlink" title="6.7 缓冲区管理"></a>6.7 缓冲区管理</h3><h5 id="1-缓冲区的引入"><a href="#1-缓冲区的引入" class="headerlink" title="1. 缓冲区的引入"></a>1. 缓冲区的引入</h5><p><strong>缓冲区</strong>是一个存储区域，可以由专门的硬件寄存器组成，也可利用内存作为缓冲区。使用硬件作为缓冲区的成本较高，容量也较小，一般仅用在对速度要求非常高的场合(如存储器管理中所用的联想寄存器）一般情况下利用内存作为缓冲区，“设备独立性软件”的缓冲区管理就是要组织管理好这些缓冲区。<br>引入缓冲区的原因有：</p><ol><li>缓和 CPU 与 I/O 设备间速度不匹配的矛盾：CPU 的运算速率远远高于 I/O 设备的速率，如果没有缓冲区，在运行时会因为 I/O 设备跟不上 CPU 的速度导致 CPU 停下来等待；</li><li>减少对 CPU 的中断频率，放宽对 CPU 中断响应时间的限制。随着传输速率的提高，需要配置位数更多的寄存器进行缓冲；</li><li>解决数据粒度不匹配的问题：生产者所生产的数据粒度比消费者小时，生产者进程可以一连生产多个数据单元的数据。生产者比消费者粒度大时，生产者每次生产的数据消费者可以分几次从缓冲区中取出消费；</li><li>提高 CPU 和 I/O 设备之间的并行性：生产者在生产了一批数据并将它放入缓冲区后，便可立即去进行下一次的生产。</li></ol><h5 id="2-单缓冲区"><a href="#2-单缓冲区" class="headerlink" title="2. 单缓冲区"></a>2. 单缓冲区</h5><p>假设某用户进程请求某种块设备读入若干块的数据。若采用<strong>单缓冲(Single Buffer)</strong>的策略，操作系统会在主存中为其分配一个缓冲区。当缓冲区数据非空时，不能往缓冲区冲入数据，只能从缓冲区把数据传出。当缓冲区为空时可以往缓冲区冲入数据，但必须把缓冲区充满以后，才能从缓冲区把数据传出。<br><img src="source/images/操作系统5：I-O系统/1774310-20210818155537924-2120766036.png" alt="img" style="zoom:80%;"></p><p>假定从磁盘把一块数据输入到缓冲区的时间为 T，OS 将该缓冲区中的数据传送到用户区的时间为 M，CPU 数据处理(计算)的时间为C。由于 T 和 C 是可以并行的，当 T &gt; C 时系统对每一块数据的处理时间为 M + T，反之则为M + C，故可把系统对每一块数据的处理时间表示为 <strong>Max(C,T) + M</strong>。<br><img src="source/images/操作系统5：I-O系统/1774310-20210818155852133-1508845224.png" alt="img" style="zoom: 67%;"></p><h5 id="2-双缓冲区"><a href="#2-双缓冲区" class="headerlink" title="2. 双缓冲区"></a>2. 双缓冲区</h5><p>由于缓冲区是共享资源，生产者与消费者在使用缓冲区时必须互斥。如果消费者尚未取走缓冲区中的数据，即使生产者又生产出新的数据，也无法将它送入缓冲区，生产者等待。</p><p>如果设置了两个缓冲区能解决这一问题，同时可以加快输入和输出速度，提高设备利用率。<strong>双缓冲区机制(Double Buffer)</strong>也称缓冲对换(Buffer Swapping)，在设备输入时先将数据送入第一缓冲区，装满后便转向第二缓冲区。此时操作系统可以从第一缓冲区中移出数据，并送入用户进程，接着由 CPU 对数据进行计算。<br><img src="source/images/操作系统5：I-O系统/1774310-20210818160542688-1393507114.png" alt="img" style="zoom: 67%;"><br>在双缓冲时系统处理一块数据的时间可以粗略地认为是 <strong>Max(C，T)</strong>，如果 C &lt; T 可使块设备连续输入，如果 C &gt; T 则可使 CPU 不必等待设备输入。对于字符设备，若采用行输入方式，在 CPU 执行第一行中的命令时，用户可继续向第二缓冲区输入下一行数据。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第六章 输入输出系统/1774310-20210818160741008-539738633.png" alt="img" style="zoom: 67%;"><br>如果在实现两台机器之间的通信时仅为它们配置了单缓冲，那么它们之间在任一时刻只能实现半双工的数据传输。为了实现全双工数据传输，必须在两台机器中都设置两个缓冲区，一个用作发送缓冲区，另一个用作接收缓冲区。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第六章 输入输出系统/1774310-20210818161135382-1494178956.png" alt="img" style="zoom: 80%;"></p><h5 id="3-环形缓冲区"><a href="#3-环形缓冲区" class="headerlink" title="3. 环形缓冲区"></a>3. 环形缓冲区</h5><p>若两个缓冲区的速度相差甚远，双缓冲的效果则不够理想，不过可以通过缓冲区数量的增加来改善。<strong>多缓冲机制</strong>可将多个缓冲区组织成环形缓冲区形式，在环形缓冲中包括多个缓冲区，其每个缓冲区的大小相同。</p><p>作为输入的多缓冲区可分为三种类型：用于装输入数据的空缓冲区 R、已装满数据的缓冲区 G 以及计算进程正在使用的现行工作缓冲区 C。作为输入的缓冲区可设置三个指针：用于指示计算进程下一个可用缓冲区 G 的指针 Nextg、指示输入进程下次可用的空缓冲区 R 的指针 Nexti，以及用于指示计算进程正在使用的缓冲区 C 的指针 Current。<br><img src="source/images/操作系统5：I-O系统/1774310-20210818162059152-849959912.png" alt="img" style="zoom: 67%;"><br>使用输入循环缓冲，可使输入进程和计算进程并行执行,相应地指针 Nexti 和 Nextg 将不断地沿着顺时针方向移动。这样就可能出现下 Nexti 指针追赶上 Nextg 指针，这意味着输入进程输入数据的速度大于计算进程处理数据的速度。也有可能出现 Nextg 指针追赶上 Nexti 指针，这意味着输入数据的速度低于计算进程处理数据的速度。</p><h5 id="4-缓冲池"><a href="#4-缓冲池" class="headerlink" title="4. 缓冲池"></a>4. 缓冲池</h5><p>当系统较大时会存在大量的循环缓冲，这不仅要消耗大量的内存空间，而且其利用率不高。目前广泛流行既可用于输入又可用于输出的公用缓冲池，在池中设置了多个可供若干个进程共享的缓冲区。缓冲池与缓冲区的区别在于，缓冲区仅仅是一组内存块的链表，而缓冲池则是包含了一个管理的数据结构及一组操作函数的管理机制。</p><p>缓冲池管理着多个缓冲区，每个缓冲区由用于标识和管理的缓冲首部以及用于存放数据的缓冲体两部分组成。缓冲首部一般包括缓冲区号、设备号、设备上的数据块号、同步信号量以及队列链接指针等。为了管理上的方便，一般将缓冲池中具有相同类型的缓冲区链接成一个队列，于是可形成以下三个队列。除了三个队列外，还应具有四种工作缓冲区：用于收容输入数据的工作缓冲区、用于提取输入数据的工作缓冲区、用于收容输出数据的工作缓冲区，以及用于提取输出数据的工作缓冲区。</p><div class="table-container"><table><thead><tr><th>队列</th><th>说明</th></tr></thead><tbody><tr><td>空白缓冲队列 emq</td><td>由空缓冲区所链成的队列</td></tr><tr><td>输入队列 inq</td><td>由装满输入数据的缓冲区所链成的队列</td></tr><tr><td>输出队列 outq</td><td>由装满输出数据的缓冲区所链成的队列</td></tr></tbody></table></div><p>缓冲区可以有如下 4 个工作方式：</p><ol><li>输入进程请求输入数据；</li><li>计算进程想要取得一块输入数据；</li><li>计算进程想要将准备好的数据冲入缓冲区；</li><li>输出进程请求输出数据。</li></ol><p><img src="source/images/操作系统5：I-O系统/1774310-20210818163659498-1307640016.png" alt="img" style="zoom:80%;"></p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统4：虚拟存储器</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-4-xu-ni-cun-chu-qi/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-4-xu-ni-cun-chu-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="第五章-虚拟存储器"><a href="#第五章-虚拟存储器" class="headerlink" title="第五章 虚拟存储器"></a>第五章 虚拟存储器</h1><h3 id="5-1-虚拟存储器概述"><a href="#5-1-虚拟存储器概述" class="headerlink" title="5.1 虚拟存储器概述"></a>5.1 虚拟存储器概述</h3><h4 id="5-1-1-常规存储器管理方式的特征和局部性原理"><a href="#5-1-1-常规存储器管理方式的特征和局部性原理" class="headerlink" title="5.1.1 常规存储器管理方式的特征和局部性原理"></a>5.1.1 常规存储器管理方式的特征和局部性原理</h4><h5 id="1-常规存储器管理方式"><a href="#1-常规存储器管理方式" class="headerlink" title="1.常规存储器管理方式"></a>1.常规存储器管理方式</h5><p>无论是连续还是离散的存储器管理方式，统称为传统存储器管理方式，它们全都具有如下两个共同的特征。第一个是<strong>一次性</strong>，是指作业必须一次性地全部装入内存后方能开始运行。第二个是<strong>驻留性</strong>，是指作业被装入内存后，整个作业都一直驻留在内存中，其中任何部分都不会被换出，直至作业运行结束。尽管运行中的进程可能会被阻塞，或者有的程序模块在运行过一次后就不再需要(运行)了，它们都仍将继续占用的内存资源。部装入内存后方能运行。由于这两个性质，可能会导致两种情况：</p><ol><li>有的作业很大，其所要求的内存空间超过了内存总容量，作业不能全部被装入内存使该作业无法运行；</li><li>有大量作业要求运行，但由于内存容量不足以容纳所有这些作业，只能将少数作业装入内存先运行，将其它大量的作业留在外存上等待。</li></ol><p>出现上述两种情况的原因都是由于内存容量不够大，如果从物理上增加内存容量，往往会受到机器自身的限制而且要增加成本，另一种方法是从逻辑上扩充内存容量。</p><h5 id="2-局部性原理"><a href="#2-局部性原理" class="headerlink" title="2. 局部性原理"></a>2. 局部性原理</h5><p>程序在执行时将呈现出局部性规律，即在一较短的时间内程序的执行仅局限于某个部分，相应地所访问的存储空间也局限于某个区域。局限性表现在下述两个方面：</p><div class="table-container"><table><thead><tr><th>局部性</th><th>说明</th></tr></thead><tbody><tr><td>时间局部性</td><td>如果程序中的某条指令被执行，则不久以后该指令可能再次执行；如果某数据被访问过，则不久以后该数据可能再次被访问，典型例子是程序中的循环结构</td></tr><tr><td>空间局部性</td><td>一旦程序访问了某个存储单元，在不久之后其附近的存储单元也将被访问，典型例子是是程序的顺序执行或数组的遍历</td></tr></tbody></table></div><h5 id="3-虚拟存储器的基本工作情况"><a href="#3-虚拟存储器的基本工作情况" class="headerlink" title="3. 虚拟存储器的基本工作情况"></a>3. 虚拟存储器的基本工作情况</h5><p>基于局部性原理可知，应用程序运行时仅须将当前要运行的少数页面或段先装入内存便可，其余部分暂留在盘上。在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。这样使一个大的用户程序在较小的内存空间中运行，也可在内存中同时装入更多的进程，使它们并发执行。</p><h4 id="5-1-2-虚拟存储器的定义和特征"><a href="#5-1-2-虚拟存储器的定义和特征" class="headerlink" title="5.1.2 虚拟存储器的定义和特征"></a>5.1.2 虚拟存储器的定义和特征</h4><h5 id="1-虚拟存储器的定义"><a href="#1-虚拟存储器的定义" class="headerlink" title="1. 虚拟存储器的定义"></a>1. 虚拟存储器的定义</h5><p>在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存。<strong>虚拟存储器是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。</strong>它的运行速度接近于内存速度，而每位的成本却又接近于外存。虚拟内存的最大容量是由计算机的 CPU 寻址范围确定的，实际容量是内存和外存容量之和和 CPU 寻址范围之间的最小值。例如某计算机地址结构为 32 位，按字节编址，内存大小为 512 MB，外存大小为 2 GB。则虚拟内存的最大容量为 2^32 B = 4 GB，虚拟内存的实际容量 = min(2^32 B, 512 MB + 2 GB) = 2 GB + 512 MB</p><h5 id="2-虚拟存储器的特征"><a href="#2-虚拟存储器的特征" class="headerlink" title="2. 虚拟存储器的特征"></a>2. 虚拟存储器的特征</h5><p>虚拟内存有一下三个主要特征：</p><div class="table-container"><table><thead><tr><th>特征</th><th>说明</th></tr></thead><tbody><tr><td>多次性</td><td>无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存</td></tr><tr><td>对换性</td><td>在作业运行时无需一直常驻内存，而是允许在作业运行过程中将作业换入、换出</td></tr><tr><td>虚拟性</td><td>从逻辑上扩充了内存的容量，使用户看到的内存容量远大于实际的容量</td></tr></tbody></table></div><h4 id="5-1-3-虚拟存储器的实现方法"><a href="#5-1-3-虚拟存储器的实现方法" class="headerlink" title="5.1.3 虚拟存储器的实现方法"></a>5.1.3 虚拟存储器的实现方法</h4><p>在虚拟存储器中，允许将一个作业分多次调入内存。如果采用连续分配方式，必须事先为作业一次性地申请一个足以容纳整个作业的内存空间，这样无法、也无意义再从逻辑上扩大内存容量。所以虚拟存储器的实现，都建立在离散分配存储管理方式的基础上。</p><h5 id="1-分页请求系统"><a href="#1-分页请求系统" class="headerlink" title="1. 分页请求系统"></a>1. 分页请求系统</h5><p>分页请求系统是在分页系统的基础上，增加请求调页功能和页面置换功能，形成<strong>页式虚拟存储系统</strong>。它允许用户程序只装入少数页面的程序(及数据)即可启动运行，再通过调页功能及页面置换功能陆续地把即将运行的页面调入内存，同时把暂不运行的页面换出到外存上。</p><h5 id="2-请求分段系统"><a href="#2-请求分段系统" class="headerlink" title="2. 请求分段系统"></a>2. 请求分段系统</h5><p>请求分段系统是在分段系统的基础上，增加了请求调段及分段置换功能，形成<strong>段式虚拟存储系统</strong>。它允许用户程序只要装入少数段（而非所有的段）的程序和数据即可启动运行，以后通过调段功能和段的置换功能将暂不运行的段调出，再调入即将运行的段。</p><h3 id="5-2-请求分页存储管理方式"><a href="#5-2-请求分页存储管理方式" class="headerlink" title="5.2 请求分页存储管理方式"></a>5.2 请求分页存储管理方式</h3><h4 id="5-2-1-请求分页中的硬件支持"><a href="#5-2-1-请求分页中的硬件支持" class="headerlink" title="5.2.1 请求分页中的硬件支持"></a>5.2.1 请求分页中的硬件支持</h4><p>计算机系统除了要求一定容量的内存和外存外，还需要有请求页表机制、缺页中断机构以及地址变换机构。</p><h5 id="1-请求页表机制"><a href="#1-请求页表机制" class="headerlink" title="1. 请求页表机制"></a>1. 请求页表机制</h5><p>在请求分页系统中需要的主要数据结构是请求页表，作用仍然是将逻辑地址映射为物理地址。为了满足页面换进换出的需要，在请求页表中又增加了四个字段。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810163245613-287487414.png" alt="img"></p><div class="table-container"><table><thead><tr><th>字段</th><th>说明</th></tr></thead><tbody><tr><td>状态位 P</td><td>指示该页是否已调入内存，供程序访问时参考</td></tr><tr><td>访问字段 A</td><td>记录本页在一段时间内被访问的次数，供置换页面时参考</td></tr><tr><td>修改位 M</td><td>标识该页在调入内存后是否被修改过，供置换页面时参考</td></tr><tr><td>外存地址</td><td>用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考</td></tr></tbody></table></div><h5 id="2-缺页中断机构"><a href="#2-缺页中断机构" class="headerlink" title="2. 缺页中断机构"></a>2. 缺页中断机构</h5><p>在请求分页系统中，每当要访问的页面不在内存时，便产生一个<strong>缺页中断</strong>，然后由操作系统的缺页中断处理程序处理中断。此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒放回就绪队列。如果内存中有空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项。如果内存中没有空闲块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间被修改过，则要将其写回外存。未修改过的页面不用写回外存。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810165459251-305797898.png" alt="img"><br>缺页中断是一种特殊的中断，它是在指令执行期间产生和处理中断信号。一条指令在执行期间可能产生多次缺页中断，例如“copy A to B”将逻辑地址 A 中的数据复制到逻辑地址 B，而 A、B 属于不同的页面就有可能产生两次中断。</p><h5 id="3-地址变换机构"><a href="#3-地址变换机构" class="headerlink" title="3. 地址变换机构"></a>3. 地址变换机构</h5><p>请求分页系统中的地址变换机构是在分页系统地址变换机构的基础上，再增加了某些功能所形成的，如产生和处理缺页中断以及从内存中换出一页的功能等。在进行地址变换时，首先检索快表，试图从中找出所要访问的页。若找到便修改页表项中的访问位，对于写指令还须将修改位置成“1”，表示该页在调入内存后已被修改。然后利用页表项中给出的物理块号和页内地址形成物理地址，地址变换过程到此结束。如果在快表中未找到该页的页表项，则应到内存中去查找页表，再从找到的页表项中的状态位 P 来了解该页是否已调入内存。若该页已调入内存，这时应将该页的页表项写入快表。当快表已满时，则应先调出按某种算法所确定的页的页表项，然后再写入该页的页表项。若该页尚未调入内存，这时应产生缺页中断，请求 OS 从外存把该页调入内存。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810171305271-232901193.png" alt="img"></p><h4 id="5-2-2-请求分页中的内存分配"><a href="#5-2-2-请求分页中的内存分配" class="headerlink" title="5.2.2 请求分页中的内存分配"></a>5.2.2 请求分页中的内存分配</h4><p>在为进程分配内存时，将涉及到为保证进程能正常运行需要多少物理块数，以及在为每个进程分配物理块时应采取什么样的分配策略的问题。</p><h5 id="1-最小物理块数的确定"><a href="#1-最小物理块数的确定" class="headerlink" title="1. 最小物理块数的确定"></a>1. 最小物理块数的确定</h5><p><strong>驻留集</strong>指请求分页存储管理中给进程分配的物理块的集合，在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。若驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少。驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大小。</p><h5 id="2-内存分配策略"><a href="#2-内存分配策略" class="headerlink" title="2. 内存分配策略"></a>2. 内存分配策略</h5><p>在请求分页系统中分配内存时，可采取固定或可变分配两种策略。</p><div class="table-container"><table><thead><tr><th>分配策略</th><th>说明</th></tr></thead><tbody><tr><td>固定分配</td><td>操作系统为每个进程分配一组固定数目的物理块，在进程运行期间不再改变</td></tr><tr><td>可变分配</td><td>先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少</td></tr></tbody></table></div><p>在进行置换时，也可采取全局置换或局部置换两种策略。</p><div class="table-container"><table><thead><tr><th>分配策略</th><th>说明</th></tr></thead><tbody><tr><td>局部置换</td><td>发生缺页时只能选进程自己的物理块进行置换</td></tr><tr><td>全局置换</td><td>可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存</td></tr></tbody></table></div><p>通过分配策略和置换策略的组合，可组合出以下三种适用的策略。简单地说可变分配全局置换是只要缺页就给分配新物理块，可变分配局部置换是要根据发生缺页的频率来动态地增加或减少进程的物理块。</p><div class="table-container"><table><thead><tr><th>策略</th><th>说明</th></tr></thead><tbody><tr><td>固定分配局部置换</td><td>系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入需要的页面。这种策略的缺点是，很难在刚开始就确定应为每个进程分配多少个物理块才算合理。</td></tr><tr><td>可变分配全局置换</td><td>刚开始会为每个进程分配一定数量的物理块，操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程。若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程。只要某进程发生缺页，都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加。</td></tr><tr><td>可变分配局部置换</td><td>刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度。反之如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。</td></tr></tbody></table></div><p>没有固定分配全局置换的原因是，全局置换意味着一个进程拥有的物理块数量必然会改变，因此不可能是固定分配。</p><h5 id="3-物理块分配算法"><a href="#3-物理块分配算法" class="headerlink" title="3. 物理块分配算法"></a>3. 物理块分配算法</h5><p>在采用固定分配策略时，如何将系统中可供分配的所有物理块分配给各个进程，可采用下述几种算法：</p><ol><li>平均分配算法：即将系统中所有可供分配的物理块平均分配给各个进程；</li><li>按比例分配算法：即根据进程的大小按比例分配物理块；</li><li>考虑优先权的分配算法：为了照顾到重要的、紧迫的作业能尽快地完成，应为它分配较多的内存空间。</li></ol><h4 id="5-2-3-页面调入策略"><a href="#5-2-3-页面调入策略" class="headerlink" title="5.2.3 页面调入策略"></a>5.2.3 页面调入策略</h4><p>为使进程能够正常运行，必须事先将要执行的那部分程序和数据所在的页面调入内存。</p><h5 id="1-何时调入页面"><a href="#1-何时调入页面" class="headerlink" title="1. 何时调入页面"></a>1. 何时调入页面</h5><p>为了确定系统将进程运行时所缺的页面调入内存的时机，可采取预调页策略或请求调页策略。<strong>预调页策略</strong>是采用一种以预测为基础的预调页策略，将那些预计在不久之后便会被访问的页面预先调入内存。如果预测较准确能有效改善性能，但目前预调页的成功率仅约 50%。<br><strong>请求调页策略</strong>是进程在运行中需要访问某部分程序和数据时，若发现其所在的页面不在内存便立即提出请求，由 OS 将其所需页面调入内存。由请求调页策略所确定调入的页是一定会被访问的，且请求调页策略比较易于实现，故在目前的虚拟存储器中大多采用此策略。但这种策略每次仅调入一页，故须花费较大的系统开销，增加了磁盘 I/O 的启动频率。</p><h5 id="2-从何处调入页面"><a href="#2-从何处调入页面" class="headerlink" title="2. 从何处调入页面"></a>2. 从何处调入页面</h5><p>将请求分页系统中的外存分为两部分，一部分是用于存放文件的<strong>文件区</strong>，一部分是用于存放对换页面的<strong>对换区</strong>。通常由于对换区是采用连续分配方式，而文件区是采用离散分配方式，所以对换区的数据存取(磁盘 I/O)速度比文件区的高。每当发生缺页请求时，系统应从何处将缺页调入内存有以下情况：<br>第一种情况，当系统拥有足够的对换区空间，这时可以全部从对换区调入所需页面，以提高调页速度。在进程运行前，便须将与该进程有关的文件从文件区拷贝到对换区。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第五章 虚拟存储器/1774310-20210810211443507-1500684421.png" alt="img" style="zoom:67%;"><br>第二种情况，系统缺少足够的对换区空间，这时凡是不会被修改的文件，都直接从文件区调入，这些页面由于它们未被修改，不必再将它们重写到磁盘(换出)。以后再调入时，仍从文件区直接调入。但对于那些可能被修改的部分，在将它们换出时便须调到对换区，以后需要时再从对换区调入。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810211559218-1241703051.png" alt="img" style="zoom:67%;"><br>第三种情况可以使用 UNIX 方式，凡是未运行过的页面，都应从文件区调入。而对于曾经运行过但又被换出的页面，由于是被放在对换区，因此在下次调入时应从对换区调入。<br><img src="../../../../Download/文档/操作系统笔记/source/images/第五章 虚拟存储器/1774310-20210810211640396-1763788550.png" alt="img" style="zoom:67%;"></p><h5 id="3-页面调入过程"><a href="#3-页面调入过程" class="headerlink" title="3. 页面调入过程"></a>3. 页面调入过程</h5><p>每当程序所要访问的页面未在内存时(存在位为“0”)，便向 CPU 发出一缺页中断，中断处理程序首先保留 CPU 环境，分析中断原因后转入缺页中断处理程序。该程序通过查找页表得到该页在外存的物理块后，如果此时内存能容纳新页，则启动磁盘 I/O，将所缺之页调入内存，然后修改页表。如果内存已满，则须先按照某种置换算法，从内存中选出一页准备换出。如果该页未被修改过(修改位为“0”)，可不必将该页写回磁盘；但如果此页已被修改(修改位为“1”)，则必须将它写回磁盘，然后再把所缺的页调入内存，并修改页表中的相应表项，置其存在位为“1”，并将此页表项写入快表中。在缺页调入内存后，利用修改后的页表形成所要访问数据的物理地址，再去访问内存数据。</p><h5 id="4-缺页率"><a href="#4-缺页率" class="headerlink" title="4. 缺页率"></a>4. 缺页率</h5><p>假设一个进程的逻辑空间为 n 页，系统为其分配的内存物理块数为 m(m ≤ n)。如果在进程的运行过程中，访问页面成功的次数为 S，访问页面失败的次数为 F，则该进程总的页面访问次数和缺页率 f 的计算公式为：</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">A</span> = S + F</span><br><span class="line"><span class="attr">f</span> = F / A</span><br></pre></td></tr></tbody></table></figure><p>通常缺页率受到以下几个因素的影响：</p><ol><li>页面大小：页面划分较大则缺页率较低，反之缺页率较高。</li><li>进程所分配物理块的数目：所分配的物理块数目越多缺页率越低，反之则越高。</li><li>页面置换算法：算法的优劣决定了进程执行过程中缺页中断的次数</li><li>程序固有特性：程序编制的局部化程度越高，相应执行时的缺页程度越低。</li></ol><p>事实情况下没有修改过的页面可以直接放弃，而修改过的页面则必须进行保存，所以处理这两种情况时的时间也是不同的。假设被置换的页面被修改的概率是 β，其缺页中断处理时间为 ta，被置换页面没有被修改的缺页中断时间为 ts，那么缺页中断处理时间的计算公式为：</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">t</span> = β × ta + (<span class="number">1</span> - β) × tb</span><br></pre></td></tr></tbody></table></figure><h3 id="5-3-页面置换算法"><a href="#5-3-页面置换算法" class="headerlink" title="5.3 页面置换算法"></a>5.3 页面置换算法</h3><p>内存已无空闲空间时，为了保证该进程能正常运行，系统必须从内存中调出一页程序或数据送到磁盘的对换区中。应将哪个页面调出，须根据一定的算法来确定，选择换出页面的算法称为<strong>页面置换算法(Page-Replacement Algorithms)</strong>。置换算法的好坏将直接影响到系统的性能，不适当的算法可能会导致进程发生“抖动”，一个好的页面置换算法应具有较低的页面更换频率。</p><h4 id="5-3-1-最佳置换算法和先进先出置换算法"><a href="#5-3-1-最佳置换算法和先进先出置换算法" class="headerlink" title="5.3.1 最佳置换算法和先进先出置换算法"></a>5.3.1 最佳置换算法和先进先出置换算法</h4><h5 id="1-最佳置换算法"><a href="#1-最佳置换算法" class="headerlink" title="1. 最佳置换算法"></a>1. 最佳置换算法</h5><p>最佳置换算法是一种理论上的算法，其所选择的被淘汰页面将是以后永不使用或在最长未来时间内不再被访问的页面。采用最佳置换算法通常可保证获得最低的缺页率，但由于无法预知哪一个页面是未来最长时间内不再被访问的，因而该算法无法实现，但可以利用该算法去评价其它算法。<br>假定系统为某进程分配了三个物理块，有以下的页面号引用串。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1</span><br></pre></td></tr></tbody></table></figure><p>进程运行时先将 7，0，1 三个页面装入内存，当进程要访问页面 2 时将会产生缺页中断。此时 OS 根据最佳置换算法将选择页面 7 淘汰，这是因为页面 0 将作为第 5 个被访问的页面，页面 1 是第 14 个被访问的页面，而页面 7 则要在第18次页面访问时才需调入。以此类推，得到采用最佳置换算法在各个页面引用时的状态。由表格可看出，采用最佳置换算法发生了 6 次页面置换。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810214851671-1123728659.png" alt="img"></p><h5 id="2-先进先出页面置换算法"><a href="#2-先进先出页面置换算法" class="headerlink" title="2. 先进先出页面置换算法"></a>2. 先进先出页面置换算法</h5><p>FIFO 算法总是淘汰最先进入内存的页面，也就是选择在内存中驻留时间最久的页面予以淘汰。该算法实现简单，但该算法与进程实际运行的规律不相适应，因为在进程中有些页面经常被访问，FIFO 算法并不能保证这些页面不被淘汰。<br>假定系统为某进程分配了三个物理块，有以下的页面号引用串。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1</span><br></pre></td></tr></tbody></table></figure><p>采用 FIFO 算法进，当进程第一次访问页面 2 时将把第 7 页换出，因为它是最先被调入内存的。在第一次访问页面 3 时，又将把第 0 页换出，因为它在现有的 2、0、1 三个页面中是最老的页。利用 FIFO 算法时，进行了 12 次页面置换，比最佳置换算法正好多一倍。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810215419893-1381106537.png" alt="img"></p><h4 id="5-3-2-最近最久未使用和最少使用置换算法"><a href="#5-3-2-最近最久未使用和最少使用置换算法" class="headerlink" title="5.3.2 最近最久未使用和最少使用置换算法"></a>5.3.2 最近最久未使用和最少使用置换算法</h4><h5 id="1-最近最久未使用-LRU-置换算法"><a href="#1-最近最久未使用-LRU-置换算法" class="headerlink" title="1. 最近最久未使用(LRU)置换算法"></a>1. 最近最久未使用(LRU)置换算法</h5><p><strong>最近最久未使用 LRU(Least Recently Used)</strong>置换算法根据页面调入内存后的使用情况做出决策的，LRU 算法是选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 t。当需淘汰一个页面时，选择现有页面中其 t 值最大的页面淘汰。LRU 置换算法虽然是一种比较好的算法，但要求系统有较多的支持硬件。可以为每个在内存中的页面配置一个移位寄存器记录未使用时间，也可以利用一个特殊的栈保存当前使用的各个页面的页面号。<br>假定系统为某进程分配了三个物理块，有以下的页面号引用串。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1</span><br></pre></td></tr></tbody></table></figure><p>当进程第一次对页面 2 进行访问时，由于页面 7 是最近最久未被访问的，故将它置换出去。当进程第一次对页面 3 进行访问时，第 1 页成为最近最久未使用的页，将它换出。利用 LRU 算法时，进行了 9 次页面置换。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810220551703-743698317.png" alt="img"></p><h5 id="2-最少使用（LFU）置换算法"><a href="#2-最少使用（LFU）置换算法" class="headerlink" title="2. 最少使用（LFU）置换算法"></a>2. 最少使用（LFU）置换算法</h5><p>最少使用（Least Frequently Used）置换算法，为在内存中的每个页面设置一个移位寄存器，用来记录该页面被访问的频率。该置换算法选择在最近时期使用最少的页面作为淘汰页。</p><h4 id="5-3-3-Clock置换算法"><a href="#5-3-3-Clock置换算法" class="headerlink" title="5.3.3 Clock置换算法"></a>5.3.3 Clock置换算法</h4><p><strong>时钟置换算法</strong>是一种性能和开销较均衡的算法，又称 CLOCK 算法或最近未用（NRU，NotRecently Used)算法。</p><h5 id="1-简单的Clock置换算法"><a href="#1-简单的Clock置换算法" class="headerlink" title="1. 简单的Clock置换算法"></a>1. 简单的Clock置换算法</h5><p>简单的 CLOCK 算法为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时其访问位为 1，当需要淘汰一个页面时，只需检查页的访问位。如果是 0 就选择该页换出，如果是 1 则将它置为 0，暂不换出并继续检查下一个页面。若第一轮扫描中所有页面都是 1，则将这些页面的访问位依次置为 0 后，再进行第二轮扫描。</p><h5 id="2-改进型Clock置换算法"><a href="#2-改进型Clock置换算法" class="headerlink" title="2. 改进型Clock置换算法"></a>2. 改进型Clock置换算法</h5><p>在将一个页面换出时，如果该页已被修改过，便须将该页重新写回到磁盘上。但如果该页未被修改过，则不必将它拷回磁盘。对于修改过的页面，在换出时所付出的开销比未修改过的页面大。在改进型 Clock 算法中，还须再增加一个<strong>置换代价</strong>的因素，这样选择页面换出时，未使用过和未被修改过的页面要综合考虑。由访问位 A 和修改位 M 可以组合成下面四种类型的页面：</p><ol><li>A = 0，M = 0：该页最近既未被访问，又未被修改，是最佳淘汰页。</li><li>A = 0，M = 1：该页最近未被访问，但已被修改，并不是很好的淘汰页。</li><li>A = 1，M = 0：最近已被访问，但未被修改，该页有可能再被访问。</li><li>A = 1，M = 1：最近已被访问且被修改，该页可能再被访问。</li></ol><p>在进行页面置换时，与简单 Clock 算法的差别在于该算法须同时检查访问位 A 与修改位 M。其执行过程可分成以下三步：</p><ol><li>从指针所指示的当前位置开始扫描循环队列，寻找第一类页面。将所遇到的第一个页面作为所选中的淘汰页，第一次扫描期间不改变访问位 A；</li><li>如果第一步失败则开始第二轮扫描，寻找第二类页面，将所遇到的第一个这类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位都置 0；</li><li>如果第二步也失败则将指针返回到开始的位置，并将所有的访问位复 0 然后重复第一步。如果仍失败就再重复第二步，此时就一定能找到被淘汰的页。</li></ol><p>改进后的算法与简单 Clock 算法比较，可减少磁盘的 I/O 操作次数。但为了找到一个可置换的页，可能须经过几轮扫描。</p><h4 id="5-3-4-页面缓冲算法"><a href="#5-3-4-页面缓冲算法" class="headerlink" title="5.3.4 页面缓冲算法"></a>5.3.4 页面缓冲算法</h4><p>对于已经被修改过的页面，在将其换出时应当写回磁盘。如果每当有一个页面要被换出时就将它写回磁盘，这意味着每换出一个页面，便需要启动一次磁盘。<strong>页面缓冲算法 PBA</strong>在系统中建立了一个已修改换出页面的链表，对每一个要被换出的页面(已修改)，系统可暂不把它们写回磁盘，而是将它们挂在已修改换出页面的链表上。仅当被换出页面数目达到一定值时，再将它们一起写回到磁盘上，这样就显著地减少了磁盘 I/O 的操作次数。如果有进程在这批数据还未写回磁盘时需要再次访问这些页面时，就不需从外存上调入，而直接从已修改换出页面链表中获取，这样也可以减少将页面从磁盘读入内存的频率。</p><h3 id="5-4-抖动与工作集"><a href="#5-4-抖动与工作集" class="headerlink" title="5.4 抖动与工作集"></a>5.4 抖动与工作集</h3><h5 id="1-抖动"><a href="#1-抖动" class="headerlink" title="1. 抖动"></a>1. 抖动</h5><p>由于虚拟存储器系统能从逻辑上扩大内存，这时只需装入一个进程的部分程序和数据便可开始运行。故人们希望在系统中能运行更多的进程以提高处理机的利用率，但处理机的实际利用率却如图的实线所示。随着进程数目的增加，处理机的利用率急剧增加，但到达 N1 时增速就减慢了，到达 Nmax 时处理机利用率达到最大。到达 N2 时若再继续增加进程数，利用率将加速下降趋于 0，这是因为发生了“抖动”现象。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20211225225155768-907291309.png" alt="img" style="zoom:67%;"><br>频繁的页面调度行为称为<strong>抖动(Thrashing)</strong>或颠簸，表现为刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数，也就是分配给进程的物理块不够。</p><h5 id="2-工作集"><a href="#2-工作集" class="headerlink" title="2. 工作集"></a>2. 工作集</h5><p>进程发生缺页率的时间间隔与进程所获得的物理块数有关，缺页率会随着分配的物理块数的增加而明显地减少。当物理块增加到某个数目时，再增加物理块对缺页率的改善已经不明显，此时就没有继续增加的必要了。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20211225225639097-1260639640.png" alt="img" style="zoom:67%;"><br><strong>工作集</strong>指在某段时间间隔里，进程实际访问页面的集合。操作系统会根据“窗口尺寸”来算出工作集，工作集大小可能小于窗口尺寸。实际应用中操作系统可以统计进程的工作集大小，根据工作集大小给进程分配若干内存块。<br>例如窗口尺寸为 5，经过一段时间的监测发现某进程的工作集最大为 3，那么可以给这个进程分配 3 个以上的内存块满足运行需要。一般来说，驻留集大小不能小于工作集大小，否则进程运行过程中将频繁缺页。</p><h5 id="3-防止抖动的方法"><a href="#3-防止抖动的方法" class="headerlink" title="3. 防止抖动的方法"></a>3. 防止抖动的方法</h5><p>为了保证系统具有较大的吞吐量，必须防止“抖动”的发生，下面是几个较常用的预防“抖动”发生的方法。</p><div class="table-container"><table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>采取局部置换策略</td><td>当某进程发生缺页时，只能在分配给自己的内存空间内进行置换，不允许从其它进程去获得新的物理块</td></tr><tr><td>把工作集算法融入到处理机调度中</td><td>在调度程序从外存调入作业之前，必须先检查每个进程在内存的驻留页面是否足够多。如果都已足够多，此时便可以从外存调入新的作业，反之则应首先为那些缺页率居高的作业增加新的物理块</td></tr><tr><td>利用“L = S”准则调节缺页率</td><td>L 是缺页之间的平均时间，S 是置换一个页面所需的时间。如果是 L 远比 S 大说明很少发生缺页，反之则说明频繁发生缺页。理论和实践证明利用“L = S”准则，对于调节缺页率十分有效</td></tr><tr><td>选择暂停的进程</td><td>当多道程序度偏高时，基于某种原则选择暂停某些当前活动的进程，将它们调出到磁盘上，以便把腾出的内存空间分配给缺页率发生偏高的进程</td></tr></tbody></table></div><h3 id="5-5-请求段式存储管理方式"><a href="#5-5-请求段式存储管理方式" class="headerlink" title="5.5 请求段式存储管理方式"></a>5.5 请求段式存储管理方式</h3><h4 id="5-5-1-请求分段中的硬件支持"><a href="#5-5-1-请求分段中的硬件支持" class="headerlink" title="5.5.1 请求分段中的硬件支持"></a>5.5.1 请求分段中的硬件支持</h4><p>与请求分页系统相似，在请求分段系统中所需的硬件支持有段表机制、缺段中断机构，以及地址变换机构。</p><h5 id="1-请求段表机制"><a href="#1-请求段表机制" class="headerlink" title="1. 请求段表机制"></a>1. 请求段表机制</h5><p>在请求分段式管理中所需的主要数据结构是<strong>请求段表</strong>，除了具有请求分页机制中有的访问字段 A、修改位 M、存在位 P 和外存始址四个字段外，还增加了存取方式字段和增补位，这些字段供程序在调进、调出时参考。<br><img src="source/images/操作系统4：虚拟存储器/1774310-20210810223048732-698080473.png" alt="img"></p><div class="table-container"><table><thead><tr><th>字段</th><th>说明</th></tr></thead><tbody><tr><td>存取方式</td><td>可根据段的属性对它实施保护，如果该字段为两位，则存取属性是只执行、只读和允许读/写。</td></tr><tr><td>状态位 P</td><td>指示该页是否已调入内存，供程序访问时参考</td></tr><tr><td>访问字段 A</td><td>记录本页在一段时间内被访问的次数，供置换页面时参考</td></tr><tr><td>修改位 M</td><td>标识该页在调入内存后是否被修改过，供置换页面时参考</td></tr><tr><td>增补位</td><td>用于表示本段在运行过程中是否做过动态增长</td></tr><tr><td>外存地址</td><td>用于指出该页在外存上的地址，通常是物理块号，供调入该页时参考</td></tr></tbody></table></div><h5 id="2-缺段中断机构"><a href="#2-缺段中断机构" class="headerlink" title="2. 缺段中断机构"></a>2. 缺段中断机构</h5><p>在请求分段系统中采用的是请求调段策略，每当发现运行进程所要访问的段尚未调入内存时，便由缺段中断机构产生缺段中断信号，进入 OS 后由缺段中断处理程序将所需的段调入内存。与缺页中断机构类似，但由于分段是信息的逻辑单位，因而不可能出现一条指令被分割在两个分段中和一组信息被分割在两个分段中的情况。由于段不是定长的，这使对缺段中断的处理要比对缺页中断的处理复杂。</p><h5 id="3-地址变换机构-1"><a href="#3-地址变换机构-1" class="headerlink" title="3. 地址变换机构"></a>3. 地址变换机构</h5><p>因为被访问的段并非全在内存，所以在地址变换时若发现所要访问的段不在内存，必须先将所缺的段调入内存并修改段表，然后才能再利用段表进行地址变换。为此在地址变换机构中又增加了某些功能，如缺段中断的请求及处理等。</p><h4 id="5-5-2-分段的共享与保护"><a href="#5-5-2-分段的共享与保护" class="headerlink" title="5.5.2 分段的共享与保护"></a>5.5.2 分段的共享与保护</h4><h5 id="1-分段共享"><a href="#1-分段共享" class="headerlink" title="1. 分段共享"></a>1. 分段共享</h5><p>分段存储管理方式的优点是便于实现分段的共享与保护，实现分段共享可在系统中配置一张<strong>共享段表</strong>，所有各共享段都在共享段表中占有一表项。在表项的上面记录了共享段的段号、段长、内存始址、状态(存在）位、外存始址以及共享计数等信息，接下去就是记录了共享此分段的每个进程的情况。</p><div class="table-container"><table><thead><tr><th>字段</th><th>说明</th></tr></thead><tbody><tr><td>共享进程计数 count</td><td>记录有多少进程正在共享该分段，当所有共享该段的进程全都不需要分段时才回收该段所占内存区</td></tr><tr><td>存取控制字段</td><td>对于一个共享段，应为不同的进程赋予不同的存取权限</td></tr><tr><td>段号</td><td>对于一个共享段，在不同的进程中可以具有不同的段号，每个进程可用自己进程的段号去访问该共享段</td></tr></tbody></table></div><p>在为共享段分配内存时，对第一个请求使用该共享段的进程，由系统为该共享段分配一物理区，再把共享段调入该区，同时将该区的始址填入请求进程的段表的相应项中。还须在共享段表中增加一表项，填写请求使用该共享段的进程名、段号和存取控制等有关数据，把 count 置为 1。当又有其它进程需要调用该共享段时，由于该共享段已被调入内存，故此时无须再为该段分配内存，而只需在调用进程的段表中增加一表项，再执行 count = count + 1 操作表明有两个进程共享该段。<br>当共享此段的某进程不再需要该段时，应将该段释放，包括撤消在该进程段表中共享段所对应的表项，以及执行 count = count - 1 操作。若结果为 0 则须由系统回收该共享段的物理内存，以及取消在共享段表中该段所对应的表项，否则只是取消调用者进程在共享段表中的有关记录。</p><h5 id="2-分段保护"><a href="#2-分段保护" class="headerlink" title="2. 分段保护"></a>2. 分段保护</h5><p>在分段系统中，由于每个分段在逻辑上是相对独立的，因而比较容易实现信息保护。目前常采用以下几种措施：</p><div class="table-container"><table><thead><tr><th>措施</th><th>说明</th></tr></thead><tbody><tr><td>越界检查</td><td>在进行地址变换时，首先将逻辑地址空间的段号与段表长度进行比较，如果段号等于或大于段表长度，将发出地址越界中断信号。此外还在段表中为每个段设置有段长字段，在进行地址变换时，还要检查段内地址是否等于或大于段长，若大于段长，将产生地址越界中断信号</td></tr><tr><td>存取控制检查</td><td>在段表的每个表项中都设置了一个“存取控制”字段，用于规定对该段的访问方式，通常的访问方式有只读、只执行、读/写</td></tr><tr><td>环保护机构</td><td>在该机制中规定：低编号的环具有高优先权，OS 核心处于 0 号环内，某些重要的实用程序和操作系统服务占居中间环，而一般的应用程序则被安排在外环上</td></tr></tbody></table></div>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统3：存储器管理</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-3-cun-chu-qi-guan-li/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-3-cun-chu-qi-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="第四章-存储器管理"><a href="#第四章-存储器管理" class="headerlink" title="第四章 存储器管理"></a>第四章 存储器管理</h1><h4 id="4-1-存储器的层次结构"><a href="#4-1-存储器的层次结构" class="headerlink" title="4.1 存储器的层次结构"></a>4.1 存储器的层次结构</h4><h5 id="1-多层结构的存储器系统"><a href="#1-多层结构的存储器系统" class="headerlink" title="1. 多层结构的存储器系统"></a>1. 多层结构的存储器系统</h5><p>1）存储器的多层结构</p><p>对于通用计算机而言，存储层次至少应具有三级：最高层为CPU寄存器，中间为主存，最底层是辅存。</p><p>在较高级的计算机中，还可以根据具体的功能细分为：寄存器，高速缓存，主存储器，磁盘缓存，固定磁盘，可移动存储介质。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210806153845639-1342588523.png" alt="img" style="zoom:80%;"></p><p>2）可执行存储器</p><p>在计算机系统的存储层次中，寄存器和主存又被称为可执行存储器，进程可以在很少的时钟周期内使用一条load或store指令对可执行存储器进行访问，但对辅存的访问则需要通过I/O设备实现，所需耗费的时间远远高于访问可执行存储器。</p><h5 id="2-主存储器与寄存器"><a href="#2-主存储器与寄存器" class="headerlink" title="2. 主存储器与寄存器"></a>2. 主存储器与寄存器</h5><p>1）主存储器</p><p>主存储器简称内存或主存，用于保存进程运行时的程序和数据。由于主存访问速度远低于CPU执行指令的速度，为缓和这一矛盾，在计算机系统中引入寄存器和高速缓存Cache。</p><p>2）寄存器</p><p>寄存器拥有与处理机相同的速度，故对寄存器的访问速度最快，完全能与CPU协调工作，但价格十分昂贵。</p><p>访问速度：寄存器&gt;高速缓存Cache&gt;主存&gt;辅存。</p><h5 id="3-高速缓存和磁盘缓存"><a href="#3-高速缓存和磁盘缓存" class="headerlink" title="3. 高速缓存和磁盘缓存"></a>3. 高速缓存和磁盘缓存</h5><p>1）高速缓存cache</p><p>高速缓存cache是介于寄存器和主存之间的存储器，主要用于备份主存中的最常用数据，以减少处理机对主存的访问次数，大幅度地提高程序执行速度。</p><p>2）磁盘缓存</p><p>由于目前磁盘的I/O速度远低于对主存的访问速度，为了缓和两者之间在速度上的不匹配，而设置了磁盘缓存。磁盘缓存即利用主存中的部分存储空间暂时存放频繁使用的一部分磁盘数据和信息，以减少访问磁盘的次数。</p><p>磁盘缓存与高速缓存不同，高速缓存是实际存在的存储器，而磁盘缓存则是利用了主存的部分存储空间。</p><h5 id="4-内存管理的功能"><a href="#4-内存管理的功能" class="headerlink" title="4. 内存管理的功能"></a>4. 内存管理的功能</h5><p>内存管理的主要功能有：</p><ul><li>内存空间的分配与回收</li><li>地址转换</li><li>内存空间的扩充</li><li>内存共享</li><li>存储保护</li></ul><h4 id="4-2-程序的装入和链接"><a href="#4-2-程序的装入和链接" class="headerlink" title="4.2 程序的装入和链接"></a>4.2 程序的装入和链接</h4><p>用户程序要在系统中运行，必须先将它装入内存，然后再将其转变为一个可执行程序，通常都要经过编译、链接和装入三个步骤。</p><p>编译：由编译程序（Compiler）对用户源程序进行编译，形成若干个目标模块（Object Moudle）；</p><p>链接：由链接程序（Linker）将编译后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个完整的装入模块（Load Moudle）。</p><p>装入：由装入程序（Loader）将装入模块装入内存。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210806160856292-1556606790.png" alt="img" style="zoom: 67%;"></p><h5 id="1-程序的装入"><a href="#1-程序的装入" class="headerlink" title="1. 程序的装入"></a>1. 程序的装入</h5><p>1）绝对装入方式 （物理地址=逻辑地址）</p><p>当计算机系统很小，且仅能运行单道程序时，完全有可能知道程序将驻留在内存的什么位置。此时可以采用绝对装入方式。用户程序编译后，将产生绝对地址（即物理地址），绝对装入程序便可按照装入模块中的地址，将程序和数据装入内存。</p><p>2）可重定位装入方式 （物理地址=逻辑地址+真实起始地址）</p><p>在多道程序环境下，编译程序不可能预知经编译后的目标模块应放在内存中的何处。因此，对于用户程序编译所形成的目标模块，它们的起始地址通常都是从0开始的，而程序中的其它地址则是相对于起始地址计算的，即装入模块中的所有逻辑地址都是相对于起始地址0的偏移量。当模块装入内存后即获得一个真实的起始地址，则模块中其它逻辑地址应加上这个真实起始地址才能得到对应的物理地址。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210806191533284-514654663.png" alt="img" style="zoom:67%;"></p><p>通常，把在装入时对目标程序中指令和数据地址的修改过程称为重定位。又因为地址变换通常是在进程装入时一次完成的，以后不再改变，故称为静态重定位。</p><p>3）动态运行时的装入方式</p><p>可重定位装入方式可将装入模块装入到内存中任何允许的位置，故可用于多道程序环境。但该方式并不允许程序运行时在内存中移动位置。程序若在内存中移动，并须对程序和数据的地址进行修改后方能运行，较为麻烦，在这种情况下，应采取动态运行时装入的方式。</p><p>动态运行时的装入程序在把装入模块装入内存后，并不立即把装入模块中的逻辑地址转换为物理地址，而是把这种地址转换推迟到程序真正要执行时才进行。为使地址转换不影响指令执行的速度，这种方式需要一个重定位寄存器的支持。</p><h5 id="2-程序的链接"><a href="#2-程序的链接" class="headerlink" title="2. 程序的链接"></a>2. 程序的链接</h5><p>在对目标模块进行链接时，根据链接时间的不同，可分为如下三种：</p><p>1）静态链接</p><p>事先链接，在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块，以后不再拆开。</p><p>在将若干个目标模块装配成一个装入模块时，需解决以下两个问题：</p><ul><li>对相对地址进行修改。</li><li>变换外部调用符号。</li></ul><p>这种先进行链接所形成的一个完整的装入模块，又称为可执行文件。通常都不再把它拆开，要运行时可直接将它装入内存。</p><p>2）装入时动态链接</p><p>这是指将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的链接方式。</p><p>装入时动态链接方式有以下优点：</p><ul><li>便于修改和更新</li><li>便于实现对目标模块的共享</li></ul><p>3）运行时动态链接</p><p>将对某些模块的链接推迟到程序执行时才进行。亦即，在执行过程中，当发现一个被调用模块尚未装入内存时，立即由OS去找到该模块，并将之装入内存，将其链接到调用者模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到装入模块上，这样不仅能加快程序的装入过程，而且可节省大量的内存空间。</p><h4 id="4-3-连续分配存储管理方式"><a href="#4-3-连续分配存储管理方式" class="headerlink" title="4.3 连续分配存储管理方式"></a>4.3 连续分配存储管理方式</h4><blockquote><p>连续分配存储管理方式为一个用户程序分配一个连续的内存空间，即程序中代码或数据的逻辑地址相邻，体现在内存空间分配时物理地址的相邻。连续分配方式可分为四类：单一连续分配、固定分区分配、动态分区分配以及动态可重定位分区分配算法四种方式。</p></blockquote><h5 id="1-单一连续分配"><a href="#1-单一连续分配" class="headerlink" title="1. 单一连续分配"></a>1. 单一连续分配</h5><p>在单道程序环境下，当时的存储器管理方式是把内存分为系统区和用户区两部分，系统区仅提供给OS使用，它通常是放在内存的低址部分。而在用户区内存中，仅装有一道用户程序，即整个内存的用户空间由该程序独占。这样的存储器分配方式被称为单一连续分配方式。</p><h5 id="2-固定分区分配"><a href="#2-固定分区分配" class="headerlink" title="2. 固定分区分配"></a>2. 固定分区分配</h5><p>为了能在内存中装入多道程序，且使这些程序之间又不会发生相互干扰，于是将整个用户空间划分为若干个固定大小的区域，在每个分区中只装入一道作业，这样就形成了最早的、也是最简单的一种可运行多道程序的分区式存储管理方式。</p><p>1）划分分区的方法</p><p>（1）分区大小相等</p><p>即所有的内存分区大小相等，其缺点是缺乏灵活性，当程序太小时，会造成内存空间的浪费，当程序太大时，一个分区又不足以装下该程序，致使该程序无法运行。</p><p>（2）分区大小不等</p><p>为了增加存储器分配的灵活性，应将存储器分区划分为若干个大小不等的分区。通常，可把内存划分成含有多个较小的分区、适量的中等分区及少量的大分区。</p><p>2）内存分配</p><p>为了便于内存分配，通常将分区按其大小进行排队，并为之建立一张分区使用表，其中各表项包括每个分区的起始地址、大小及状态。</p><h5 id="3-动态分区分配"><a href="#3-动态分区分配" class="headerlink" title="3. 动态分区分配"></a>3. 动态分区分配</h5><p>动态分区分配又称为可变分区分配，它是根据进程的实际需要，动态地为之分配内存空间。</p><p>在实现动态分区分配时，将涉及到分区分配中所用的数据结构、分区分配算法和分区的分配与回收操作这样三方面的问题。</p><p>1）动态分区分配中的数据结构</p><p>为了实现动态分区分配，系统中必须配置相应的数据结构来描述空闲分区和已分配分区的情况。常用的数据结构有以下 2 种形式，第一种是<strong>空闲分区表</strong>，它在系统每个空闲分区占一个表目，表目中包括分区号、分区大小和分区始址等数据项。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>12</td><td>20</td><td>空闲</td></tr><tr><td>2</td><td>32</td><td>32</td><td>空闲</td></tr><tr><td>3</td><td>64</td><td>64</td><td>空闲</td></tr><tr><td>4</td><td>128</td><td>128</td><td>空闲</td></tr></tbody></table></div><p>第二种是<strong>空闲分区链</strong>，每个分区的起始部分设置一些用于控制分区分配的信息，通过前、后向链接指针将所有的空闲分区链接成一个双向链。<br><img src="source/images/操作系统3：存储器管理/1774310-20210807142822348-1192454029.png" alt="img" style="zoom:67%;"></p><p>2）动态分区分配算法</p><p>基于顺序搜索的动态分区分配算法：首次适应算法、循环首次适应算法、最佳适应算法、最坏适应算法。</p><p>基于索引搜索的动态分区分配算法：快速适应算法、伙伴系统、哈希算法。</p><p>3）分区分配操作</p><p>（1）分配内存</p><p>系统应利用某种分配算法，从空闲分区链(表)中找到所需大小的分区。设请求的分区大小为 u.size，表中每个空闲分区的大小可表示为 m.size。若 m.size - u.size ≤ size(size 是事先规定的不再切割的剩余分区的大小)，说明多余部分太小可不再切割，将整个分区分配给请求者。如果多余部分超过 size，便从该分区中按请求的大小划分出一块内存空间分配出去，余下的部分仍留在空闲分区链(表)中，然后将分配区的首址返回给调用者。<br>例如当前的内存分配状态如图所示，内存分配表如图所示。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>20</td><td>5</td><td>空闲</td></tr><tr><td>2</td><td>5</td><td>35</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p><img src="../../../../Download/文档/操作系统笔记/source/images/第四章 存储器管理/1774310-20210808135130427-515015169.png" alt="img" style="zoom:67%;"><img src="../../../../Download/文档/操作系统笔记/source/images/第四章 存储器管理/1774310-20210808135449463-1125684133.png" alt="img" style="zoom:67%;"><img src="source/images/操作系统3：存储器管理/1774310-20210808140015206-1889854015.png" alt="img" style="zoom:67%;"><br>现在需要插入大小为 5M 的进程三，通过某种算法后插入分区 1，修改后的内存分配表和内存状态如下。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>15</td><td>10</td><td>空闲</td></tr><tr><td>2</td><td>5</td><td>35</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p>如果通过某种算法后插入分区 2，修改后的内存分配表可以把分区 2 删除。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>20</td><td>5</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p>（2）回收内存</p><p>当进程运行完毕释放内存时，系统根据回收区的首址，从空闲区链(表)中找到相应的插入点，此时可能出现以下四种情况之一。</p><p>情况一：</p><p>第一种情况是回收区与插入点的前一个空闲分区 F1。此时应将回收区与插入点的前一分区合并，不必为回收分区分配新表项，而只需修改其前一分区 F1 的大小。例如内存分配表和内存状态如下，此时要回收进程 1。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>20</td><td>5</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p><img src="source/images/操作系统3：存储器管理/1774310-20210808140015206-1889854015.png" alt="img" style="zoom:67%;"><img src="../../../../Download/文档/操作系统笔记/source/images/第四章 存储器管理/1774310-20210808140430171-399569346.png" alt="img" style="zoom:67%;"><br>将回收的空间和分区 1 和并，然后修改分区大小即可。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>30</td><td>5</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p>情况二：</p><p>第二种情况是回收分区与插入点的后一空闲分区 F2 相邻接，此时也可将两分区合并形成新的空闲分区，但用回收区的首址作为新空闲区的首址，大小为两者之和。例如内存分配表和内存状态如下，此时要回收进程 2。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>20</td><td>5</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p><img src="source/images/操作系统3：存储器管理/1774310-20210808140015206-1889854015.png" alt="img" style="zoom:67%;"><img src="../../../../Download/文档/操作系统笔记/source/images/第四章 存储器管理/1774310-20210808140757759-1490347801.png" alt="img" style="zoom:67%;"><br>将回收的空间和分区 3 和并，除了修改分区大小还要修改起始地址。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>20</td><td>5</td><td>空闲</td></tr><tr><td>3</td><td>30</td><td>40</td><td>空闲</td></tr></tbody></table></div><p>情况三：</p><p>第三种情况是回收区同时与插入点的前、后两个分区邻接，此时将三个分区合并，使用 F1 的表项和 F1 的首址并取消F2的表项，大小为三者之和。例如内存分配表和内存状态如下，此时要回收进程 1。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>15</td><td>10</td><td>空闲</td></tr><tr><td>2</td><td>5</td><td>35</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p><img src="../../../../Download/文档/操作系统笔记/source/images/第四章 存储器管理/1774310-20210808135449463-1125684133.png" alt="img" style="zoom:67%;"><img src="source/images/操作系统3：存储器管理/1774310-20210808141905297-131463450.png" alt="img" style="zoom:67%;"><br>将回收的空间和分区 1、2 和并，然后修改分区大小即可。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>30</td><td>10</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p>情况四：</p><p>第四种情况是回收区既不与 F1 邻接又不与 F2 邻接，这时应为回收区单独建立一个新表项，填写回收区的首址和大小，并根据其首址插入到空闲链中的适当位置。例如内存分配表和内存状态如下，此时要回收进程 3。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>20</td><td>5</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr></tbody></table></div><p><img src="source/images/操作系统3：存储器管理/1774310-20210808140015206-1889854015.png" alt="img" style="zoom:67%;"><img src="../../../../Download/文档/操作系统笔记/source/images/第四章 存储器管理/1774310-20210808151220610-1325146759.png" alt="img" style="zoom:67%;"><br>这时就需要向内存分配表加入一个新条目，并且写上大小和起始地址。</p><div class="table-container"><table><thead><tr><th>分区号</th><th>大小</th><th>起始地址</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>20</td><td>5</td><td>空闲</td></tr><tr><td>3</td><td>15</td><td>55</td><td>空闲</td></tr><tr><td>2</td><td>5</td><td>35</td><td>空闲</td></tr></tbody></table></div><h5 id="4-基于顺序搜索的动态分区分配算法"><a href="#4-基于顺序搜索的动态分区分配算法" class="headerlink" title="4. 基于顺序搜索的动态分区分配算法"></a>4. 基于顺序搜索的动态分区分配算法</h5><p>为了实现动态分区分配，通常是将系统中的空闲分区链接成一个链。所谓顺序搜索，是指依次搜索空闲分区链上的空闲分区，去寻找一个其大小能满足要求的分区。</p><p>1）首次适应（first fit,FF）算法</p><p>FF算法要求空闲分区链以地址递增的次序链接。在分配内存时，从链首开始顺序查找，直至找到一个大小能满足要求的空闲分区为止。该算法倾向于利用低址部分的空闲分区，从而保留了高址部分的大空闲区，这为以后到达的大作业分配大的内存空间创造了条件。其缺点是低址部分不断被划分，会留下很多难以利用的、很小的空闲分区，称为碎片。而每次查找又都是从低址部分开始的，这无疑又会增加查找可用空闲分区时的开销。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808151858269-1262905384.png" alt="img" style="zoom:67%;"></p><p>2）循环首次适应（next fit,NF）算法</p><p>循环首次适应算法在为进程分配内存空间时，不再是每次都从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直至找到一个能满足要求的空闲分区。为实现该算法，应设置一个起始查寻指针，用于指示下一次起始查询的空闲分区，并采用循环查找方式。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808152319108-419288793.png" alt="img" style="zoom:67%;"></p><p>3）最佳适应（best fit,BF）算法</p><p>所谓“最佳”是指，每次为作业分配内存时，总是能把满足要求、又是最小的空闲分区分配给作业，避免“大材小用”。为了加速寻找，该算法要求将所有的空闲分区按其容量以从小到大的顺序形成一空闲分区链。孤立地看，最佳适应算法似乎是最佳的，然而在宏观上却不一定。因为每次分配后所切割下来的剩余部分总是最小的，这样，在存储器中会留下许多难以利用的碎片。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808152512930-1737564250.png" alt="img" style="zoom:67%;"></p><p>4）最坏适应（worst fit,WF）算法</p><p>最坏适应算法选择空闲分区的策略正好与最佳适应算法相反：它在扫描整个空闲分区链时，总是挑选一个最大的空闲分区，从中分割一部分给作业使用，其缺点是会导致存储器中缺乏大的空闲分区，优点是可使剩下的空闲分区不至于太小，产生碎片的可能性最小，同时该算法的查找效率很高，因为该算法要求空闲分区按容量从大到小排序，查找时，只要看第一个 分区能否满足作业要求即可。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808152740243-43186705.png" alt="img" style="zoom:67%;"></p><h5 id="5-基于索引搜索的动态分区分配算法"><a href="#5-基于索引搜索的动态分区分配算法" class="headerlink" title="5. 基于索引搜索的动态分区分配算法"></a>5. 基于索引搜索的动态分区分配算法</h5><p>1）快速适应算法</p><p>该算法又称为分类搜索法，是将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表，这样系统中存在多个空闲分区链表。同时，在内存中设立一张管理索引表，其中的每一个索引表项对应了一种空闲分区类型，并记录了该类型空闲分区链表表头的指针。</p><p>该算法在搜索可用空闲分区时分为两步：第一步是根据进程的长度，从索引表中去寻找能容纳它的最小空闲区链表；第二步是从链表中取下第一块进行分配即可。另外，该算法不会对任何分区进行分割，所以不会产生碎片。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808154652546-363602472.png" alt="img" style="zoom:67%;"></p><p>2）伙伴系统</p><p><strong>伙伴系统(buddy system)</strong>算法规定无论已分配分区或空闲分区，其大小均为 2 的 k 次幂(k 为整数，1 ≤ k ≤ m)。将这些空闲分区按分区的大小进行分类，对于具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20220116192839497-722241483.png" alt="img" style="zoom: 67%;"></p><p>当需要为进程分配一个长度为 n 的存储空间时，首先计算一个 i (2^i-1 &lt; n ≤ 2^i)，然后在空闲分区大小为 2^i 的空闲分区链表中查找。若找到即把该空闲分区分配给进程。如果找不到表明长度为 2^i 的空闲分区已经耗尽，则在分区大小为 2^i+1 的空闲分区链表中寻找。若存在 2^i+1 的一个空闲分区，则把该空闲分区分为相等的两个分区，其中的一个分区用于分配，而把另一个加入分区大小为 2^i 的空闲分区链表中。如果还是找不到就继续搜索，以此类推。</p><p>在伙伴系统中，对于一个大小为 2^k，地址为 x 的内存块，其伙伴块的地址则用 buddyk(x)表示，其通式为：<br><img src="source/images/操作系统3：存储器管理/1774310-20210808155250765-962288082.png" alt="img" style="zoom: 80%;"><br>在回收空闲分区时，需要对空闲分区进行合并，所以其时间性能比快速适应算法差.但由于它采用了索引搜索算法，比顺序搜索算法好。由于对空闲分区进行合并，减少了小的空闲分区，提高了空闲分区的可使用率，故优于快速适应算法，比顺序搜索法略差。</p><p>3）哈希算法</p><p>哈希算法就是利用哈希快速查找的优点，以及空闲分区在可利用空闲区表中的分布规律建立哈希函数。构造一张以空闲分区大小为关键字的哈希表，该表的每一个表项记录了一个对应的空闲分区链表表头指针。当进行空闲分区分配时，根据所需空闲分区大小通过哈希函数计算，从中得到相应的空闲分区链表，实现最佳分配策略。<br><img src="source/images/操作系统3：存储器管理/1774310-20210808155520966-137472263.png" alt="img" style="zoom:67%;"></p><h5 id="6-动态可重定位分区分配"><a href="#6-动态可重定位分区分配" class="headerlink" title="6. 动态可重定位分区分配"></a>6. 动态可重定位分区分配</h5><p>1）紧凑</p><p>通过移动内存中作业的位置，把原来多个分散的小分区（碎片）拼接成一个大分区的方法，称为紧凑。在每次紧凑后，都必须对移动了的程序或数据进行重定位。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808160005788-1126592807.png" alt="img" style="zoom:67%;"><img src="../../../../Download/文档/操作系统笔记/source/images/第四章 存储器管理/1774310-20210808160224120-2121704243.png" alt="img" style="zoom:67%;"></p><p>2）动态重定位</p><p>把在装入时对目标程序中指令和数据地址的修改过程称为重定位。而把地址变换过程是在程序执行期间，随着对每条指令或数据的访问自动进行的，称为动态重定位。</p><p>3）动态重定位分区分配算法</p><p>动态重定位分区分配算法与动态分区分配算法的差别仅在于：在这种分配算法中，增加了紧凑的功能。</p><h4 id="4-4-覆盖与交换"><a href="#4-4-覆盖与交换" class="headerlink" title="4.4 覆盖与交换"></a>4.4 覆盖与交换</h4><h5 id="1-覆盖技术"><a href="#1-覆盖技术" class="headerlink" title="1. 覆盖技术"></a>1. 覆盖技术</h5><p>覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分，因此可把用户空间划分成一个固定区和若干覆盖区。将经常活跃的部分放在固定区，其余部分按调用关系分段。首先将那些即将要访问的段放入覆盖区，其它段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。</p><p>覆盖技术的特点是：打破了必须将一个进程的全部信息装入主存后才能运行的限制。</p><p>缺点：必须由程序员声明覆盖结构， 对用户不透明， 增加了用户的编程负担，覆盖技术只用于早期的操作系统中。</p><p><img src="source/images/操作系统3：存储器管理/e7a55d65c9d472ae9da88f25b4fdeb9d.png" alt="img" style="zoom:75%;"></p><h5 id="2-交换技术"><a href="#2-交换技术" class="headerlink" title="2. 交换技术"></a>2. 交换技术</h5><p>交换的基本思想是：把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又称换出；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称换入。</p><blockquote><p>内存空间紧张时, 系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(即<strong>进程在内存与磁盘间动态调度</strong>)。</p></blockquote><p>交换技术主要在不同进程之间进行，而覆盖则用于同一个程序或进程中。</p><p>对于主存无法存放用户程序的矛盾，现代操作系统是通过虚拟存储技术来解决的，而覆盖技术已经成为历史。</p><h4 id="4-5-分页存储管理方式"><a href="#4-5-分页存储管理方式" class="headerlink" title="4.5 分页存储管理方式"></a>4.5 分页存储管理方式</h4><p>连续分配管理方式会形成许多碎片，虽然可以通过紧凑方法将碎片拼接成可用的大块空间，但须为之付出很大开销。如果允许一个进程直接分散地装入到许多不邻接的分区中，便可充分的利用内存空间，而无需再紧凑。</p><p>基于这一思想产生了离散分配方式，根据在离散分配时所分配地址空间的基本单位的不同，又可将离散分配方式分为以下三种：</p><p>（1）分页存储管理方式：在该方式中，将用户程序的地址空间分为若干个固定大小的区域，称为页。相应地，也将内存空间分为若干个物理块，称为页框，页和块的大小相同。这样可以将用户程序的任一页放入任一物理块中，实现了离散分配。</p><p>（2）分段存储管理方式：段式存储管理方式按照用户进程中的自然段划分逻辑空间，以满足用户和程序员方便编程、信息保护和共享、动态增长以及动态链接等多方面的需要。</p><p>（3）段页式存储管理方式：结合分段和分页管理方式，综合两者的优点，先根据用户程序分段，再将每段分页。</p><h5 id="1-基本方法"><a href="#1-基本方法" class="headerlink" title="1. 基本方法"></a>1. 基本方法</h5><p>1）页面和物理块</p><p>（1）页面</p><p>分页存储管理是<strong>将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页</strong>，并为各页加以编号，从 0 开始，如第 0 页、第 1 页等。相应地，也<strong>把内存空间分成与页面相同大小的若干个存储块，称为(物理)块或页框(frame)</strong>，也同样为它们加以编号，如 0#块、1#块等等。在为进程分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相邻接的物理块中。由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为“<strong>页内碎片</strong>”。</p><p>（2）页面大小</p><p>在分页系统中的页面其大小应适中。页面若太小，一方面虽然可使内存碎片减小，从而减少了内存碎片的总空间，有利于提高内存利用率，但另一方面也会使每个进程占用较多的页面，从而导致进程的页表过长，占用大量内存；此外，还会降低页面换进换出的效率。然而，如果选择的页面较大，虽然可以减少页表的长度，提高页面换进换出的速度，但却又会使页内碎片增大。因此，页面的大小应选择适中，且页面大小应是 2 的幂，通常为 512 B～8 KB。</p><p>2）地址结构</p><p>分页地址中的地址结构如下：</p><p><img src="source/images/操作系统3：存储器管理/v2-11982304658dcb5ee2a0bb2323ceacf8_1440w.png" alt="img" style="zoom:80%;"></p><p>它含有两部分：前一部分为<strong>页号 P</strong>，后一部分为<strong>位移量 W</strong>(即页内地址)。图中的地址长度为 32 位，其中 0～11 位为页内地址，即每页的大小为 4 KB；12～31 位为页号，地址空间最多允许有 1 M 页。</p><p>对于某特定机器，其地址结构是一定的。若给定一个逻辑地址空间中的地址为 A，页面的大小为 L，则页号 P 和页内地址 d 可按下式求得：</p><p><img src="source/images/操作系统3：存储器管理/image-20220824172109340.png" alt="image-20220824172109340" style="zoom: 67%;"></p><p>其中，INT 是整除函数，MOD 是取余函数。即<code>P=A/L,d=A%L</code>。例如，其系统的页面大小为 1 KB，设 A = 2170 B，则由上式可以求得 P = 2，d = 122。</p><p>3）页表</p><p>在分页系统中，允许将进程的各个页离散地存储在内存不同的物理块中，但系统应能保证进程的正确运行，即能在内存中找到每个页面所对应的物理块。为此，系统又为每个进程建立了一张页面映像表，简称页表。在进程地址空间内的所有页(0～n)，依次在页表中有一页表项，其中记录了相应页在内存中对应的物理块号，见下图的中间部分。在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，<strong>页表的作用是实现从页号到物理块号的地址映射</strong>。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808230851706-1419585523.png" alt="img" style="zoom:67%;"></p><p>即使在简单的分页系统中，也常在页表的表项中设置一存取控制字段，用于对该存储块中的内容加以保护。当存取控制字段仅有一位时，可用来规定该存储块中的内容是允许读/写，还是只读；若存取控制字段为二位，则可规定为读/写、只读和只执行等存取方式。如果有一进程试图去写一个只允许读的存储块时，将引起操作系统的一次中断。如果要利用分页系统去实现虚拟存储器，则还须增设一数据项。</p><h5 id="2-地址变换机构"><a href="#2-地址变换机构" class="headerlink" title="2. 地址变换机构"></a>2. 地址变换机构</h5><p>1）基本地址变换机构</p><p>为了能将用户地址空间中的逻辑地址变换为内存空间中的物理地址，在系统中必须设置地址变换机构。该机构的基本任务是实现从逻辑地址到物理地址的转换。由于页内地址和物理地址是一一对应的(例如，对于页面大小是 1 KB 的页内地址是 0～1023，其相应的物理块内的地址也是 0～1023，无须再进行转换)，因此，<strong>地址变换机构的任务实际上只是将逻辑地址中的页号，转换为内存中的物理块号</strong>。又因为页面映射表的作用就是用于实现从页号到物理块号的变换，因此，地址变换任务是借助于页表来完成的。</p><p>页表的功能可以由一组专门的寄存器来实现。一个页表项用一个寄存器。由于寄存器具有较高的访问速度，因而有利于提高地址变换的速度；但由于寄存器成本较高，且大多数现代计算机的页表又可能很大，使页表项的总数可达几千甚至几十万个，显然这些页表项不可能都用寄存器来实现，因此，<strong>页表大多驻留在内存中</strong>。在系统中只设置一个页表寄存器 PTR(Page-Table Register)，在其中存放页表在内存的始址和页表的长度。平时，进程未执行时，页表的始址和页表长度存放在本进程的 PCB 中。当调度程序调度到某进程时，才将这两个数据装入页表寄存器中。因此，在单处理机环境下，虽然系统中可以运行多个进程，但只需一个页表寄存器。</p><p>当进程要访问某个逻辑地址中的数据时，分页地址变换机构会自动地将有效地址(相对地址)分为页号和页内地址两部分，再以页号为索引去检索页表。查找操作由硬件执行。在执行检索之前，先将页号与页表长度进行比较，如果页号大于或等于页表长度，则表示本次所访问的地址已超越进程的地址空间。于是，这一错误将被系统发现并产生一地址越界中断。若未出现越界错误，则<strong>将页表始址与页号和页表项长度的乘积相加，便得到该表项在页表中的位置，于是可从中得到该页的物理块号</strong>，将之装入物理地址寄存器中。与此同时，再将有效地址寄存器中的页内地址送入物理地址寄存器的块内地址字段中。这样便完成了从逻辑地址到物理地址的变换。下图为分页系统的地址变换机构。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210808233819512-1829312549.png" alt="img" style="zoom: 80%;"></p><p>2）具有快表的地址变换机构</p><p>由于页表是存放在内存中的，这使 CPU 在每存取一个数据时，都要两次访问内存。第一次是访问内存中的页表，从中找到指定页的物理块号，再将块号与页内偏移量 W 拼接，以形成物理地址。第二次访问内存时，才是从第一次所得地址中获得所需数据(或向此地址中写入数据)。因此，采用这种方式将使计算机的处理速度降低近 1/2。可见，以此高昂代价来换取存储器空间利用率的提高，是得不偿失的。</p><p>为了提高地址变换速度，可在地址变换机构中增设一个具有并行查寻能力的特殊高速缓冲寄存器，又称为“联想寄存器”(Associative Memory)，或称为“快表”，在 IBM 系统中又取名为 TLB(Translation Lookaside Buffer)，用以存放当前访问的那些页表项。此时的地址变换过程是：<strong>在 CPU 给出有效地址后，由地址变换机构自动地将页号 P 送入高速缓冲寄存器，并将此页号与高速缓存中的所有页号进行比较，若其中有与此相匹配的页号，便表示所要访问的页表项在快表中。于是，可直接从快表中读出该页所对应的物理块号，并送到物理地址寄存器中。</strong>如在块表中未找到对应的页表项，则还须再访问内存中的页表，找到后，把从页表项中读出的物理块号送地址寄存器；同时，再将此页表项存入快表的一个寄存器单元中，亦即，重新修改快表。但如果联想寄存器已满，则 OS 必须找到一个老的且已被认为不再需要的页表项，将它换出。下图为具有快表的地址变换机构。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809005149697-1877838704.png" alt="img" style="zoom: 80%;"></p><h5 id="3-访问内存的有效时间"><a href="#3-访问内存的有效时间" class="headerlink" title="3. 访问内存的有效时间"></a>3. 访问内存的有效时间</h5><p>从进程发出指定逻辑地址的访问请求，经过地址变换，到在内存中找到对应的实际物理地址单元并取出数据，所需要花费的总时间称为内存的<strong>有效访问时间(Effective AccessTime，EAT)</strong>。<br>假设访问一次内存的时间为 t，在基本分页存储管理方式中，有效访问时间分为 2 次访问内存时间之和：</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">EAT</span> = t + t = <span class="number">2</span>t</span><br></pre></td></tr></tbody></table></figure><p>在引入快表的分页存储管理方式中，如果快表命中可以直接得到逻辑页所对应的物理块号，减少了一次内存访问。命中率是指使用快表并在其中成功查找到所需页面的表项的比率，引入 TLB 的分页存储管理方式的 EAT 计算公式如下，其中 λ 表示查找快表所需要的时间，a 表示命中率，t 表示访问一次内存所需要的时间。</p><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">EAT = a × λ + (t + λ)(1 - a) + t </span><br><span class="line">    = 2t + λ - t x a</span><br></pre></td></tr></tbody></table></figure><p>例如某系统使用基本分页存储管理，并采用了具有快表的地址变换机构。访问一次快表耗时 1us，访问一次内存耗时 100us，若快表的命中率为 90%，访问一个逻辑地址的平均耗时通过计算可以得到。</p><figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">快表和慢表分开查找：(1 + 100) <span class="emphasis">* 0.9 + (1 + 100 + 100) *</span> 0.1 = 111 us</span><br><span class="line">快表和慢表同时查找：(1 + 100) <span class="emphasis">* 0.9 + (100 + 100)     *</span> 0.1 = 110.9 us</span><br></pre></td></tr></tbody></table></figure><p>若未采用快表机制，则访问一个逻辑地址需要 100 + 100 = 200us，显然引入快表机制后访问一个逻辑地址的速度被加快。</p><h5 id="4-两级和多级页表"><a href="#4-两级和多级页表" class="headerlink" title="4. 两级和多级页表"></a>4. 两级和多级页表</h5><p>现代的大多数计算机系统，都支持非常大的逻辑地址空间($2^{32}B$~$2^{64}B$​)。在这样的环境下，页表就变得非常大，要占用相当大的内存空间。例如，对于一个具有 32 位逻辑地址空间的分页系统，规定页面大小为 4 KB 即 $2^{12}$ B，则在每个进程页表中的页表项可达 1 兆个之多。又因为每个页表项占用一个字节，故每个进程仅仅其页表就要占用 1 MB 的内存空间，而且还要求是连续的。显然这是不现实的，我们可以采用下述两个方法来解决这一问题：</p><ul><li>采用离散分配方式来解决难以找到一块连续的大内存空间的问题；</li><li>只将当前需要的部分页表项调入内存，其余的页表项仍驻留在磁盘上，需要时再调入。</li></ul><p>1）两级页表</p><p>对于要求连续的内存空间来存放页表的问题，可利用将页表进行分页，并离散地将各个页面分别存放在不同的物理块中的办法来加以解决，同样也要为离散分配的页表再建立一张页表，称为外层页表(Outer Page Table)，在每个页表项中记录了页表页面的物理块号。下面我们仍以前面的 32 位逻辑地址空间为例来说明。当页面大小为 4 KB 时( 12 位)，若采用一级页表结构，应具有 20 位的页号，即页表项应有 1 兆个；在采用两级页表结构时，再对页表进行分页，使每页中包含 $2^{10}$ (即 1024) 个页表项，最多允许有 $2^{10}$ 个页表分页；或者说，外层页表中的外层页内地址 P2为 10 位，外层页号 P1也为 10 位。此时的逻辑地址结构可描述如下：</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809151345496-1882693214.png" alt="img" style="zoom:80%;"></p><p>由图可以看出，在页表的每个表项中存放的是进程的某页在内存中的物理块号，如第0#页存放在 1#物理块中；1#页存放在 4#物理块中。而在外层页表的每个页表项中，所存放的是某页表分页的首址，如第 0#页表是存放在第 1011#物理块中。我们可以利用外层页表和页表这两级页表，来实现从进程的逻辑地址到内存中物理地址间的变换。</p><p>为了地址变换实现上的方便起见，在地址变换机构中同样需要增设一个外层页表寄存器，用于存放外层页表的始址，并利用逻辑地址中的外层页号，作为外层页表的索引，从中找到指定页表分页的始址，再利用 P2 作为指定页表分页的索引，找到指定的页表项，其中即含有该页在内存的物理块号，用该块号和页内地址 d 即可构成访问的内存物理地址。下图为两级页表时的地址变换机构。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809153421054-440132979.png" alt="img" style="zoom:80%;"></p><p>上述对页表施行离散分配的方法，虽然解决了对大页表无需大片存储空间的问题，但并未解决用较少的内存空间去存放大页表的问题。换言之，只用离散分配空间的办法并未减少页表所占用的内存空间。解决方法是把当前需要的一批页表项调入内存，以后再根据需要陆续调入。在采用两级页表结构的情况下，对于正在运行的进程，必须将其外层页表调入内存，而对页表则只需调入一页或几页。为了表征某页的页表是否已经调入内存，还应在外层页表项中增设一个状态位 S，其值若为 0，表示该页表分页尚未调入内存；否则，说明其分页已在内存中。进程运行时，地址变换机构根据逻辑地址中的 P1，去查找外层页表；若所找到的页表项中的状态位为 0，则产生一中断信号，请求 OS 将该页表分页调入内存。</p><p>2）多级页表</p><p>当使用的计算机的位数不同时，可能会继续拓展到多级页表，将外层页表再进行分页，将各分页离散地装入到不相邻接的物理块中，再利用第 2 级的外层页表来映射它们之间的关系。若采用多级页表机制，则各级页表的大小不能超过一个页面。例如某系统按字节编址，采用 40 位逻辑地址，页面大小为 4KB，页表项大小为 4B，假设采用纯页式存储，则要采用几级页表？页内偏移量为几位?<br>首先页面大小 = 4KB = 2^12B，按字节编址的页内偏移量为 12 位。页号 = 40 - 12 = 28 位，页面大小 = 2^12B，页表项大小 = 4B，则每个页面可存放 212 / 4 = 210 个页表项。此时需要 10 位二进制位才能映射到 210 个页表项，因此每一级的页表对应页号应为 10 位。总共 28 位的页号至少要分为三级。</p><h5 id="5-反置页表"><a href="#5-反置页表" class="headerlink" title="5. 反置页表"></a>5. 反置页表</h5><p>1）反置页表的引入</p><p>在分页系统中为每个进程配置了一张页表，进程逻辑地址空间中的每一页在页表中都对应有一个页表项。在现代计算机系统中，通常允许一个进程的逻辑地址空间非常大，因此就需要有许多的页表项，而因此也会占用大量的内存空间。为了减少页表占用的内存空间，引入了反置页表。<strong>反置页表(Inverted Page Table)</strong>则为每一个物理块设置一个页表项，并将它们按物理块的编号排序，其中的内容则是页号和其所隶属进程的标识符。</p><p>2）地址变换</p><p>在利用反置页表进行地址变换时，是根据进程标识符和页号检索反置页表。如果检索到与之匹配的页表项，则该页表项(中)的序号 i 便是该页所在的物理块号，可用该块号与页内地址一起构成物理地址送内存地址寄存器。若检索了整个反置页表仍未找到匹配的页表项，则表明此页尚未装入内存。对于不具有请求调页功能的存储器管理系统，此时则表示地址出错。</p><p>然而在该表中只包含了已经调入内存的页面，并未包含尚未调入内存的页面，因此还必须为每个进程建立一个外部页表。(External Page Table)。该页表与传统的页表一样，当所访问的页面在内存时，并不需要访问外部页表，仅当发现所需之页面不在内存时才使用。在页表中包含了各个页在外存的物理位置，通过它可将所需之页面调入内存。</p><p>由于在反置页表中是为每一个物理块设置一个页表项，当内存容量很大时，页表项的数目还是会非常大的。要利用进程标识符和页号去检索这样大的一张线性表是相当费时的，可利用 Hash 算法来进行检索。</p><h4 id="4-6-分段存储管理方式"><a href="#4-6-分段存储管理方式" class="headerlink" title="4.6 分段存储管理方式"></a>4.6 分段存储管理方式</h4><p>在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。在分段系统中，实现共享则容易得多，只需在每个进程的段表中为文本编辑程序设置一个段表项。</p><p>如果说推动存储管理方式从固定分区到动态分区分配，进而又发展到分页存储管理方式的主要动力，是提高内存利用率，那么，引入分段存储管理方式的目的，则主要是为了满足用户（程序员）在编程和使用上多方面的要求，其中有些要求是其它几种存储管理方式所难以满足的。因此，这种存储管理方式已成为当今所有存储管理方式的基础。</p><h5 id="1-分段存储管理方式的引入"><a href="#1-分段存储管理方式的引入" class="headerlink" title="1. 分段存储管理方式的引入"></a>1. 分段存储管理方式的引入</h5><p>引入分段存储管理方式，主要是为了满组用户和程序员的下述一系列需要：</p><p><strong>1) 方便编程</strong></p><p>通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都是从0开始编址，并有自己的名字和长度。因此，希望要访问的逻辑地址是由段名(段号)和段内偏移量(段内地址)决定的。例如，下述的两条指令便是使用段名和段内地址：</p><p><strong>LOAD 1，[A] |〈D〉；</strong></p><p><strong>STORE 1，[B] |〈C〉；</strong></p><p>其中，前一条指令的含义是将分段A中D单元内的值读入 <a href="https://siaoyin.com/Info/7457733957403597544">寄存器</a> 1；后一条指令的含义是将寄存器1的内容存入B分段的C单元中。</p><p><strong>2) 信息共享</strong></p><p>在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，共享某个例程和函数。分页系统中的“页”只是存放信息的物理单位(块)，并无完整的意义，不便于实现共享；然而段却是信息的逻辑单位。由此可知，为了实现段的共享，希望存储管理能与用户程序分段的组织方式相适应。</p><p><strong>3) 信息保护</strong></p><p>信息保护同样是对信息的逻辑单位进行保护，因此，分段管理方式能更有效和方便地实现信息保护功能。</p><p><strong>4) 动态增长</strong></p><p>在实际应用中，往往有些段，特别是数据段，在使用过程中会不断地增长，而事先又无法确切地知道数据段会增长到多大。前述的其它几种存储管理方式，都难以应付这种动态增长的情况，而分段存储管理方式却能较好地解决这一问题。</p><p><strong>5) 动态链接</strong></p><p>动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主程序所对应的目标程序装入内存并启动运行，当运行过程中又需要调用某段时，才将该段(目标程序)调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。</p><h5 id="2-分段系统的基本原理"><a href="#2-分段系统的基本原理" class="headerlink" title="2. 分段系统的基本原理"></a>2. 分段系统的基本原理</h5><p>1）分段</p><p>在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。例如，有主程序段MAIN、子程序段X、数据段D及栈段S等，如图4-17所示。每个段都有自己的名字。为了实现简单起见，通常可用一个段号来代替段名，每个段都从0开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，因而各段长度不等。整个作业的地址空间由于是分成多个段，因而是二维的，亦即，其逻辑地址由段号(段名)和段内地址所组成。</p><p>分段地址中的地址具有如下结构：</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809202153407-723123847.png" alt="img" style="zoom:67%;"></p><p>在该地址结构中，允许一个作业最长有 64 K个段，每个段的最大长度为64 KB。分段方式已得到许多编译程序的支持，编译程序能自动地根据源程序的情况而产生若干个段。例如，Pascal编译程序可以为全局变量、用于存储相应参数及返回地址的过程调用栈、每个过程或函数的代码部分、每个过程或函数的局部变量等等，分别建立各自的段。类似地，Fortran编译程序可以为公共块(Common block)建立单独的段，也可以为数组分配一个单独的段。装入程序将装入所有这些段，并为每个段赋予一个段号。</p><p>2）段表</p><p>在前面所介绍的动态分区分配方式中，系统为整个进程分配一个连续的内存空间。而在分段式存储管理系统中，则是为每个分段分配一个连续的分区，而进程中的各个段可以离散地移入内存中不同的分区中。为使程序能正常运行，亦即，能从物理内存中找出每个逻辑段所对应的位置，应像分页系统那样，在系统中为每个进程建立一张段映射表，简称“段表”。每个段在表中占有一个表项，其中记录了该段在内存中的起始地址(又称为“基址”)和段的长度，如右图所示。段表可以存放在一组寄存器中，这样有利于提高地址转换速度，但更常见的是将段表放在内存中。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809204111777-1592732636.png" alt="img" style="zoom: 67%;"></p><p>3）地址变换机构</p><p>为了实现从进程的逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表始址和段表长度TL。在进行地址变换时，系统将逻辑地址中的段号与段表长度TL进行比较。若S&gt;TL，表示段号太大，是访问越界，于是产生越界中断信号；若未越界，则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的起始地址，然后，再检查段内地址d是否超过该段的段长SL。若超过，即d&gt;SL，同样发出越界中断信号；若未越界，则将该段的基址d与段内地址相加，即可得到要访问的内存物理地址。</p><p>下图示出了分段系统的地址变换过程。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809205219873-404407898.png" alt="img" style="zoom:80%;"></p><p>像分页系统一样，当段表放在内存中时，每要访问一个数据，都须访问两次内存，从而极大地降低了计算机的速率。解决的方法也和分页系统类似，再增设一个联想存储器，用于保存最近常用的段表项。由于一般情况是段比页大，因而段表项的数目比页表项的数目少，其所需的联想存储器也相对较小，便可以显著地减少存取数据的时间，比起没有地址变换的常规存储器的存取速度来仅慢约10%～15%。</p><h5 id="3-信息共享"><a href="#3-信息共享" class="headerlink" title="3. 信息共享"></a>3. 信息共享</h5><p>分段系统的一个突出优点，是易于实现段的共享，即允许若干个进程共享一个或多个分段，且对段的保护也十分简单易行。在分页系统中，虽然也能实现程序和数据的共享，但远不如分段系统来得方便。我们通过一个例子来说明这个问题。例如，有一个多用户系统，可同时接纳40个用户，他们都执行一个文本编辑程序(Text Editor)。如果文本编辑程序有160 KB的代码和另外40 KB的数据区，则总共需有 8 MB的内存空间来支持40个用户。如果160 KB的代码是可重入的（reentrant），则无论是在分页系统还是在分段系统中，该代码都能被共享，在内存中只需保留一份文本编辑程序的副本，此时所需的内存空间仅为1760 KB(40×40+160)，而不是8000 KB。</p><p>假定每个页面的大小为4 KB，那么，160 KB的代码将占用40个页面，数据区占10个页面。为实现代码的共享，应在每个进程的页表中都建立40个页表项，它们的物理块号都是21#～60#。在每个进程的页表中，还须为自己的数据区建立页表项，它们的物理块号分别是61#～70#、71#～80#、81#～90#，…，等等。下图是分页系统中共享editor的示意。</p><p><img src="source/images/操作系统3：存储器管理/image-20220824173248052.png" alt="image-20220824173248052" style="zoom:67%;"></p><p>在分段系统中，实现共享则容易得多，只需在每个进程的段表中为文本编辑程序设置一个段表项。下图是分段系统中共享editor的示意图。</p><p><img src="source/images/操作系统3：存储器管理/image-20220824173319597.png" alt="image-20220824173319597" style="zoom:67%;"></p><p>可重入代码(Reentrant Code)又称为“纯代码”(Pure Code)，是一种允许多个进程同时访问的代码。为使各个进程所执行的代码完全相同，绝对不允许可重入代码在执行中有任何改变。因此，可重入代码是一种不允许任何进程对它进行修改的代码。但事实上，大多数代码在执行时都可能有些改变，例如，用于控制程序执行次数的变量以及指针、信号量及数组等。为此，在每个进程中，都必须配以局部数据区，把在执行中可能改变的部分拷贝到该数据区，这样，程序在执行时，只需对该数据区（属于该进程私有）中的内容进行修改，并不去改变共享的代码，这时的可共享代码即成为可重入码。</p><h5 id="4-分段和分页的主要区别"><a href="#4-分段和分页的主要区别" class="headerlink" title="4. 分段和分页的主要区别"></a>4. 分段和分页的主要区别</h5><p>分页和分段系统有许多相似之处。比如，两者都采用离散分配方式，且都要通过地址映射机构来实现地址变换。但在概念上两者完全不同，主要表现在下述三个方面。</p><p>(1) 页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。段则是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。</p><p>(2) 页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而段的长度却不固定，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。</p><p>(3) 分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间则是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。</p><h5 id="5-段页式存储管理方式"><a href="#5-段页式存储管理方式" class="headerlink" title="5. 段页式存储管理方式"></a>5. 段页式存储管理方式</h5><p>前面所介绍的分页和分段存储管理方式都各有其优缺点。分页系统能有效地提高内存利用率，而分段系统则能很好地满足用户需要。如果能对两种存储管理方式“各取所长”，则可以将两者结合成一种新的存储管理方式系统。这种新系统既具有分段系统的便于实现、分段可共享、易于保护、可动态链接等一系列优点，又能像分页系统那样很好地解决内存的外部碎片问题，以及可为各个分段离散地分配内存等问题。把这种结合起来形成的新系统称为“段页式系统”。</p><p>1）基本原理</p><p>段页式系统的基本原理，是分段和分页原理的结合，即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。下图一个作业地址空间的结构。该作业有三个段，页面大小为 4 KB。</p><p><img src="source/images/操作系统3：存储器管理/image-20220824173406111.png" alt="image-20220824173406111" style="zoom:67%;"></p><p>在段页式系统中，其地址结构由段号、段内页号及页内地址三部分所组成，如上图所示。</p><p>在段页式系统中，为了实现从逻辑地址到物理地址的变换，系统中需要同时配置段表和页表。段表的内容不再是内存始址和段长，而是页表始址和页表长度。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809221054415-1013582389.png" alt="img" style="zoom: 67%;"></p><p>2）地址变换过程</p><p>在段页式系统中，为了便于实现地址变换，须配置一个段表寄存器，其中存放段表始址和段表长 TL。进行地址变换时，首先利用段号 S，将它与段表长 TL 进行比较。若 S&lt;TL，表示未越界，于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的页表始址，并利用逻辑地址中的段内页号 P 来获得对应页的页表项位置，从中读出该页所在的物理块号 b，再利用块号 b 和页内地址来构成物理地址。下图是段页式系统中的地址变换机构。</p><p><img src="source/images/操作系统3：存储器管理/1774310-20210809224418501-1762243473.png" alt="img"></p><p>在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内存中的段表，从中取得页表始址；第二次访问是访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正从第二次访问所得的地址中，取出指令或数据。</p><p>显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一个高速缓冲寄存器。每次访问它时，都须同时利用段号和页号去检索高速缓存，若找到匹配的表项，便可从中得到相应页的物理块号，用来与页内地址一起形成物理地址；若未找到匹配表项，则仍须再三次访问内存。由于它的基本原理与分页及分段的情况相似，故在此不再赘述。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统2：处理机调度与死锁</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-2-chu-li-ji-diao-du-yu-si-suo/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-2-chu-li-ji-diao-du-yu-si-suo/</url>
      
        <content type="html"><![CDATA[<h1 id="第三章-处理机调度与死锁"><a href="#第三章-处理机调度与死锁" class="headerlink" title="第三章 处理机调度与死锁"></a>第三章 处理机调度与死锁</h1><blockquote><p>在多道程序环境下，内存中存在着多个进程，其数目往往多于处理机的数目。这就要求系统能按照某种算法，动态地将处理机分配给处于就绪状态的一个进程，使之执行。分配处理机的任务由处理机调度程序完成。调度的实质是一种资源分配，处理机调度是对处理机资源进行分配。</p></blockquote><h4 id="3-1-处理机调度层次和调度算法的目标"><a href="#3-1-处理机调度层次和调度算法的目标" class="headerlink" title="3.1 处理机调度层次和调度算法的目标"></a>3.1 处理机调度层次和调度算法的目标</h4><p>一、处理机调度的层次</p><h5 id="1-高级调度"><a href="#1-高级调度" class="headerlink" title="1. 高级调度"></a>1. 高级调度</h5><p>高级调度又称为长程调度或<strong>作业调度</strong>，它的调度对象是作业。其主要功能是根据某种算法，决定将外存上处于后备队列中的哪几个作业调入内存，为它们创建进程、分配必要的资源，并将它们放入就绪队列。高级调度主要用于多道批处理系统中，而在分时系统和实时系统中不设置高级调度。</p><h5 id="2-低级调度"><a href="#2-低级调度" class="headerlink" title="2. 低级调度"></a>2. 低级调度</h5><p>低级调度又称为短程调度或<strong>进程调度</strong>，其所调度的对象是进程（或内核级线程）。其主要的功能是，根据某种算法，决定就绪队列中的哪个进程应获得处理机，并由分派程序将处理机分配给被选中的进程。进程调度是最基本的一种调度，在多道批处理、分时和实时三种类型的OS中，都必须配置进程调度。进程调度的运行频率最高，不宜使进程调度算法太复杂。</p><h5 id="3-中级调度"><a href="#3-中级调度" class="headerlink" title="3. 中级调度"></a>3. 中级调度</h5><p>中级调度又称为<strong>内存调度</strong>。引入中级调度的主要目的是，提高内存利用率和系统吞吐量。为此，应把那些暂时不能运行的进程，调至外存等待，此时进程的状态称为就绪驻外存状态（或挂起状态）。当它们已具备运行条件且内存又稍有空闲时，由中级调度来决定，把外存上的那些已具备运行条件的就绪进程再重新调入内存，并修改其状态为就绪状态，挂在就绪队列上等待。</p><p>中级调度实际上就是存储器管理中的对换功能，将在第四章中介绍。</p><p>二、处理机调度算法的目标</p><h5 id="4-调度算法的共同目标"><a href="#4-调度算法的共同目标" class="headerlink" title="4. 调度算法的共同目标"></a>4. 调度算法的共同目标</h5><p>1）资源利用率。为提高系统的资源利用率，应使系统中的处理机和其它所有资源都尽可能地保持忙碌状态。其中最重要的处理机利用率可以用以下方法计算：</p><script type="math/tex; mode=display">CPU利用率=\frac{CPU有效工作时间}{CPU有效工作时间+CPU空闲等待时间}</script><p>2）公平性。公平性是指应使诸进程都获得合理的CPU时间，不会发生进程饥饿现象。</p><p>3）平衡性。在系统中可能具有多种类型的进程，有的属于计算型作业，有的属于I/O型，调度算法应尽可能保持其平衡。</p><p>4）策略强制执行。对所制定的策略其中包括安全策略，只要需要，就必须予以准确地执行，即使会造成某些工作的延迟也要执行。</p><h5 id="5-批处理系统的目标"><a href="#5-批处理系统的目标" class="headerlink" title="5. 批处理系统的目标"></a>5. 批处理系统的目标</h5><p>1）平均周转时间短。所谓周转时间，是指从作业被提交给系统开始，到作业完成为止的这段时间间隔。它包括四部分时间：在外存后备队列上等待作业调度的时间、在内存就绪队列上等待进程调度的时间、进程在CPU上执行的时间，以及进程等待I/O操作完成的时间。</p><p>对于每个用户而言，都希望自己作业的周转时间最短，而对于计算机系统的管理者而言，则希望作业的平均周转时间最短。作业的平均周转时间即为各作业周转时间的平均值。</p><p>为了进一步反映调度的性能，更清晰地描述各进程在其周转时间中，等待和执行时间的具体分配状况，往往使用带权周转时间，即作业的周转时间$T$与系统为它提供服务的时间$T_{s}$之比,即$W=T/T_{S}$。</p><p>故平均带权周转时间为各作业带权周转时间的平均值，即：</p><script type="math/tex; mode=display">W=\frac{1}{n}\sum_{i=1}^{n}{\frac{T_{i}}{T_{s}}}</script><p>2）系统吞吐量高。由于吞吐量是指在单位时间内系统所完成的作业数，因而它与批处理作业的平均长度有关。</p><p>3）处理机的利用率高。</p><h5 id="6-分时系统的目标"><a href="#6-分时系统的目标" class="headerlink" title="6. 分时系统的目标"></a>6. 分时系统的目标</h5><p>1）响应时间快。所谓响应时间，是从用户通过键盘提交一个请求开始，直到屏幕上出现处理结果为之的一段时间间隔。</p><p>2）均衡性。指系统响应时间的快慢应与用户所请求服务的复杂性相适应。</p><h5 id="7-实时系统的目标"><a href="#7-实时系统的目标" class="headerlink" title="7. 实时系统的目标"></a>7. 实时系统的目标</h5><p>1）截至时间的保证。所谓截止时间，是指某任务必须开始执行的最迟时间，或必须完成的最迟时间。对于严格的实时系统，其调度方式和调度算法必须能保证这一点。</p><p>2）可预测性。</p><h4 id="3-2-作业与作业调度"><a href="#3-2-作业与作业调度" class="headerlink" title="3.2 作业与作业调度"></a>3.2 作业与作业调度</h4><p>在多道批处理系统中，作业是用户提交给系统的一项相对独立的工作。作业通过输入设备输入到磁盘存储器，并保存在一个后备作业队列中，再由作业调度程序将其从外存调入内存。</p><h5 id="1-批处理系统中的作业"><a href="#1-批处理系统中的作业" class="headerlink" title="1. 批处理系统中的作业"></a>1. 批处理系统中的作业</h5><p>1）作业与作业步</p><p>作业（Job）：作业不仅包含了通常的程序和数据，而且还应配有一份作业说明书，系统根据该说明书来对程序的运行进行控制。在批处理系统中，是以作业为基本单位从外存调入内存的。</p><p>作业步（Job Step）：通常，在作业运行期间，每个作业都必须经过若干个相对独立又相互关联的顺序加工步骤才能得到结果，我们把其中的每个步骤称为一个作业步。</p><p>2）作业控制块JCB</p><p>为了管理和调度作业，在多道批处理系统中，为每个作业设置了一个作业控制块JCB，它是作业在系统中存在的标志，其中保存了系统对作业进行管理和调度所需的全部信息。</p><p>通常在JCB中包含的内容有：作业标识、用户名称、用户账号、作业类型、作业状态、调度信息、资源需求、资源使用情况等。</p><p>3）作业运行的阶段</p><p>作业从进入系统到运行结束，通常需要经历收容、运行和完成三个阶段。相应地，作业也就有后备状态、运行状态和完成状态。</p><h5 id="2-作业调度的主要任务"><a href="#2-作业调度的主要任务" class="headerlink" title="2. 作业调度的主要任务"></a>2. 作业调度的主要任务</h5><p>作业调度的主要任务是，根据JCB中的信息，检查系统中的资源能否满足作业对资源的需求，以及按照一定的调度算法，从外存的后备队列中选取某些作业调入内存，并为它们创建进程、分配必要的资源。然后再将新创建的进程排在就绪队列上等待调度。</p><p>每次执行作业调度时，都需要做出两个决定：接纳多少作业和接纳哪些作业。</p><p>对系统来说，希望装入较多的作业，有利于提高CPU的利用率和系统吞吐量。但如果内存中同时运行的作业太多，进程在运行时因为内存不足所发生的中断就会急剧增加。这将会使平均周转时间显著延长，影响到系统的服务质量。因此，多道程序度的确定是根据计算机的系统规模、运行速度、作业大小，以及能否获得较好的系统性能等情况作出适当的抉择的。</p><p>接纳哪些作业取决于所采用的调度算法。</p><h5 id="3-作业调度算法"><a href="#3-作业调度算法" class="headerlink" title="3. 作业调度算法"></a>3. 作业调度算法</h5><p>1）先来先服务（first-come first-served,FCFS）调度算法</p><p>系统按照作业的先后到达次序来进行调度。或者说它是在优先考虑在系统中等待时间最长的作业，而不考虑该作业所需执行时间的长短。FCFS是最简单的调度算法，既可以用于作业调度，也可以用于进程调度。FCFS算法在单处理机系统中已很少作为主调度算法，但经常把它与其它调度算法相结合，形成一种更为有效的算法。</p><p>特点：算法简单但效率低；对长作业有利，对短作业不利（相对于短作业优先和高响应比优先算法）；有利于CPU繁忙型作业，而不利于I/O繁忙型作业。</p><p>2）短作业优先（short job first,SJF）调度算法</p><p>短作业优先算法是以作业的长短来计算优先级，作业越短，其优先级越高。作业的长短是以作业所要求的运行时间来衡量的。SJF算法可以分别用于进程调度和作业调度。短作业优先算法的优点是作业的平均等待时间、平均周转时间最少，因为长作业在最后运行，不会出现长作业运行时有多个短作业同时等待的情况。</p><p>短作业优先调度算法的缺点：</p><ol><li>必须预知作业的运行时间。</li><li>对长作业非常不利，长作业的周转时间会明显的增长。</li><li>在采用SJF算法时，人机无法实现交互。</li><li>该调度算法没有考虑作业的紧迫程度，故不能保证紧迫性作业能够得到及时处理。</li></ol><p>3）优先级调度算法（PSA）</p><p>在优先级调度算法中，基于作业的紧迫程度，由外部赋予作业相应的优先级，紧迫程度高的作业优先调度。这样就可以保证紧迫性作业优先运行。优先级调度算法可以作为作业调度算法，也可以作为进程调度算法。</p><p>4）高响应比优先调度算法（HRRN）</p><p>在批处理系统中，FCFS算法所考虑的只是作业的等待时间，而忽视了作业的运行时间。而SJF算法则正好相反，只考虑作业的运行时间，而忽视了作业的等待时间。高响应比优先调度算法则既考虑了作业的等待时间，又考虑了作业的运行时间。因此既照顾了短作业，又不致使长作业的等待时间过长，从而改善了处理机调度的性能。</p><p>高响应比优先调度算法为每个作业引入一个动态的优先级，优先级随着等待时间的延长而增加，这使长作业的优先级在等待过程中不断增加，等到足够的时间后，必然有机会获得处理机。优先级的变化规律可描述为：</p><script type="math/tex; mode=display">优先权=\frac{等待时间+要求服务时间}{要求服务时间}</script><p>等待时间与服务时间之和就是系统对该作业的响应时间，故优先级相当于响应比$R_{p}$。</p><script type="math/tex; mode=display">R_{P}=\frac{等待时间+要求服务时间}{要求服务时间}=\frac{响应时间}{要求服务时间}</script><p>由上式可以看出：</p><ol><li>如果作业的等待时间相同，则要求服务的时间越短，其优先权越高，因而类似于SJF算法，有利于短作业。</li><li>当要求服务的时间相同时，作业的优先权又决定于其等待时间，等待时间越长优先级越高，因而该算法又类似于FCFS算法。</li><li>对于长作业的优先级，可以随等待时间的增加而提高，其等待时间足够长时，也可获得处理机。</li></ol><p>因此该算法实现了较好的折中。当然在利用该算法时，每次进行调度之前都需要先做响应比的计算，显然会增加系统开销。</p><h4 id="3-3-进程调度"><a href="#3-3-进程调度" class="headerlink" title="3.3 进程调度"></a>3.3 进程调度</h4><p>进程调度是操作系统中必不可少的一种调度。</p><h5 id="1-进程调度的任务、机制和方式"><a href="#1-进程调度的任务、机制和方式" class="headerlink" title="1. 进程调度的任务、机制和方式"></a>1. 进程调度的任务、机制和方式</h5><p>1）进程调度的任务</p><p>进程调度的任务主要有三：</p><p>（1）保存处理机的现场信息。在进行调度时首先要保存当前进程的处理机的现场信息，如程序计数器、多个寄存器中的内容等。</p><p>（2）按某种算法选取进程。调度程序按某种算法从就绪队列中选取一个进程，将其状态改为运行状态，并准备把处理机分配给它。</p><p>（3）把处理机分配给进程。由分派程序把处理机分配给该进程，此时需要将选中进程的进程控制块内有关处理机现场的信息装入处理器相应的各个寄存器内，把处理器的控制权交给该进程，让它从上次的断点处恢复运行。</p><p>2）进程调度的机制</p><p>为了实现进程调度，在进程调度机制中应包含如下三个基本部分。</p><p>（1）排队器。为了提高进程调度的效率，应事先将系统中的所有就绪进程按照一定的策略排成一个或多个队列，以便调度程序能够尽快地找到它。以后每有一个进程转变为就绪状态时，排队器便将它插入到相应的就绪队列。</p><p>（2）分派器。分派器依照进程调度程序所选定的进程，将其从就绪队列中取出，然后进行从分派器到新选出进程间的上下文切换，将处理机分配给新选出的进程。</p><p>（3）上下文切换器。在对处理机进行切换时，会发生两对上下文切换操作：一、第一对上下文切换时，OS将保存当前进程的上下文，即把当前的处理机寄存器内容保存到该进程进程控制块的相应单元，再装入分派程序的上下文，以便分派程序运行。二、第二对上下文切换是移出分派程序的上下文，而把新选进程的CPU现场信息装入到处理机的各个相应寄存器中，以便新选进程运行。</p><p>在进行上下文切换时需要执行大量的load和store等操作指令，需要花费大量的时间。现在已有靠硬件实现的方法来减少上下文切换的时间。一般采用两组寄存器，一组寄存器供处理机在系统态时使用，而另一组寄存器供应用程序使用，切换上下文只需改变指针，使其指向当前寄存器组即可。</p><p><img src="source/images/操作系统2：处理机调度与死锁/1774310-20210804135512985-298150332.png" alt="img" style="zoom:80%;"></p><p>3）进程调度的方式</p><p>（1）非抢占方式</p><p>在采用非抢占方式时，一旦把处理机分配给某进程后，就一直让它运行下去，绝不会因为时钟中断或其它任何原因去抢占当前正在运行下进程的处理机，直至该进程完成或发生某事件而被阻塞时，才把处理机分配给其它进程。</p><p>在采用非抢占调度方式时，可能引起进程调度的因素可归结为：</p><ol><li>正在执行的进程运行完毕，或因发生某事件而使其无法继续运行。</li><li>正在执行中的进程因提出I/O请求而暂停执行。</li><li>在进程通信或同步的过程中，执行了某种原语操作，如Block原语。</li></ol><p>这种调度方式的优点是实现简单、系统开销小，适用于大多数的批处理系统，但它不能用于分时系统和大多数实时系统。</p><p>（2）抢占方式</p><p>抢占调度方式允许调度进程根据某种原则去暂停执行某个正在运行的进程，将已分配给该进程的处理机重新分配给另一进程。对于批处理系统，可以防止一个长进程长时间的占用处理机，以确保处理机能为所有进程提供更为公平的服务。在分时系统中，只有使用抢占方式才有可能实现人机交互。在实时系统中，抢占方式能满足实时任务的需求。</p><p>抢占不是一种任意性行为，必须遵循一定的原则，主要的原则有：</p><ol><li>优先权原则。允许优先级高的新到进程抢占当前进程的处理机。</li><li>短进程优先原则。允许新到的短进程抢占当前长进程的处理机。</li><li>时间片原则。即各进程按时间片轮转运行时，当正在执行的进程的一个时间片用完后，便停止该进程的执行而重新进行调度。</li></ol><h5 id="2-轮转调度算法"><a href="#2-轮转调度算法" class="headerlink" title="2. 轮转调度算法"></a>2. 轮转调度算法</h5><p>在分时系统中，最为简单也最为常见的是基于时间片的轮转调度算法。该算法采取了非常公平的处理机分配方式，既让就绪队列上的每一个进程每次仅运行一个时间片。如果就绪队列上有n个进程，则每个进程每次大约都可获得1/n的处理机时间。</p><p>1）轮转法的基本原理</p><p>在轮转法中，系统根据FCFS策略，将所有的就绪进程排成一个就绪队列，并可设置每隔一定时间间隔即产生一次中断，激活系统中的进程调度程序，完成一次调度，将CPU分配给队首进程，令其执行。当进程的时间片耗尽或者执行完毕时，系统再次将CPU分配给新的队首进程（或新到达的紧迫进程）。由此，就可以保证就绪队列中的所有进程在一个确定的时间段内，都能获得一次CPU执行。</p><p>2）进程切换时机</p><p>一、若时间片尚未用完，进程便已经执行完毕，就立即激活调度程序，将该进程从就绪队列中删除，再调度就绪队列的队首进程运行，并启动一个新的时间片。</p><p>二、若时间片耗尽，则计时器中断处理程序被激活，如果该进程尚未执行完毕，调度程序将把它送入就绪队列的末尾。</p><p>3）时间片大小的确定</p><p>时间片过小，会频繁地执行进程调度和进程的上下文切换，增加系统开销；时间片过大，则无法满足短作业和交互式用户的需求。</p><h5 id="3-优先级调度算法"><a href="#3-优先级调度算法" class="headerlink" title="3. 优先级调度算法"></a>3. 优先级调度算法</h5><p>1）优先级调度算法的类型</p><p>（1）非抢占式优先级调度算法</p><p>（2）抢占式优先级调度算法</p><p>2）优先级的类型</p><p>（1）静态优先级</p><p>静态优先级是在进程创建时确定的，在进程的整个运行期间保持不变。</p><p>确定进程优先级大小的因素有：进程类型（系统进程&gt;用户进程），进程对资源的需求（需求越少优先级越高），用户要求（紧迫程度）。静态优先级简单易行，系统开销小，但不够精确。</p><p>（2）动态优先级</p><p>动态优先级是指在创建进程之初，先赋予其一个优先级，然后其值随进程的推进或等待时间的增加而改变，以便获得更好的调度性能。前面介绍的作业调度算法中的高响应比优先调度算法就是典型的动态优先级。若所有的进程都拥有相同的优先级，则相当于先来先服务（FCFS）算法。</p><h5 id="4-多队列调度算法"><a href="#4-多队列调度算法" class="headerlink" title="4. 多队列调度算法"></a>4. 多队列调度算法</h5><p>如前所述的各种调度算法，在系统中进设置一个进程的就绪队列，相应地也就只能应用一种调度算法，过于固定、单一，无法满足系统中不同用户对进程调度策略地不同要求，在多处理机系统中，这种单一调度策略的缺点更显突出。</p><p>多队列调度算法将系统中的进程就绪队列从一个拆分为若干个，将不同类型或性质的进程固定分配在不同的就绪队列，不同的就绪队列可以按需采用不同的调度算法，一个就绪队列中的进程可以设置不同的优先级，不同的就绪队列本身也可以设置不同的优先级。</p><h5 id="5-多级反馈队列调度算法"><a href="#5-多级反馈队列调度算法" class="headerlink" title="5. 多级反馈队列调度算法"></a>5. 多级反馈队列调度算法</h5><p>1）调度机制</p><p>（1）设置多个就绪队列。并为每个队列赋予不同的优先级。第一个队列的优先级最高，其余队列的优先级逐个降低。</p><p>（2）每个队列都采用FCFS算法。当新进程进入内存后，首先将它放入第一队列的末尾，按先来先服务原则等待调度。当轮到该进程执行时，如果它能在该时间片内完成，便可撤离系统。否则，即它在一个时间片结束时尚未完成，调度队列将其调入第二队列的末尾等待调度，依此类推。当进程最后被降到n级队列时，在第n队列中便按照轮转（RR）方式运行。</p><p>（3）按队列优先级调度。调度程序首先调度最高优先级队列中的诸进程运行，仅当第一队列为空时才调度第二队列中的进程运行，以此类推。如果处理机正在第i队列中为某进程服务时又有新进程进入任一优先级更高的队列，则此时须立即把正在运行的进程放到第i队列的末尾，而把处理机分配给新到的高优先级进程。</p><p><img src="source/images/操作系统2：处理机调度与死锁/1774310-20210804162152080-1112528517.png" alt="img" style="zoom:80%;"></p><p>2）调度算法的性能</p><p>在多级反馈队列调度算法中，如果规定第一级队列的时间片略大于多数人机交互所需的处理时间，便能较好地满足各种类型用户的需求。</p><h4 id="3-4-实时调度"><a href="#3-4-实时调度" class="headerlink" title="3.4 实时调度"></a>3.4 实时调度</h4><h5 id="1-实现实时调度的基本条件"><a href="#1-实现实时调度的基本条件" class="headerlink" title="1. 实现实时调度的基本条件"></a>1. 实现实时调度的基本条件</h5><p>（1）提供必要的信息。</p><p>如就绪时间、开始截止时间和完成截止时间、处理时间、资源要求、优先级。</p><p>（2）系统处理能力强。</p><p>假定系统中有m个周期性的硬实时任务，它们的处理时间可表示为Ci，周期时间表示为Pi，则在单处理机情况下，必须满足下面的限制条件系统才是可调度的：</p><script type="math/tex; mode=display">\sum_{i=1}^{m}\frac{C_{i}}{P_{i}}≤1</script><p>提高系统的处理能力，其途径有二：其一仍是采用单处理机系统，但须增强其处理能力，以显著地减少对每一个任务的处理时间；其二是采用多处理机系统。假定系统中的处理机数为 N，则应将上述的限制条件改为：</p><script type="math/tex; mode=display">\sum_{i=1}^{m}\frac{C_{i}}{P_{i}}≤N</script><p>（3）采用抢占式调度机制。</p><p>在含有硬实时任务的实时系统中，广泛采用抢占机制。当一个优先权更高的任务到达时，允许将当前任务暂时挂起，而令高优先权任务立即投入运行，这样便可满足该硬实时任务对截止时间的要求。但这种调度机制比较复杂。</p><p>（4）具有快速切换机制。</p><p>为保证要求较高的硬实时任务能及时运行，在实时系统中还应具有快速切换机制，以保证能进行任务的快速切换。该机制应具有如下两方面的能力：</p><ul><li>对外部中断的快速响应能力。为使在紧迫的外部事件请求中断时系统能及时响应，要求系统具有快速硬件中断机构，还应使禁止中断的时间间隔尽量短，以免耽误时机(其它紧迫任务)。</li><li>快速的任务分派能力。在完成任务调度后，便应进行任务切换。为了提高分派程序进行任务切换时的速度，应使系统中的每个运行功能单位适当地小，以减少任务切换的时间开销。</li></ul><h5 id="2-实时调度算法的分类"><a href="#2-实时调度算法的分类" class="headerlink" title="2. 实时调度算法的分类"></a>2. 实时调度算法的分类</h5><p>可以按不同方式对实时调度算法加以分类，如根据实时任务性质的不同，可将实时调度的算法分为<strong>硬实时调度算法</strong>和<strong>软实时调度算法</strong>；而按调度方式的不同，又可分为<strong>非抢占调度算法</strong>和<strong>抢占调度算法</strong>； 还可因调度程序调度时间的不同而分成<strong>静态调度算法</strong>和<strong>动态调度算法</strong>，前者是指在进程执行前，调度程序便已经决定了各进程间的执行顺序，而后者则是在进程的执行过程中，由调度程序届时根据情况临时决定将哪一进程投入运行。在多处理机环境下，还可将调度算法分为<strong>集中式调度</strong>和<strong>分布式调度</strong>两种算法。</p><p>这里，我们仅按调度方式的不同对调度算法进行分类。</p><p>1）非抢占式调度算法</p><p>（1）<strong>非抢占式轮转调度算法</strong>。</p><p>由一台计算机控制若干个相同的(或类似的)对象，为每一个被控对象建立一个实时任务，并将它们排成一个轮转队列。调度程序每次选择队列中的第一个任务投入运行。当该任务完成后，便把它挂在轮转队列的末尾，等待下次调度运行，而调度程序再选择下一个(队首)任务运行。</p><p>（2）<strong>非抢占式优先调度算法</strong></p><p>如果在实时系统中存在着要求较为严格(响应时间为数百毫秒)的任务，则可采用非抢占式优先调度算法为这些任务赋予较高的优先级。当这些实时任务到达时，把它们安排在就绪队列的队首，等待当前任务自我终止或运行完成后才能被调度执行。</p><p>2）抢占式调度算法</p><p>（1）<strong>基于时钟中断的抢占式优先权调度算法</strong></p><p>在某实时任务到达后，如果该任务的优先级高于当前任务的优先级，这时并不立即抢占当前任务的处理机，而是等到时钟中断到来时，调度程序才剥夺当前任务的执行，将处理机分配给新到的高优先权任务。这种调度算法能获得较好的响应效果，其调度延迟可降为几十毫秒至几毫秒。因此，此算法可用于大多数的实时系统中。</p><p>（2）<strong>立即抢占(Immediate Preemption)的优先权调度算法</strong></p><p>在这种调度策略中，要求操作系统具有快速响应外部事件中断的能力。一旦出现外部中断，只要当前任务未处于临界区，便立即剥夺当前任务的执行，把处理机分配给请求中断的紧迫任务。这种算法能获得非常快的响应，可把调度延迟降低到几毫秒至 100 微秒，甚至更低。</p><p><img src="source/images/操作系统2：处理机调度与死锁/image-20220826134933125.png" alt="image-20220826134933125" style="zoom: 80%;"></p><h5 id="3-常见的实时调度算法"><a href="#3-常见的实时调度算法" class="headerlink" title="3. 常见的实时调度算法"></a>3. 常见的实时调度算法</h5><p>1）最早截止时间优先（Earliest Deadline First,EDF）算法</p><p>根据任务的开始截止时间确定任务优先级的调度算法。截止时间越早则优先级越高。该算法要求在系统中保持一个实时任务就绪队列，该队列按各任务截止时间的先后排序。</p><p>2）最低松弛度优先（Least Laxity First,LLF）算法</p><p>该算法是根据任务紧急(或松弛)的程度，来确定任务的优先级。任务的紧急程度愈高，为该任务所赋予的优先级就越高，以使之优先执行。</p><h5 id="4-优先级倒置"><a href="#4-优先级倒置" class="headerlink" title="4. 优先级倒置"></a>4. 优先级倒置</h5><p>何谓“优先级倒置”现象，可采用什么方法来解决？</p><p>答：优先级倒置，即高优先级进程被低优先级进程延迟或阻塞的现象。</p><p>优先级倒置的解决方法：</p><p>(1) 规定进程在进入临界区后，其所占有的处理机不允许被抢占。</p><p>(2) 动态优先级继承。</p><h4 id="3-5-死锁概述"><a href="#3-5-死锁概述" class="headerlink" title="3.5 死锁概述"></a>3.5 死锁概述</h4><h5 id="1-资源问题"><a href="#1-资源问题" class="headerlink" title="1. 资源问题"></a>1. 资源问题</h5><p>1）可重用性资源和消耗性资源。</p><ul><li><p>可重用性资源。<br>是一种可供用户重复使用多次的资源。每一个可重用性资源只能分配给一个进程使用，不允许多个进程共享。资源的单元数目是相对固定的，在运行期间既不能创建也不能删除它。例如设备、文件。</p></li><li><p>消耗性资源。<br>在进程运行期间，由进程动态地创建和消耗。资源的单元数目在进程运行期间可以不断变化的。进程可以请求若干个可消耗性资源单元。可消耗性资源通常由生产者创建，消费者消耗。例如进程间通信的消息。</p></li></ul><p>2）可抢占性资源和不可抢占性资源。</p><ul><li>可抢占性资源不会引起死锁。</li><li>不可抢占性资源是指资源一旦被分配给进程，只能在进程用完后自行释放。</li></ul><h5 id="2-计算机系统中的死锁"><a href="#2-计算机系统中的死锁" class="headerlink" title="2. 计算机系统中的死锁"></a>2. 计算机系统中的死锁</h5><ol><li><p>竞争不可抢占性资源引起死锁。<br>两进程分别保持一个临界资源，而又分别因请求对方所保持的资源被阻塞。</p><p><img src="source/images/操作系统2：处理机调度与死锁/1774310-20210805143451008-1059689047.png" alt="img" style="zoom: 67%;"></p></li><li><p>竞争可消耗性资源引起死锁。<br>一进程需接受到对方发送的消息a后才能发送消息b，而另一进程需接受到对方发送的消息b后才能发送消息a。</p><p><img src="source/images/操作系统2：处理机调度与死锁/1774310-20210805144306792-1233499135.png" alt="img" style="zoom: 67%;"></p></li><li><p>进程推进顺序不当引起死锁。<br>进程在运行过程中，对资源的申请和释放的顺序非法引起死锁。</p></li></ol><h5 id="3-死锁的定义、必要条件和处理方法"><a href="#3-死锁的定义、必要条件和处理方法" class="headerlink" title="3. 死锁的定义、必要条件和处理方法"></a>3. 死锁的定义、必要条件和处理方法</h5><ol><li><p>死锁的定义。<br>如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那么该组进程是死锁的（Deadlock）。</p></li><li><p>产生死锁的必要条件。</p><ul><li><strong>互斥条件</strong>：即在一段时间内某资源只由一个进程占用。如果其它进程请求该资源则只能等待。</li><li><strong>请求和保持条件</strong>：指进程已经保持了至少一个资源，又请求新资源而被阻塞，但又对自己已获得的资源保持不放。</li><li><strong>不可抢占条件</strong>：进程已获得的资源在未使用完之前不能被抢占，只能在进程使用完时由进程自己释放。</li><li><strong>循环等待条件</strong>：即存在一个进程——资源的循环链。</li></ul></li><li><p>处理死锁的方法。</p><ul><li>预防死锁：即破坏产生死锁的四个必要条件中的一个或几个条件。</li><li>避免死锁：在资源的动态分配过程中，用某种方法去防止系统进入不安全状态。</li><li>检测死锁：允许发生死锁，但可通过系统所设置的检测机构，及时地检测出死锁的发生，然后采取适当措施。</li><li>解除死锁：常用的实施方法是撤消或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程。</li></ul><p>上述方法对死锁的防范程度逐渐减弱，但对应的是资源利用率的提高，以及进程因资源因素而阻塞的频度下降（即并发程度提高）。</p></li></ol><h4 id="3-6-预防死锁"><a href="#3-6-预防死锁" class="headerlink" title="3.6 预防死锁"></a>3.6 预防死锁</h4><p>由于互斥条件是非共享设备所必须的，不仅不能改变，还应加以保证，因此主要是破坏其它三个条件。</p><h5 id="1-破化“请求和保持”条件"><a href="#1-破化“请求和保持”条件" class="headerlink" title="1. 破化“请求和保持”条件"></a>1. 破化“请求和保持”条件</h5><p>1）第一种协议</p><p>规定所有进程在开始运行之前，都必须一次性地申请其在整个运行过程所需的全部资源。在整个运行期间便不会再提出资源要求，从而破坏了请求条件。在分配资源时，只要有一种资源不能满足某进程的要求，即使其它所需的各资源都空闲，也不分配给该进程，即在该进程的等待期间，它并未占有任何资源，因而也破坏了保持条件。</p><p>2）第二种协议</p><p>允许进程只获得运行初期所需的资源后，便开始运行。进程运行过程中再逐步释放已分配给自己的、且已用毕的全部资源，然后再去请求新的所需资源。</p><h5 id="2-破坏“不可抢占”条件"><a href="#2-破坏“不可抢占”条件" class="headerlink" title="2. 破坏“不可抢占”条件"></a>2. 破坏“不可抢占”条件</h5><p>当一个已经保持了某些资源的进程，再提出新的资源请求而不能立即得到满足时，必须释放它已经保持了的所有资源，待以后需要时再重新申请。这意味着某一进程已经占有的资源，在运行过程中会被暂时地释放掉，也可认为是被抢占了，从而破坏了“不可抢占”条件。</p><h5 id="3-破化“循环等待”条件"><a href="#3-破化“循环等待”条件" class="headerlink" title="3. 破化“循环等待”条件"></a>3. 破化“循环等待”条件</h5><p>系统将所有类型资源进行线性排队，并赋予不同的序号。规定每个进程必须按序号递增的顺序请求资源。假如某进程已请求到一些序号较高的资源，后来它又想请求一个序号低的资源时，它必须先释放所有具有相同和更高序号的资源后，才能申请序号低的资源。在采用这种策略后不可能再出现环路，因而破坏了“循环等待”条件。</p><h4 id="3-7-避免死锁"><a href="#3-7-避免死锁" class="headerlink" title="3.7 避免死锁"></a>3.7 避免死锁</h4><h5 id="1-系统安全状态"><a href="#1-系统安全状态" class="headerlink" title="1. 系统安全状态"></a>1. 系统安全状态</h5><p>系统在进行资源分配之前，应先计算此次资源分配的安全性。所谓安全状态，是指系统能按某种进程顺序(P1，P2，…，Pn)每个进程Pi分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成。此时称(P1，P2，…，Pn)为安全序列。如果系统无法找到这样一个安全序列，则称系统处于不安全状态。</p><p>避免死锁的实质在于：系统在进行资源分配时，如何使系统不进入不安全状态。</p><h5 id="2-利用银行家算法避免死锁"><a href="#2-利用银行家算法避免死锁" class="headerlink" title="2. 利用银行家算法避免死锁"></a>2. 利用银行家算法避免死锁</h5><p>Dijkstra的银行家算法名字是由于该算法原本是为银行系统设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。<br>为实现银行家算法，每一个新进程在进入系统时，它必须申明在运行过程中，可能需要每种资源类型的最大单元数目，其数目不应超过系统所拥有的资源总量。</p><p>1）银行家算法中的数据结构。</p><p>在系统中必须设置四种数据结构，分别用来描述系统中可利用的资源、所有进程对资源的最大需求、系统中的资源分配，以及所有进程还需要多少资源的情况。</p><ul><li>可利用资源向量 Available。这是一个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目，其初始值是系统中所配置的该类全部可用资源的数目，其数值随该类资源的分配和回收而动态地改变。如果 Available[j]=K，则表示系统中现有$R_{j}$类资源K个。</li><li>最大需求矩阵 Max。这是一个 n×m 的矩阵，它定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果 Max[i,j]=K，则表示进程i需要$R_{j}$类资源的最大数目为K。</li><li>分配矩阵 Allocation。这也是一个 n×m 的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果 Allocation[i,j]=K，则表示进程i当前已分得$R_{j}$类资源的数目为K。</li><li>需求矩阵 Need。这也是一个 n×m 的矩阵，用以表示每一个进程尚需的各类资源数。如果 Need[i,j]=K，则表示进程i还需要$R_{j}$类资源 K个，方能完成其任务。</li><li>上述三个矩阵间存在下述关系：Need[i,j]=Max[i,j]-Allocation[i,j]</li></ul><p>2)银行家算法。</p><p>设 Request[i] 是进程$P_{i}$的请求向量，如果 $Request_{i}[j]=K$，表示进程$P_{i}$需要K个$R_{j}$类型的资源。当$P_{i}$发出资源请求后，系统按下述步骤进行检查：</p><p>(1）如果 $Request_{i}[j]≤Need[i,j]$，便转向步骤(2)；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。</p><p>(2）如果 $Request_{i}[j]≤Available[j]$，便转向步骤(3)；否则，表示尚无足够资源，$P_{i}$须等待。</p><p>(3）系统试探着把资源分配给进程$P_{i}$，并修改下面数据结构中的数值：</p><p>​    $Available[j] = Available[j]-Request_{i}[j]$；</p><p>​    $Allocation[i,j] = Allocation[i,j]+Request_{i}[j]$；</p><p>​    $Need[i,j] = Need[i,j]-Request_{i}[j]$；</p><p>(4）系统执行安全性算法，检查此次资源分配后系统是否处于安全状态。若安全，才正式将资源分配给进程$P_{i}$，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程$P_{i}$等待。</p><p><img src="source/images/操作系统2：处理机调度与死锁/1774310-20211015150624204-323115928.png" alt="img" style="zoom: 80%;"></p><p>3)安全性算法。</p><p>系统所执行的安全性算法可描述如下：</p><p>(1）设置两个向量：</p><p>① 工作向量 Work，它表示系统可提供给进程继续运行所需的各类资源数目，它含有 m个元素，在执行安全算法开始时，Work=Available。</p><p>② Finish，它表示系统是否有足够的资源分配给进程，使之运行完成。开始时先做Finish[i]=false；当有足够资源分配给进程时，再令 Finish[i]=true。</p><p>(2）从进程集合中找到一个能满足下述条件的进程：</p><p>① Finish[i]=false;</p><p>② Need[i,j]≤Work[j]；</p><p>若找到，执行步骤(3)，否则，执行步骤(4)。</p><p>(3）当进程$P_{i}$获得资源后，可顺利执行，直至完成，并释放出分配给它的资源，故应执行：<br>    Work[j] = Work[j]+Allocation[i,j]；<br>    Finish[i] = true；<br>    go to step 2；<br>(4) 如果所有进程的 Finish[i]=true 都满足，则表示系统处于安全状态；否则，系统处于不安全状态。</p><h4 id="3-8-死锁的检测和解除"><a href="#3-8-死锁的检测和解除" class="headerlink" title="3.8 死锁的检测和解除"></a>3.8 死锁的检测和解除</h4><h5 id="1-死锁的检测"><a href="#1-死锁的检测" class="headerlink" title="1. 死锁的检测"></a>1. 死锁的检测</h5><p>为了能对系统中是否发生了死锁进行检测，必须：1）保存有关资源的请求和分配信息；2）提供一种算法，以利用这些信息来检测系统是否已进入死锁状态。</p><p>1)资源分配图。</p><p>系统死锁可利用资源分配图来描述。该图是由一组结点N和一组边E所组成的一个对偶G=(N,E)。<br>把结点N分为两个互斥的子集，即一组进程结点P和一组资源结点R。<br>由进程$P_{i}$指向资源$R_{j}$，它表示进程$P_{i}$请求一个单位的$R_{j}$资源。由资源$R_{j}$指向进程$P_{i}$，它表示把一个单位的资源 $R_{j}$分配给进程 $P_{j}$。<br>用圆圈代表一个进程，用方框代表一类资源。</p><p><img src="source/images/操作系统2：处理机调度与死锁/1774310-20210805230232210-1306695891.png" alt="img" style="zoom:67%;"></p><p>2）死锁定理。</p><p>利用把资源分配图加以简化的方法，来检测系统是否为死锁状态。</p><p>1）在资源分配图中，找出一个既不阻塞又非独立的进程结点Pi。消去Pi所求的请求边和分配边，使之成为孤立的结点。表示其运行完毕。依次进行。</p><p>2）在进行一系列的简化后，若能消去图中所有的边，使所有的进程结点都成为孤立结点，则称该图是可完全简化的；若不能通过任何过程使该图完全简化，则称该图是不可完全简化的。</p><p>有关文献已经证明，所有的简化顺序，都将得到相同的不可简化图。同样可以证明：S为死锁状态的充分条件是：当且仅当S状态的资源分配图是不可完全简化的。该充分条件被称为<strong>死锁定理</strong>。</p><p><img src="source/images/操作系统2：处理机调度与死锁/1774310-20210805230745422-14628352.png" alt="img" style="zoom: 67%;"></p><h5 id="2-死锁的解除"><a href="#2-死锁的解除" class="headerlink" title="2. 死锁的解除"></a>2. 死锁的解除</h5><p>常采用解除死锁的两种方法是：</p><ul><li>抢占(死锁进程所需的)资源。</li><li>终止(死锁)进程。</li></ul><p>1）终止进程的方法。</p><ul><li><p>终止所有死锁进程。</p></li><li><p>逐个终止进程，直至有足够的资源，以打破循环等待。</p></li></ul><p>选择终止进程的策略最主要的依据是，为死锁解除所付出的”代价最小“。</p><p>2）付出代价最小的死锁解除算法。</p><p>一种付出代价最小的死锁解除算法是类似于动态规划地去选择被终止进程。<br>还有一个比较有效的方法是类似于贪心地去选择被终止进程。</p><p>3）王道书上解除死锁的办法是：资源剥夺法、撤销进程法和进程回退法。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统1：进程控制与描述</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-1-jin-cheng-kong-zhi-yu-miao-shu/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-1-jin-cheng-kong-zhi-yu-miao-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="第二章-进程的描述与控制"><a href="#第二章-进程的描述与控制" class="headerlink" title="第二章 进程的描述与控制"></a>第二章 进程的描述与控制</h1><blockquote><p>在传统的操作系统中，为了提高资源利用率和系统吞吐量，通常采用多道程序设计技术，将多个程序同时装入内存，使之并发运行，传统意义上的程序不能再独立运行。此时，作为资源分配和独立运行的基本单位都是进程。</p></blockquote><h4 id="2-1-前趋图和程序执行"><a href="#2-1-前趋图和程序执行" class="headerlink" title="2.1 前趋图和程序执行"></a>2.1 前趋图和程序执行</h4><p>在早期未配置OS的系统和单道批处理程序中，程序的执行方式是顺序执行，即在内存中仅装入一道用户程序，由它独占系统中的所有资源，只有在一个用户程序执行完成后才允许装入另一个程序并执行。可见，这种顺序执行的运行方式存在着浪费资源、系统运行效率低等缺点。</p><p>而在多道程序系统中，由于内存中可以同时装入多个程序，使它们共享系统资源，并发执行，显然可以克服上述缺点。程序的顺序执行和并发执行这两种执行方式之间有显著的不同，尤其是考虑到程序并发执行的特征，才导致了在操作系统中引入了进程的概念。</p><h5 id="1-前趋图"><a href="#1-前趋图" class="headerlink" title="1. 前趋图"></a>1. 前趋图</h5><p>所谓前趋图（Precedence Graph），是指一个有向无循环图，可记为DAG（Directed Acyclic Graph），它用于描述程序之间执行的先后顺序。图中的每一个节点可用来表示一个进程或程序段，乃至一条语句；结点间的有向边则表示两个节点之间存在着前趋关系。在前驱图中，除了初始节点外每个节点都至少有一个直接前趋，除了终止节点外，每个节点都至少有一个直接后继。此外，每个节点还具有一个重量，用于表示该节点所含有的程序量或程序的执行时间。注意，前趋图中是不允许有循环的。</p><h5 id="2-程序的顺序执行"><a href="#2-程序的顺序执行" class="headerlink" title="2. 程序的顺序执行"></a>2. 程序的顺序执行</h5><p>通常，一个应用程序由若干个程序段组成，每一个程序段完成特定的功能，它们在执行时，都需要按照某种先后次序顺序执行，仅当前一个程序段执行完后，才运行后一程序段。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731072931025-84000607.png" alt="img" style="zoom:80%;"></p><p>程序顺序执行时的特征：</p><ol><li>顺序性：指处理机严格地按照程序所规定的顺序执行，即每一操作必须在下一操作开始之前结束；</li><li>封闭性：指程序在封闭的环境下运行，即程序运行时独占全机资源，资源的状态（除初始状态外）只有本程序才能改变它，程序一旦开始运行，其执行结果不受外界因素影响；</li><li>可再现性：指只要程序执行时的环境和初始条件相同，当程序重复执行时，不论它是从头到尾一气呵成，还是“走走停停”地执行，都可获得相同的结果。</li></ol><p>程序顺序执行时的这种特性，为程序员检验和校正程序的错误带来了很大的方便。</p><h5 id="3-程序并发执行"><a href="#3-程序并发执行" class="headerlink" title="3. 程序并发执行"></a>3. 程序并发执行</h5><p>程序顺序执行时，虽然可以给程序员带来方便，但系统资源的利用率却很低。为此，在系统中引入了多道程序技术，使程序或程序段间能并发执行。然而，并非所有的程序都能并发执行。事实上只有不存在前趋关系的程序之间才有可能并发执行（因为它们彼此互不依赖），否则无法并发执行。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731074044348-1709701241.png" alt="img" style="zoom:80%;"></p><p>程序并发执行时的特征：</p><ol><li>间断性：程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使在这些相互执行的程序之间形成了相互制约的关系。相互制约将导致并发程序失去执行的连贯性，具有“执行——暂停——执行”这种间断性的活动规律。</li><li>失去封闭性：当系统中存在着多个可以并发执行的程序时，系统中的资源将为它们所共享，而这些资源的状态也由这些程序来改变，致使其中任一程序在运行时，其环境都必然会受到其它程序的影响。显然，程序的运行已经失去了封闭性。</li><li>不可再现性：程序在并发执行时，由于失去了封闭性，其计算结果必将与程序的执行速度有关，从而使程序的执行失去了可再现性。换言之，程序经过多次执行后，虽然它们执行时的环境和初始条件相同，但得到的结果却各不相同。</li></ol><h4 id="2-2-进程的描述"><a href="#2-2-进程的描述" class="headerlink" title="2.2 进程的描述"></a>2.2 进程的描述</h4><h5 id="1-进程的定义和特征"><a href="#1-进程的定义和特征" class="headerlink" title="1. 进程的定义和特征"></a>1. 进程的定义和特征</h5><p>在多道程序环境下，程序的进行属于并发执行，具有间断性、失去封闭性和不可再现性等特征。由此决定了通常的程序是不能参与并发执行的，否则程序的运行也就失去了意义。为了能使程序并发执行，并且可以对并发执行的程序加以描述和控制，人们引入了“进程”的概念。</p><p>为了使参与并发执行的每个程序（含数据）都能独立地运行，在操作系统中必须为之配置一个专门的数据结构，称为进程控制块（Process Control Block,PCB）。系统利用进程控制块来描述进程的基本情况和活动过程，进而控制和管理进程。这样，由程序段、相关数据段和PCB三部分便构成了进程实体（又称进程映像）。一般情况下，我们把进程实体就简称为进程。</p><p>较典型的进程定义有：</p><ol><li>进程是程序的一次执行。</li><li>进程是一个程序及其数据在处理机上顺序执行时所发生的活动。</li><li>进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。</li></ol><p>在引入了进程实体的概念之后，我们可以把传统OS中的进程定义为：</p><blockquote><p>进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。</p></blockquote><p>进程除了程序所没有的PCB结构外，还具有以下特征：</p><ol><li>动态性：进程的实质就是进程实体的执行过程，因此，动态性就是进程最基本的特征。动态性还表现在：进程由创建而产生，由调度而执行，由撤销而消亡。可见，进程实体具有一定的生命期，而程序只是一组有序指令的集合，并存放于某种介质上，其本身不具有活动的含义，因而是静态的。</li><li>并发性：是指多个进程实体同时存在于内存中，且能在一段时间内同时运行。并发性是进程的另一重要特征，同时也成为操作系统的重要特征，而程序（没有建立PCB）是不能参与并发执行的。</li><li>独立性：独立性是指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立PCB的程序都不能作为一个独立地单位参与运行。</li><li>异步性：是指进程是按异步方式运行的，即按各自独立的、不可预知的速度向前推进。</li></ol><h5 id="2-进程的基本状态及转换"><a href="#2-进程的基本状态及转换" class="headerlink" title="2.进程的基本状态及转换"></a>2.进程的基本状态及转换</h5><p>由于多个进程在并发执行时共享系统资源，致使它们在运行过程中呈现间断性的运行规律，所以进程在其生命周期内可能具有多种状态。一般而言，每个进程都至少应处于以下三种基本状态之一：</p><ol><li>就绪（Ready）状态。这是指进程已处于准备好运行的状态，即进程已分配到除CPU以外所有的必要资源，只需要再获得CPU，便可立即执行。通常将处于就绪状态的进程按照一定的策略排成一个队列，等待CPU的调度，称为就绪队列。</li><li>运行（Running）状态。即进程已获得CPU，程序正在执行的状态。</li><li>阻塞（Block）状态。指正在执行的进程由于发生某事件（如I/O请求、申请缓冲区失败等）暂时无法继续执行的状态，亦即进程的执行受到阻塞。此时引起进程调度，OS将处理机分配给另一就绪进程，而让受阻进程处于暂停状态，以提高处理机的利用率。通常操作系统会将处于阻塞状态的进程根据阻塞原因的不同设置成多个阻塞队列。</li></ol><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731082140070-1015419772.png" alt="img" style="zoom:80%;"></p><p>进程的创建和终止：</p><p>进程是由创建而产生的，创建进程是一个很复杂的过程，一般要通过多个步骤才能完成：首先由进程申请一个空白PCB，并向PCB中填写用于控制和管理进程的信息；然后为该进程分配运行时所必须的资源；最后把该进程转为就绪状态并插入就绪队列之中。</p><p>如果进程所需的资源尚不能得到满足，此时创建工作尚未完成，进程尚不能被调度运行，于是把此时所处的状态称为创建状态。引入创建状态是为了保证进程的调度必须在创建工作完成后进行，以确保对进程控制块操作的完整性。</p><p>进程的终止也需要通过两个步骤：首先，是等待操作系统的善后处理，最后将其PCB清零，并将PCB空间返还系统。当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其它有终止权的进程所终结，它将进入终止状态。</p><p>进入终止态的进程以后不能再执行，但在操作系统中依然保留一个记录，其中保存状态码和一些计时统计数据，供其它进程收集。一旦其它进程完成了对信息的提取之后，操作系统将删除该进程，即将其PCB清零，并将该空白PCB返还系统。</p><h5 id="3-挂起和激活操作"><a href="#3-挂起和激活操作" class="headerlink" title="3. 挂起和激活操作"></a>3. 挂起和激活操作</h5><p>在许多操作系统中，进程除就绪、执行和阻塞三种最基本的状态外，为了系统和用户观察和分析进程的需要，还引入了一个对进程的重要操作——挂起操作。该操作作用于某个进程时，该进程将被挂起，意味着此时该进程处于静止状态。如果进程正在执行，它将暂停执行；如果进程原本处于就绪状态，则该进程此时暂不接受调度。与挂起操作对应的是激活操作。</p><p>引入挂起操作的原因：终端用户的需要；父进程请求；负荷调节的需要；操作系统的需要。</p><blockquote><p>挂起原语——Suspend，激活原语——Active。</p></blockquote><p>引入挂起操作后五个进程状态的转换：</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731082607409-1649799763.png" alt="img" style="zoom:80%;"></p><h5 id="4-进程管理中的数据结构"><a href="#4-进程管理中的数据结构" class="headerlink" title="4. 进程管理中的数据结构"></a>4. 进程管理中的数据结构</h5><p>在计算机系统中，对于每个资源和每个进程都设置了一个数据结构，用于表征其实体，我们称之为资源信息表或进程信息表，其中包含了资源或进程的标识、描述、状态等信息以及一批指针。通过这些指针，可以将同类资源或进程的信息表分类链接成不同的队列，便于操作系统进行查找。</p><p>OS管理这些数据结构一般分为以下四类：内存表、设备表、文件表和用于进程管理的进程表，通常进程表又被称为进程控制块PCB，本节着重介绍PCB。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731154739028-839160778.png" alt="img" style="zoom:80%;"></p><p>进程控制块PCB的作用：</p><p>为了便于系统描述和管理进程的运行，在OS的核心为每个进程专门定义了一个数据结构——进程控制块（Process Control Block,PCB）。PCB作为进程实体的一部分，记录了操作系统所需的，用于描述进程的当前情况以及管理进程运行的全部信息，是操作系统中最重要的记录型数据结构。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731162933326-1113710143.png" alt="img" style="zoom:80%;"></p><p>PCB的作用是是一个在多道程序环境下不能独立运行的程序（含数据）称为一个能独立运行的基本单位，一个能与其它进程并发执行的进程。</p><ol><li>作为独立运行基本单位的标志。当一个程序配置了PCB后，就表示它已是一个能在多道程序环境下独立运行的、合法的基本单位，也就具有了取得OS服务的权利。进程随着PCB的创建而建立，随着PCB的回收而消亡，系统是通过PCB感受进程的存在的，<strong>PCB是进程存在于系统中的唯一标志</strong>。</li><li>能实现间断性运行方式。程序间断性运行时必须保留自己运行时的CPU现场信息，有了PCB后，系统就可将CPU现场信息保存在被中断进程的PCB中，供该进程再次被CPU调度执行时恢复CPU现场时使用。</li><li>提供进程管理所需要的信息。PCB中记录了程序和数据在内存或外存中的起始地址指针，当需要访问文件或I/O设备时也需要借助于PCB中的信息。此外，还可以根据PCB中的资源清单了解到该进程所需的全部资源。可见，进程的整个生命期中，操作系统总是根据PCB实施对进程的控制和管理。</li><li>提供进程调度所需要的信息。只有处于就绪状态的进程才能被调度，而PCB中记录了进程的状态信息。</li><li>实现与其它进程的同步与通信。</li></ol><p>在进程控制块PCB中，主要包含四个方面的信息：进程标识符、处理机状态、进程调度信息、进程控制信息。</p><ol><li>进程标识符：分为内部（系统）标识符和外部（用户）标识符。</li><li>处理机状态：处理机状态信息也称为处理机的上下文，主要是由处理机各种寄存器中的内容组成的。包括通用寄存器、指令计数器、程序状态字PSW、用户栈指针等。</li><li>进程调度信息：包括进程状态、进程优先级、进程调度所需的其它信息和事件。事件是指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。</li><li>进程控制信息：包括程序和数据的地址、进程同步和通信机制、资源清单和链接指针。</li></ol><p>进程控制块的组织方式：</p><ol><li><p>线性方式：即将系统中所有的PCB都组织在一张线性表中，将该表的首址存放在内存的一个专用区域中。该方式实现简单、开销小，但每次查找时都需要扫描整张表，因此适合进程数目不多的系统。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731205433453-1217053081.png" alt="img" style="zoom:80%;"></p></li><li><p>链接方式：即把具有相同状态进程的PCB分别通过PCB中的链接字链接成一个队列。这样就可以形成就绪队列、若干个阻塞队列和空白队列等。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20220120141136007-1319366976.png" alt="img" style="zoom: 80%;"></p></li><li><p>索引方式：即系统根据所有进程状态的不同，建立几张索引表，如就绪索引表、阻塞索引表等，并将各索引表在内存的首地址记录在内存的一些专用单元中。在每个索引表的表目中，记录具有相应状态的某个PCB在PCB表中的地址。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210731210827154-1412413422.png" alt="img" style="zoom: 80%;"></p></li></ol><h4 id="2-3-进程控制"><a href="#2-3-进程控制" class="headerlink" title="2.3 进程控制"></a>2.3 进程控制</h4><p>进程控制是进程管理中最基本的功能，主要包括创建新进程、终止已完成的进程、将因发生异常情况而无法继续运行的进程置于阻塞状态、负责进程运行中的状态转换等功能。</p><h5 id="1-操作系统内核"><a href="#1-操作系统内核" class="headerlink" title="1. 操作系统内核"></a>1. 操作系统内核</h5><p>现代操作系统一般将OS划分为若干个层次，再将OS不同的功能分别置于不同的层次中。通常将一些和硬件紧密相关的模块（如中断处理程序）、各种常用设备的驱动程序以及运行频率比较高的模块（如时钟管理、进程调度和许多模块所公用的一些基本操作），都安排在紧靠硬件的软件层次中，将它们常驻内存，即通常被称为的OS内核。这种安排方式目的在于两方面：一是便于对这些软件进行保护，防止遭到其它应用程序的破坏；二是可以提高操作系统的运行效率。</p><p>相对应的是，为防止OS本身及关键数据（如PCB等）遭受到应用程序有意或无意的破坏，通常也将处理机的执行状态分为系统态和用户态两种：1）系统态，又称管态、内核态。它具有较高的权限，能执行一切指令，访问所有寄存器和存储区，传统的OS都在系统态运行。2）用户态，又称目态。它是具有较低特权的执行状态，仅能执行规定的指令，访问指定的寄存器和存储区。一般情况下，应用程序只能在用户态运行，不能去执行OS指令和访问OS区域，这样可以防止应用程序对OS的破坏。</p><p>OS内核的两大方面功能：支撑功能和资源管理功能。</p><ol><li>支撑功能：中断处理、时钟管理、原语操作。</li><li>资源管理功能：进程管理、存储器管理、设备管理。</li></ol><h5 id="2-进程的创建"><a href="#2-进程的创建" class="headerlink" title="2. 进程的创建"></a>2. 进程的创建</h5><p>进程树：子进程可以继承父进程所拥有的资源，父进程对子进程具有控制权，子进程撤销时应将从父进程获得的资源归还给父进程。</p><p>引起进程创建的事件：用户登录、作业调度、提供服务、应用请求。</p><p>进程的创建过程：</p><ol><li>申请空白PCB。</li><li>为新进程分配其运行所需的资源，包括各种物理资源和逻辑资源，如内存、文件、I/O设备和CPU时间等。这些资源从操作系统或仅从其父进程获得。</li><li>初始化进程控制块。</li><li>插入就绪队列。</li></ol><h5 id="3-进程的终止"><a href="#3-进程的终止" class="headerlink" title="3. 进程的终止"></a>3. 进程的终止</h5><p>引起进程终止（Termination Of Process）的事件：</p><ol><li>正常结束</li><li>异常结束：是指进程在运行时发生了某种异常事件，使程序无法继续运行。如越界错、保护错、非法指令、特权指令错、运行超时、等待超时、算术运算错、I/O故障等。</li><li>外界干预：是指进程应外界请求而终止运行。这些干预有用户或操作系统干预、父进程请求、父进程结束。</li></ol><p>进程的终止过程：</p><ol><li>根据被终止进程的标识符检索其PCB，从中读出该进程的状态信息。</li><li>若被终止进程处于运行态，立即终止运行，并置调度标志为真，用于之后重新调度。</li><li>若被终止进程有子孙进程，应终止其子孙进程，以防子孙进程成为不可控进程。</li><li>被终止进程将其所拥有的全部资源部分归还于父进程，部分归还于操作系统。</li><li>将被终止进程（PCB）从所在队列（或链表）中移出，等待其他程序来搜集信息。</li></ol><h5 id="4-进程的阻塞与唤醒"><a href="#4-进程的阻塞与唤醒" class="headerlink" title="4. 进程的阻塞与唤醒"></a>4. 进程的阻塞与唤醒</h5><p>有下述几类事件会引起进程的阻塞和唤醒：</p><ol><li>向系统请求共享资源失败。</li><li>等待某种操作的完成。</li><li>新数据尚未到达。</li><li>等待新任务的到达。</li></ol><p>进程的阻塞过程：</p><p>正在执行的程序，如果发生了上述某事件，进程便通过调用阻塞原语block将自己阻塞。可见，阻塞是进程自身的一种主动行为。进入block过程后，由于该进程还处于执行态，所以应先立即停止执行，把PCB中的现行状态由执行态改为阻塞态，并将该进程插入阻塞队列。最后转调度程序进行重新调度，将处理机分配给另一就绪进程，并进行切换。亦即，保留被阻塞进程的处理机状态，按新进程PCB中的处理机状态设置CPU的环境。</p><p>进程唤醒过程：</p><p>当被阻塞进程所期待的事件发生时，比如它所启动的I/O操作已经完成，或其所期待的数据已经到达，则由有关进程调用唤醒原语wakeup，将等待该事件的进程唤醒。wakeup的执行过程是：首先把被阻塞进程从该事件的等待队列中移出，将其PCB中的现行状态由阻塞改为就绪，然后再将该PCB插入到就绪队列中。</p><p>应当指出，block原语和wakeup原语是一对作用刚好相反的原语，在使用它们时，必须成对使用。</p><h5 id="5-进程的挂起与激活"><a href="#5-进程的挂起与激活" class="headerlink" title="5. 进程的挂起与激活"></a>5. 进程的挂起与激活</h5><p>利用挂起原语suspend和激活原语active进行挂起和激活操作。</p><h4 id="2-4-进程同步"><a href="#2-4-进程同步" class="headerlink" title="2.4 进程同步"></a>2.4 进程同步</h4><p>在OS中引入进程后，一方面可以使系统中的多道程序并发执行，这不仅能有效地改善资源利用率，还可显著地提高系统的吞吐量，但另一方面却使系统变得更为复杂。</p><p>为保证多个程序能有条不紊地运行，在多道程序系统中，必须引入进程同步机制。在本节中，将详细介绍单处理机系统中的进程同步机制——硬件同步机制、信号量机制和管程机制等，利用它们来保证程序执行的可再现性。</p><h5 id="1-进程同步的基本概念"><a href="#1-进程同步的基本概念" class="headerlink" title="1. 进程同步的基本概念"></a>1. 进程同步的基本概念</h5><p>进程同步机制的主要任务，是对多个相关进程在执行次序上进行协调使并发执行的诸进程之间能够按照一定的规则（或时序）共享系统资源，并能很好地相互合作，从而使程序的执行具有可再现性。</p><p>在多道程序环境下，对于同处于一个系统中的多个进程，由于它们共享系统中的资源，或为完成某一任务而相互合作，它们之间可能存在着以下两种形式的制约关系：</p><ol><li>间接相互制约。多个程序在并发执行时，由于共享系统资源，如CPU、I/O设备等，致使在这些并发执行的程序之间形成相互制约的关系。如多个进程只能互斥地访问临界资源。</li><li>直接相互制约。某些应用程序，为了完成某任务而建立了两个或多个进程。这些进程将为完成同一项任务而相互合作。进程间的直接制约关系就是源于它们之间的相互合作。</li></ol><p><strong>临界资源</strong>：把在一段时间内只允许一个进程访问的资源称为临界资源（或独占资源），把在一段时间内只允许一个进程访问临界资源的资源共享称为互斥共享方式。</p><p>临界区：</p><p>不论是硬件临界资源还是软件临界资源，多个进程必须互斥地对它进行访问。</p><p>人们把在进程中访问临界资源的那段代码称为临界区。每个进程在进入临界区之前，应先对欲访问的临界资源进行检查，看它是否正被访问，因此必须在临界区代码之前增加一段用于上述检查的代码，把这段代码称为进入区；相应地，在临界区后面也要加上一段称为退出区的代码，用于将临界区正被访问的标志恢复为未被访问的标志。进程中，将除上述进入区、临界区和退出区之外的其它部分的代码统称为剩余区。</p><p>同步机制应遵循的规则：</p><ol><li>空闲让进：当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。</li><li>忙则等待：当已有进程进入临界区时，表明临界资源正在被访问因而其它试图进入临界区的进程必须等待，以保证对临界资源的互斥访问。</li><li>有限等待：对要求访问临界资源的进程，应保证在有限时间内进入自己的临界区，以免陷入“死等”状态。</li><li>让权等待：当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等”状态。</li></ol><h5 id="2-硬件同步机制"><a href="#2-硬件同步机制" class="headerlink" title="2. 硬件同步机制"></a>2. 硬件同步机制</h5><p>利用软件方法解决诸进程之间互斥地进入临界区有一定的难度，并且存在很大的局限性，现已很少采用。</p><p>相应地，目前许多计算机已提供了一些特殊的硬件指令，允许对一个字中的内容进行检测和修正，或者是对两个字的内容进行交换等。可以利用这些特殊的指令来解决临界区问题。</p><p>在对临界区进行管理时，可以将标志看成一把锁，锁开时进入，锁关时等待，初始时锁是打开的。每个要进入临界区的进程必须先对锁进行测试，当锁未开时必须等待，直至锁打开；反之，当锁打开时，则应立即关上，以阻止其它进程进入临界区。显然，为防止多个进程同时测试到锁为开的情况，测试和关锁操作必须是连续的，不允许分开进行。</p><p>1）关中断。</p><p>关中断是实现互斥最简单的方法之一。在进入锁测试之前关闭中断，直到完成锁测试并上锁之后才能打开中断。这样，进程在临界区执行期间，计算机系统不响应中断，从而不会引发调度，也就不会发生进程或线程切换。由此，保证了对锁测试和关锁操作的连续性和完整性，有效地保证了互斥。</p><p>关中断的方法存在许多缺点：滥用关中断权力可能会导致严重后果；关中断时间过长会影响系统效率；关中断方法不适用于多CPU系统。</p><p>2）利用Test-and-Set指令实现互斥。</p><p>硬件指令Test-and-Set的一般性描述如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">boolean TS(boolean *lock){</span><br><span class="line">boolean old;</span><br><span class="line">old = *lock;</span><br><span class="line">*lock = TRUE;</span><br><span class="line">return old;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>这条指令可以看作一个函数过程，其执行过程是不可分割的，即是一条原语。其中lock是一个布尔变量，有两种状态，当<code>*lock == FALSE</code>时，即未上锁，表示该资源空闲；当<code>*lock == TRUE</code>时，即已上锁，表示该资源正在被使用。</p><p>进程进入临界区之前，首先用TS指令对lock进行测试，如果其值为FALSE，表示没有进程在临界区内，可以进入，并<strong>同时</strong>将lock的值设为TRUE，等效于关闭了临界资源，阻止了其它任何进程进入临界区。</p><p>利用TS指令实现互斥的循环进程结构可描述如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">do{</span><br><span class="line">...</span><br><span class="line">while TS(&amp;lock);//当lock为true时陷入循环等待</span><br><span class="line">临界区;</span><br><span class="line">lock = FALSE;//访问结束，将资源标记为空闲状态</span><br><span class="line">剩余区;</span><br><span class="line">}while(true);</span><br></pre></td></tr></tbody></table></figure><p>3）利用Swap指令实现进程互斥</p><p>该指令称为对换指令，用于交换两个字的内容。其处理过程描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">swap</span><span class="params">(boolean *a, boolean *b)</span></span><br><span class="line">{</span><br><span class="line">boolean temp;</span><br><span class="line">temp = *a;</span><br><span class="line">*a = *b;</span><br><span class="line">*b = temp;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>用对换指令可以简单有效地实现互斥，方法是为每个临界资源设置一个全局的布尔变量lock，其初值为false，在每个进程中再利用一个局部布尔变量key。利用swap指令实现进程互斥的循环进程可描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">do</span>{</span><br><span class="line">key = TRUE;</span><br><span class="line"><span class="keyword">do</span>{</span><br><span class="line">swap(&amp;lock,&amp;key);</span><br><span class="line">}<span class="keyword">while</span>(key != FALSE);<span class="comment">//当两者均为TRUE时陷入循环测试，直至有进程释放资源</span></span><br><span class="line">临界区操作；</span><br><span class="line">lock = FALSE;</span><br><span class="line">...</span><br><span class="line">}<span class="keyword">while</span>(TRUE);</span><br></pre></td></tr></tbody></table></figure><p>局部布尔变量key用于描述当前进程是否想要访问临界区，全局布尔变量lock用于描述临界区当前是否可以访问。当某进程欲访问临界区时，其key为TRUE，若此时资源空闲，即lock为FALSE，则经swap指令，lock变为TRUE，对临界资源上锁，阻止了其他进程进入临界区。直至该进程访问结束，重新将lock置为FALSE。</p><p>利用上述硬件指令能有效地实现进程互斥，但当临界资源忙碌时，其它访问进程必须不断地进行测试，处于一种忙等状态，不符合让权等待的原则，造成处理机时间的浪费。</p><h5 id="3-信号量机制"><a href="#3-信号量机制" class="headerlink" title="3. 信号量机制"></a>3. 信号量机制</h5><p>1965年，荷兰学者Dijkstra提出的信号量机制是一种卓有成效的进程同步工具。</p><p>1）整型信号量</p><p>最初由Dijkstra把整型信号量定义为一个用于表示资源数目的整型量S，它除了初始化外，仅能通过两个标准的原子操作wait(S)和signal(S)来访问。这两个操作被称为P、V操作。</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wait(S){</span><br><span class="line"><span class="keyword">while</span>(S&lt;=<span class="number">0</span>);<span class="comment">//没有空闲资源可用，需要循环测试等待</span></span><br><span class="line">S--;<span class="comment">//当S&gt;0时才会执行，占用一个资源，可用资源数量-1</span></span><br><span class="line">}</span><br><span class="line">signal(S){</span><br><span class="line">S++;<span class="comment">//使用结束，释放资源</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>wait(S)和signal(S)是两个原子操作，它们在执行时是不可中断的。</p><p>2）记录型信号量</p><p>在整型信号量机制中，只要信号量S&lt;=0，就会不断地测试，使进程处于忙等状态，并未符合让权等待的原则。</p><p>记录型信号量机制是一种不存在忙等现象的进程同步机制。在采取了“让权等待”策略后，又出现了多个进程等待访问同一临界资源的现象，为此，在信号量机制中，除了需要一个用于代表资源数目的整型变量value外，还应增加一个进程链表指针list，用于链接上述的所有等待进程。</p><p>记录型信号量是由于它采用了记录型的数据结构而得名的。它所包含的两个数据项可描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>{</span></span><br><span class="line"><span class="type">int</span> value;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">process_control_block</span> *<span class="title">list</span>;</span></span><br><span class="line">}semaphore;</span><br></pre></td></tr></tbody></table></figure><p>相应地，wait(S)和signal(S)操作可描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">wait(semaphore *S){</span><br><span class="line">S-&gt;value--;<span class="comment">//申请访问资源，可用资源数量-1</span></span><br><span class="line"><span class="keyword">if</span> (S-&gt;value&lt;<span class="number">0</span>) block(S-&gt;<span class="built_in">list</span>);<span class="comment">//如果可用资源数量为负，则阻塞进程，将其加入等待队列</span></span><br><span class="line">}</span><br><span class="line">signal(semaphore *S){</span><br><span class="line">S-&gt;value++;<span class="comment">//释放资源，可用资源数量+1</span></span><br><span class="line"><span class="keyword">if</span> (S-&gt;value&lt;=<span class="number">0</span>) wakeup(S-&gt;<span class="built_in">list</span>);<span class="comment">//如果value&lt;=0，说明等待队列中还有进程在等待，唤醒进程</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>当资源信号量value&lt;=0时，表示没有空闲资源，此时进程调用block原语进行自我阻塞，满足了让权等待的原则。当进程释放资源后value仍小于0，表明在该信号量链表中仍有等待该资源的进程被阻塞，故调用wakeup原语将链表中的第一个等待进程唤醒。</p><p>如果S-&gt;value的初值为1，表示只允许一个进程访问临界资源，此时的信号量转化为互斥信号量，用于进程互斥。</p><p>3）AND型信号量</p><p>前面所述的进程互斥问题针对的是多个并发进程仅共享一个临界资源的情况。在有些应用场合，一个进程往往需要获得多个资源后方能执行其任务。而所需资源越多，进程间越容易发生冲突。当两个进程，既不释放自己手里的资源，又必须在获得对方的资源的前提下才能执行完成释放资源时，就会陷入僵持状态，称之为死锁。</p><p>AND同步机制的基本思想是：将进程在整个运行过程中需要的所有资源，一次性全部地分配给进程，待进程使用完后再一起释放。亦即，要么把进程所请求的资源全部分配给它，要么一个也不分配。这样就可以避免了死锁情况的发生。</p><p>为此，在wait操作中增加了一个AND条件，故称为AND同步。或称为同时wait操作，即Swait(Simultaneous wait)定义如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Swait(S1,S2,...,Sn)</span><br><span class="line">{</span><br><span class="line"><span class="keyword">while</span>(TRUE)</span><br><span class="line">{</span><br><span class="line"><span class="keyword">if</span> (Si&gt;=<span class="number">1</span> &amp;&amp;...&amp;&amp; Sn&gt;=<span class="number">1</span>){</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++)Si--;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">}</span><br><span class="line"><span class="keyword">else</span> {</span><br><span class="line">将进程置于与发现的第一个Si&lt;<span class="number">1</span>的Si相关的等待队列中，并将该进程的程序计数设置为Swait操作的开始</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">Ssignal(S1,S2,...,Sn){</span><br><span class="line"><span class="keyword">while</span> (TRUE){</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++){</span><br><span class="line">Si++;</span><br><span class="line">将所有在与Si相关的队列中等待的进程移到就绪队列中;</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>4）信号量集</p><p>记录型信号量机制中，每次仅能对某类临界资源进行一个单位的申请或释放，这显然是低效的。此外，有时在资源的数量低于某一下限值时，为保证系统的安全性，应当对申请该资源的进程予以拒绝。基于上述两点，可以对AND信号量机制加以扩充，对进程所申请的所有资源以及每类资源不同的资源需求量，在一次P、V原语操作中完成申请或释放。</p><p>进程对信号量Si的测试值不再是1，而是该资源的分配下限值$t_{i}$，即要求$S_{i}&gt;=t_{i}$，否则不予分配。一旦允许分配，进程对该资源的需求量值为$d_{i}$，即表示资源占用量，进行$S_{i}=S_{i}-d_{i}$，操作，而非简单的$S_{i}=S_{i}-1$。</p><p>由此形成一般化的“信号量集”机制。对应的<code>Swait</code>和<code>Ssignal</code>格式为：</p><p>$Swait(S1,t1,d1,…,Sn,tn,dn)$;</p><p>$Ssignal(S1,d1,…,Sn,dn)$;</p><h5 id="4-信号量的应用"><a href="#4-信号量的应用" class="headerlink" title="4.信号量的应用"></a>4.信号量的应用</h5><p>1.利用信号量实现进程互斥</p><p>为使多个进程能够互斥地访问某临界资源，只需为该临界资源设置一互斥信号量mutex，并设其初始值为1，然后将各进程访问该资源的临界区CS置于wait(mutex)和signal(mutex)操作之间即可。</p><p>2.利用信号量实现前驱关系</p><p>设有两个并发的进程P1和P2，P1中有语句S1，P2中有语句S2，我们希望在S1执行结束之后才能执行S2。为实现这种前驱关系，只需使进程P1和P2共享一个公用信号量S，并赋予其初值为0，将signal(S)操作放在S1语句之后，将wait(S)操作放在S2语句之前即可。</p><p>此时若在S1之前执行S2，由于S&lt;=0，进程P2必定阻塞，直至P1执行完S2后，signal(S)操作释放了资源，才能将P2从阻塞队列中唤醒，由此确保了S1和S2的前驱关系。</p><h5 id="5-管程机制"><a href="#5-管程机制" class="headerlink" title="5. 管程机制"></a>5. 管程机制</h5><p>1）管程的定义</p><p>信号量机制的引入解决了进程同步的描述问题，但信号量的大量同步操作分散在各个进程中不便于管理，还有可能导致系统死锁。如：生产者消费者问题中将P、V颠倒可能死锁。</p><p>为此Dijkstra于1971年提出：把所有进程对某一种临界资源的同步操作都集中起来，构成一个所谓的秘书进程。凡要访问该临界资源的进程，都需先报告秘书，由秘书来实现诸进程对同一临界资源的互斥使用。</p><p>即利用共享数据结构抽象地表示系统中的共享资源，并且将对该共享结构实施的特定操作定义为一组过程。进程对共享资源的申请、释放和其它操作必须通过这组过程，间接地对共享数据结构实现操作。</p><p>对于请求访问共享资源的诸多并发进程，可以根据资源的情况接受或阻塞，确保每次仅有一个进程进入管程，执行这组过程，使用共享资源，达到对共享资源所有访问的统一管理，有效地实现进程互斥。</p><p>代表共享资源的数据结构以及由对该数据结构实施操作的一组过程所组成的资源管理程序共同过程了一个操作系统的资源管理模块，我们称之为管程。</p><p>管程的特性：</p><ol><li>模块化：即管程是一个基本的程序单位，可以单独编译；</li><li>抽象数据类型：指管程中不仅有数据，而且有对数据的操作。</li><li>信息掩蔽：指管程中的数据结构只能被管程中的过程访问，这些过程也是在管程内部定义的，供管程外的进程调用，而管程中的数据结构以及过程的具体实现外部不可见。</li></ol><p>2）条件变量</p><p> 在利用管程实现进程同步时，必须设置同步工具，如两个同步操作原语wait和signal。而仅此还不够，考虑一种情况：当一个进程调用了管程，在管程中时被阻塞或挂起，直到阻塞或挂起的原因解除，而在此期间，如果进程不释放管程，则其他进程无法进入管程，被迫长时间等待。为了解决这个问题，引入了条件变量condition。</p><p>通常，一个进程被阻塞或挂起的原因可有多个，因此在管程中设置了多个条件变量，对这些条件变量的访问只能在管程中进行。condition x,y 表示引起进程阻塞的原因是x事件和y事件。</p><p>对条件变量的操作是wait和signal，因此条件变量也是一种抽象数据类型。每个条件变量保存了一个链表，用于记录因该条件变量而阻塞的所有进程，同时提供的两个操作即可表示为x.wait和x.signal，其含义为：</p><ol><li>x.wait：正在调用管程的进程因为x条件需要被阻塞或挂起，则调用x.wait将自己插入到x条件的等待队列上，并释放管程，直到x条件发生变化。</li><li>x.signal：正在调用管程的进程发现x条件发生了变化，则调用x.signal，重新启动一个因x条件而被阻塞或挂起的进程。如果x条件变化，但没有等待进程，则原进程继续执行而不产生任何结果。</li></ol><h4 id="2-5-经典的进程同步问题"><a href="#2-5-经典的进程同步问题" class="headerlink" title="2.5 经典的进程同步问题"></a>2.5 经典的进程同步问题</h4><h5 id="1-生产者-消费者问题"><a href="#1-生产者-消费者问题" class="headerlink" title="1. 生产者-消费者问题"></a>1. 生产者-消费者问题</h5><p>有一群生产者进程在生产产品，并将这些产品提供给消费者进程去消费。为使生产者进程与消费者进程能并发执行，在两者之间设置了一个具有n个缓冲区的缓冲池，生产者进程将其所生产的产品放入一个缓冲区中；消费者进程可以从一个缓冲区中取走产品去消费。尽管所有的生产者进程和消费者进程都是以异步方式运行的，但它们之间必须保持同步，既不允许一个消费者进程到一个空缓冲区中去取产品，也不允许生产者进程向一个已装满产品且尚未被取走的缓冲区中投放产品。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210918234344105-1454075700.png" alt="img" style="zoom:80%;"></p><p>1）利用记录型信号量解决生产者-消费者问题</p><p>可以利用互斥信号量mutex实现诸进程对缓冲池的互斥使用；利用信号量empty表示空缓冲区的数量，信号量full表示满缓冲区的数量。对生产者-消费者问题描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> in=<span class="number">0</span>,out=<span class="number">0</span>;</span><br><span class="line">item buffer[n];</span><br><span class="line">semaphore mutex=<span class="number">1</span>,empty=n,full=<span class="number">0</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">producer</span><span class="params">()</span>{</span><br><span class="line"><span class="keyword">do</span> {</span><br><span class="line">producer an item nextp;<span class="comment">//生产者想要生产一件产品</span></span><br><span class="line">...</span><br><span class="line">wait(empty);<span class="comment">//首先申请一个空缓冲区</span></span><br><span class="line">wait(mutex);<span class="comment">//mutex用来实现诸进程对缓冲池的互斥使用，防止多个进程抢占一个缓冲区</span></span><br><span class="line">buffer[in]=nextp;<span class="comment">//将产品放入空缓冲区</span></span><br><span class="line">in=(in+<span class="number">1</span>)%n;</span><br><span class="line">signal(mutex);<span class="comment">//释放缓冲池，允许其它进程使用缓冲池</span></span><br><span class="line">signal(full);<span class="comment">//满缓冲区+1，即缓冲池中的产品+1</span></span><br><span class="line">}<span class="keyword">while</span>(TRUE);</span><br><span class="line">}</span><br><span class="line"><span class="type">void</span> <span class="title function_">consumer</span><span class="params">()</span>{</span><br><span class="line">    <span class="keyword">do</span> {</span><br><span class="line">        wait(full);<span class="comment">//申请一个满缓冲区，即申请一件产品</span></span><br><span class="line">        wait(mutex);<span class="comment">//实现进程互斥，防止多个进程申请消费同一件产品</span></span><br><span class="line">        netxc=buffer[out];<span class="comment">//从满缓冲区取走一件产品</span></span><br><span class="line">        out=(out+<span class="number">1</span>)%n;</span><br><span class="line">        signal(mutex);<span class="comment">//释放缓冲池</span></span><br><span class="line">        signal(empty);<span class="comment">//释放空缓冲区，空缓冲区+1</span></span><br><span class="line">        consumer the item in nextc;</span><br><span class="line">        ...</span><br><span class="line">    }<span class="keyword">while</span>(TRUE);</span><br><span class="line">}</span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">()</span>{</span><br><span class="line">    cobegin</span><br><span class="line">        <span class="title function_">producer</span><span class="params">()</span>; consumer();</span><br><span class="line">    coend</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>注意：首先，wait(mutex)和signal(mutex)必须成对出现；其次，对资源信号量empty和full的wait和signal操作也同样需要成对出现，只不过它们分别处于不同的程序中；最后，在每个程序中的多个wait操作顺序不能颠倒，应先执行对资源信号量的wait操作，然后再执行对互斥信号量mutex的wait操作，否则可能引起进程死锁。</p><blockquote><p>如果缓冲池已满，且生产者进程仍想继续生产产品，若此时先执行wait(mutex)再执行wait(empty)，则缓冲池被锁，消费者进程无法进入缓冲池取走产品，同时生产者进程的请求也无法得到满足，陷入死锁状态。因此，必须保证P同步在前，P互斥在后，而V操作的顺序可以互换。</p></blockquote><p>2）利用AND型信号量解决生产者-消费者问题</p><p>生产者（消费者）需要同时满足两个条件才能正常进行生产和消费：一是具有一个空（满）缓冲区，二是各个进程互斥地使用缓冲池。故可以用AND型信号量解决生产者-消费者问题，即用Swait(empty/full,mutex)来代替wait(empty/full)和wait(mutex)，用Ssignal(mutex,empty/full)来代替signal(mutex)和mutex(empty/full)。描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i=<span class="number">0</span>,out=<span class="number">0</span>;</span><br><span class="line">item buffer[n];</span><br><span class="line">semaphore mutex=<span class="number">1</span>,empty=n,full=<span class="number">0</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">producer</span><span class="params">()</span>{</span><br><span class="line"><span class="keyword">do</span> {</span><br><span class="line">producer an item nextp;</span><br><span class="line">...</span><br><span class="line">Swait(empty,mutex);</span><br><span class="line">buffer[in]=nextp;</span><br><span class="line">in=(in+<span class="number">1</span>)%n;</span><br><span class="line">Ssignal(mutex,full);</span><br><span class="line">}<span class="keyword">while</span>(TRUE);</span><br><span class="line">}</span><br><span class="line"><span class="type">void</span> <span class="title function_">consumer</span><span class="params">()</span>{</span><br><span class="line"><span class="keyword">do</span> {</span><br><span class="line">Swait(full,mutex);</span><br><span class="line">nextc=buffer[out];</span><br><span class="line">out=(out+<span class="number">1</span>)%n;</span><br><span class="line">Ssignal(mutex,empty);</span><br><span class="line">consumer the item in nextc;</span><br><span class="line">...</span><br><span class="line">}<span class="keyword">while</span>(TRUE);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>3）利用管程解决生产者-消费者问题</p><p>建立一个管程，命名为producerconsumer，简称为PC，其中包括两个过程：</p><p>（1）put(x)过程。生产者利用该过程将自己生产的产品投放到缓冲池中，并用整型变量count来表示在缓冲池中已有的产品数量，当count&gt;=N时，表示缓冲池已满，生产者需等待。</p><p>（2）get(x)过程。消费者利用该过程从缓冲池中取出一个产品，当count&lt;=0时，表示缓冲池中已无可取用的产品，消费者需等待。</p><p>对于条件变量notfull和notempty，分别有两个过程cwait和csignal对它们进行操作：</p><p>（1）cwait(condition)过程：当管程被一个进程占用时，其他进程调用该过程时阻塞，并挂在条件condition的队列上。</p><p>（2）csignal(condition)过程：唤醒在cwait执行后阻塞在条件condition队列上的进程。如果这样的进程不止一个，则选择其中一个实施唤醒操作；如果队列为空，则无操作而返回。</p><p>PC管程可描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Monitor producerconsumer{</span><br><span class="line">item buffer[N];</span><br><span class="line"><span class="type">int</span> in,out;</span><br><span class="line">condition notfull,notempty;</span><br><span class="line"><span class="type">int</span> count;</span><br><span class="line">public:</span><br><span class="line"><span class="type">void</span> <span class="title function_">put</span><span class="params">(item x)</span>{</span><br><span class="line"><span class="keyword">if</span> (count&gt;=N) cwait(notfull);<span class="comment">//如果缓冲池已满，则阻塞进程并插入notfull等待队列</span></span><br><span class="line">buffer[in]=x;</span><br><span class="line">in=(in+<span class="number">1</span>)%N;</span><br><span class="line">count++;</span><br><span class="line">csignal(notempty);</span><br><span class="line">}</span><br><span class="line"><span class="type">void</span> <span class="title function_">get</span><span class="params">(item x)</span>{</span><br><span class="line"><span class="keyword">if</span> (count&lt;=<span class="number">0</span>) cwait(notempty);<span class="comment">//如果缓冲池为空，则阻塞进程并插入notempty等待队列</span></span><br><span class="line">x=buffer[out];</span><br><span class="line">out=(out+<span class="number">1</span>)%N;</span><br><span class="line">count--;</span><br><span class="line">csignal(notfull);</span><br><span class="line">}</span><br><span class="line">{in=<span class="number">0</span>;out=<span class="number">0</span>;count=<span class="number">0</span>;}</span><br><span class="line">}PC;</span><br></pre></td></tr></tbody></table></figure><p>在利用管程解决生产者-消费者问题时，其中的生产者和消费者可描述为：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">producer</span><span class="params">()</span>{</span><br><span class="line">    item x;</span><br><span class="line">    <span class="keyword">while</span>(TRUE){</span><br><span class="line">        ...</span><br><span class="line">    producer an item in nextp;</span><br><span class="line">        PC.put(x);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"><span class="type">void</span> <span class="title function_">consumer</span><span class="params">()</span>{</span><br><span class="line">    item x;</span><br><span class="line">    <span class="keyword">while</span>(TRUE){</span><br><span class="line">        PC.get(x);</span><br><span class="line">        consumer the item nextc;</span><br><span class="line">        ...</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">()</span>{</span><br><span class="line">    cobegin</span><br><span class="line">    <span class="title function_">producer</span><span class="params">()</span>; consumer();</span><br><span class="line">    coend</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h5 id="2-读者-写者问题"><a href="#2-读者-写者问题" class="headerlink" title="2. 读者-写者问题"></a>2. 读者-写者问题</h5><p>问题描述：有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读或写）同时访问共享数据时，则可能导致数据不一致的错误，因此要求：（1）允许多个读者同时对文件进行读操作；（2）只允许一个写进程往文件中写信息；（3）任一写者在完成写操作之前不允许其它读者或写者工作；（4）写者进行写操作之前，应让已有的读者和写者全部退出。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210919123656116-604008233.png" alt="img" style="zoom:80%;"></p><p>问题分析：读者和写者是互斥的，写者之间也是互斥的，读者之间是同步的。写者和任何其它进程互斥，因此很简单，用互斥信号量的P、V操作即可实现。读者则必须在与写者互斥的同时实现与其它读者的同步。</p><p>代码如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> count=<span class="number">0</span>;    <span class="comment">//count用于记录当前的读者数量</span></span><br><span class="line">semaphore mutex=<span class="number">1</span>;    <span class="comment">//用于保护更新count变量时的互斥</span></span><br><span class="line">semaphore rw=<span class="number">1</span>;    <span class="comment">//读写进程互斥信号量，用于保证读者和写者互斥地访问文件</span></span><br><span class="line">writer(){</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">        P(rw);    <span class="comment">//互斥访问共享文件</span></span><br><span class="line">        writing;<span class="comment">//写入</span></span><br><span class="line">        V(rw);     <span class="comment">//释放共享文件</span></span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">reader(){</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">        P(mutex);<span class="comment">//申请访问临界资源count</span></span><br><span class="line">        <span class="keyword">if</span> (count==<span class="number">0</span>) </span><br><span class="line">            P(rw);<span class="comment">/*如果读者进程数量为0，此时文件可能正在被writer进程使用，执行P操作，即wait(rw)，申请该资源，若该资源正在被写，则申请失败，进入等待队列排队，若wait(rw)成功，即此时既没有读者进程也没有写者进程，则保证了在进行读操作时与writer进程互斥。若count!=0，说明此时有读者进程正在读，则writer进程已经互斥，无需再执行wait(rw)操作，而读操作之间是不互斥的，直接读即可。*/</span></span><br><span class="line">        count++;</span><br><span class="line">        V(mutex);<span class="comment">//对count操作结束后释放资源以便其他进程访问</span></span><br><span class="line">        reading;<span class="comment">//读取文件</span></span><br><span class="line">        P(mutex);<span class="comment">//读取结束后需要让count--，申请访问count</span></span><br><span class="line">        count--;</span><br><span class="line">        <span class="keyword">if</span> (count==<span class="number">0</span>)</span><br><span class="line">            V(rw);<span class="comment">//如果count==0，没有进程在读文件，则归还文件，释放资源</span></span><br><span class="line">        V(mutex);<span class="comment">//释放互斥变量count</span></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>在上面的算法中，读进程是优先的，即当存在读进程时，写操作将被延迟，且只要有一个读进程活跃，随后而来的读进程都将被孕育访问文件。这样的方式会导致写进程长时间的等待，且存在写进程“饿死”的情况。</p><p>若希望避免上述情况，则当有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求。等到已在共享文件中的读进程执行完毕，立即让写进程执行。（同理，为保证读写公平，应按照阻塞队列的顺序先后唤醒进程。）</p><p>改进代码如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> count=<span class="number">0</span>;</span><br><span class="line">semaphore mutex=<span class="number">1</span>;</span><br><span class="line">semaphore rw=<span class="number">1</span>;</span><br><span class="line">semaphore w=<span class="number">1</span>;<span class="comment">//用于避免写进程饿死</span></span><br><span class="line">writer(){</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">        P(w);<span class="comment">//在无写者进程请求时进入</span></span><br><span class="line">        P(rw);</span><br><span class="line">        writing;</span><br><span class="line">        V(rw);</span><br><span class="line">        V(w);<span class="comment">//恢复对共享文件的访问</span></span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line">reader(){</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">        P(w);<span class="comment">//在无写者进程请求时进入</span></span><br><span class="line">        P(mutex);</span><br><span class="line">        <span class="keyword">if</span> (count==<span class="number">0</span>) </span><br><span class="line">            P(rw);</span><br><span class="line">        count++;</span><br><span class="line">        V(mutex);</span><br><span class="line">        V(w);<span class="comment">//恢复对共享文件的访问</span></span><br><span class="line">        reading;</span><br><span class="line">        P(mutex);</span><br><span class="line">        count--;</span><br><span class="line">        <span class="keyword">if</span> (count==<span class="number">0</span>)</span><br><span class="line">            V(rw);</span><br><span class="line">        V(mutex);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h5 id="3-哲学家进餐问题"><a href="#3-哲学家进餐问题" class="headerlink" title="3. 哲学家进餐问题"></a>3. 哲学家进餐问题</h5><p>问题描述：有五个哲学家共用一张圆桌，分别坐在周围的五张椅子上，在桌上有五个碗和五只筷子，他们的生活方式是交替地进行思考和进餐。平时，一个哲学家进行思考，饥饿时便试图取其左右最靠近他的筷子，只有在他拿到两只筷子时才能进餐。进餐毕，放下筷子继续思考。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210919113950697-271711805.png" alt="img" style="zoom: 50%;"></p><p>1）利用记录型信号量解决哲学家进餐问题</p><p>经分析可知，放在桌子上的筷子是临界资源，在一段时间内只允许一位哲学家使用。为了实现对筷子的互斥使用，可以用一个信号量表示一只筷子，由这5个信号量构成信号量数组。其描述如下：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">semaphore chopstick[<span class="number">5</span>]={<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>};</span><br></pre></td></tr></tbody></table></figure><p>所有信号量均被初始化为1，第i位哲学家的活动可描述为：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">do</span> {</span><br><span class="line">    wait(chopstick[i]);</span><br><span class="line">    wait(chopstick[(i+<span class="number">1</span>)%<span class="number">5</span>]);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//eat</span></span><br><span class="line">    ...</span><br><span class="line">    signal(chopstick[i]);</span><br><span class="line">    signal(chopstick[(i+<span class="number">1</span>)%<span class="number">5</span>]);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//think</span></span><br><span class="line">    ...</span><br><span class="line">}<span class="keyword">while</span>(TRUE);</span><br></pre></td></tr></tbody></table></figure><p>在以上描述中，当哲学家饥饿时，总是先去拿他左边的筷子，即执行<code>wait(chopstick[i])</code>；成功后，又去拿他右边的筷子，即执行<code>wait(chopstick[(i+1)%5])</code>；又成功后便可进餐。进餐毕，先放回左边的筷子，再放回右边的筷子。虽然，上述解法可以保证不会有两个相邻的哲学家同时进餐，但却有可能引起死锁。假如五个哲学家同时饥饿而各自拿起左手边的筷子时，就会使五个信号量chopstick均为0，当他们再试图去拿起右边的筷子时，都将因无筷子可拿而陷入无限期的等待。</p><p>对于这样的死锁问题，可采取以下几种解决方法：</p><ol><li>至多只允许有4位哲学家同时去拿左边的筷子最终能保证至少有一位哲学家能够进餐，并在用餐毕时能释放出他用过的两只筷子，从而使更多的哲学家能够进餐。</li><li>仅当哲学家的左右两只筷子均可用时，才允许他拿起筷子进餐。</li><li>规定奇数号哲学家先拿他左边的筷子，然后再去拿右边的筷子；而偶数号哲学家则相反。按此规定，将是1、2号哲学家竞争1号筷子；3、4号哲学家竞争3号筷子。即五位哲学家都先竞争奇数号筷子，获得后，再去竞争偶数号筷子，最后总会有一位哲学家能获得两只筷子而进餐。</li></ol><p>2）利用AND型信号量机制解决哲学家进餐问题</p><p>在哲学家进餐问题中，要求每个哲学家获得两个临界资源（筷子）后才能进餐，这在本质上就是前面所介绍的AND同步问题，故利用AND信号量机制可获得最简洁的解法。</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">semaphore chopstick[<span class="number">5</span>]={<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>};</span><br><span class="line"><span class="keyword">do</span> {</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//think</span></span><br><span class="line">    ...</span><br><span class="line">    Swait(chopstick[(i+<span class="number">1</span>)%<span class="number">5</span>],chopstick[i]);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//eat</span></span><br><span class="line">    ...</span><br><span class="line">    Ssignal(chopstick[(i+<span class="number">1</span>)%<span class="number">5</span>],chopstick[i]);</span><br><span class="line">}<span class="keyword">while</span>(TRUE);</span><br></pre></td></tr></tbody></table></figure><h5 id="4-吸烟者问题"><a href="#4-吸烟者问题" class="headerlink" title="4. 吸烟者问题"></a>4. 吸烟者问题</h5><p>吸烟者问题是为了解决“可以生产多个产品的单生产者”问题提供了一个思路。</p><p>问题描述：有三个抽烟者和一个供应者。每个抽烟者不停地卷烟抽，组成一根烟需要三种材料：烟草、纸和胶水。三个抽烟者中，第一个有烟草，第二个有纸，第三个拥有胶水。供应者无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，那么供应者可以继续提供另外两种材料，如此重复（让三个抽烟者轮流地抽烟）。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210919150521872-1834185513.png" alt="img" style="zoom:80%;"></p><p>问题分析：</p><p>1）关系分析。供应者与三个抽烟者分别是同步关系。供应着无法同时满足两个或两个以上的抽烟者，所以三个抽烟者是互斥关系。<br>2）整理思路。这里有四个进程，一个供应者，三个抽烟者。<br>3）信号量设置。信号量offer1，offer2，offer3分别表示烟草和纸的组合、烟草和胶水的组合、纸和胶水的组合。信号量finish用于互斥进行抽烟动作。</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> random; <span class="comment">//存储随机数</span></span><br><span class="line">semaphore offer1=<span class="number">0</span>; <span class="comment">//定义信号量对应烟草和纸组合的资源</span></span><br><span class="line">semaphore offer2=<span class="number">0</span>; <span class="comment">//定义信号量对应烟草和胶水组合的资源</span></span><br><span class="line">semaphore offer3=<span class="number">0</span>; <span class="comment">//定义信号量对应纸和胶水组合的资源</span></span><br><span class="line">semaphore finish=<span class="number">0</span>; <span class="comment">//定义信号量表示抽烟是否完成</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//供应者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">    random = 任意一个整数随机数;</span><br><span class="line">    random=random% <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">if</span>(random==<span class="number">0</span>)</span><br><span class="line">        V(offerl) ; <span class="comment">//提供烟草和纸</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(random==l) </span><br><span class="line">        V(offer2);  <span class="comment">//提供烟草和胶水</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        V(offer3)  <span class="comment">//提供纸和胶水</span></span><br><span class="line">    <span class="comment">// 任意两种材料放在桌子上;</span></span><br><span class="line">    P(finish);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//拥有烟草者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">    P (offer3);</span><br><span class="line">    <span class="comment">// 拿纸和胶水，卷成烟，抽掉;</span></span><br><span class="line">    V(finish);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//拥有纸者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">    P(offer2);</span><br><span class="line">    <span class="comment">// 烟草和胶水,卷成烟，抽掉；</span></span><br><span class="line">    V(finish);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">//拥有胶水者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>){</span><br><span class="line">    P(offer1);</span><br><span class="line">    <span class="comment">// 拿烟草和纸，卷成烟，抽掉;</span></span><br><span class="line">    v(finish);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h4 id="2-6-进程通信"><a href="#2-6-进程通信" class="headerlink" title="2.6 进程通信"></a>2.6 进程通信</h4><blockquote><p>进程通信是指进程间的信息交换。P、V操作是低级通信方式，高级通信方式是指以较高速率传输大量数据的通信方式。</p></blockquote><p>目前，高级通信机制可归结为四大类：共享存储器系统、管道通信系统、消息传递系统以及客户机-服务器系统。</p><h5 id="1-共享存储器系统"><a href="#1-共享存储器系统" class="headerlink" title="1. 共享存储器系统"></a>1. 共享存储器系统</h5><p>在共享存储器系统中，相互通信的进程共享某些数据结构或共享存储区，进程之间能够通过这些空间进行通信。据此，又可分为基于共享数据结构的通信方式和基于共享存储区的通信方式。</p><p>基于共享数据结构的通信方式仅适于传递相对少量的数据，通信效率底下，属于低级通信方式。</p><p>基于共享存储区的通信方式为了传输大量数据，在内存中划出了一块共享存储区域，诸进程可通过对该共享区域的读或写交换信息，数据的形式及位置甚至访问控制都是由进程负责，而不是OS，属于高级通信方式。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210801092007946-1777432566.png" alt="img" style="zoom: 80%;"></p><h5 id="2-管道-pipe-通信系统"><a href="#2-管道-pipe-通信系统" class="headerlink" title="2. 管道(pipe)通信系统"></a>2. 管道(pipe)通信系统</h5><p>所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名pipe文件。</p><p>向管道（共享文件）提供输入的发送进程（即写进程）以字符流形式将大量数据送入管道；而接受管道输出的接收进程（即读进程）则从管道中接收数据。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210801092403875-920699540.png" alt="img" style="zoom: 80%;"></p><p>为了协调双方的通信，管道机制必须提供以下三个方面的协调能力：一、互斥，即当一个进程正在对pipe执行读/写操作时，其它进程必须等待；二、同步，指当写进程把一定数量的数据写入pipe，便去睡眠等待，直到读进程取走数据后再把它唤醒；当读进程读一空pipe时，也应睡眠等待直至写进程写入数据后再将它唤醒；三、确定对方是否存在，只有确定了对方已存在时才能进行通信。</p><h5 id="3-消息传递系统"><a href="#3-消息传递系统" class="headerlink" title="3. 消息传递系统"></a>3. 消息传递系统</h5><p>在该机制中，进程不必借助任何共享存储区或数据结构，而是以格式化的消息（message）为单位，将通信的数据封装在消息中，并利用操作系统提供的一组通信命令（原语），在进程间进行消息传递，完成进程间的数据交换。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210801094007632-1260755192.png" alt="img" style="zoom:80%;"></p><p>该方式隐藏了通信实现细节，使通信过程对用户透明化。</p><p>基于消息传递系统的通信方式属于高级通信方式，因其实现方式的不同，可进一步分为：一、直接通信方式，指发送进程通过操作系统所提供的发送原语，直接把消息发送给目标进程。二、间接通信方式，指发送和接收进程都通过共享中间实体（称为邮箱）的方式进行消息的发送和接收，完成进程间的通信。</p><h5 id="4-客户机-服务器系统"><a href="#4-客户机-服务器系统" class="headerlink" title="4. 客户机-服务器系统"></a>4. 客户机-服务器系统</h5><p>客户机-服务器系统的通信机制，在网络环境的各种应用领域已成为当前主流的通信实现机制，其主要的实现方法分为三类：套接字、远程过程调用和远程方法调用。</p><p>套接字：一个套接字就是一个通信标识类型的数据结构，包含了通信目的的地址、通信使用的端口号、通信网络的传输层协议、进程所在的网络地址，以及针对客户或服务器程序提供的不同系统调用等，是进程通信和网络通信的基本构件。套接字包括基于文件型和基于网络型两类。</p><p>远程过程调用RPC是一个通信协议，它允许运行于一台主机（本地）系统上的进程调用另一台主机（远程）系统上的进程，而对程序员表现为常规的过程调用，无需额外地为此编程。</p><h4 id="2-7-线程的基本概念"><a href="#2-7-线程的基本概念" class="headerlink" title="2.7 线程的基本概念"></a>2.7 线程的基本概念</h4><h5 id="1-线程的引入"><a href="#1-线程的引入" class="headerlink" title="1. 线程的引入"></a>1. 线程的引入</h5><p>如果说，在OS中引入进程是为了使多个程序能够并发执行，以提高资源利用率和系统吞吐量，那么，在操作系统中再引入线程，则是为了减少程序在并发执行时所付出的时空开销，使OS具有更好的并发性。</p><p>首先让我们来回顾进程的两个基本属性：</p><p>1）进程是一个可拥有资源的独立单位，一个进程要能独立运行，它必须拥有一定的资源，包括用于存放程序正文、数据的磁盘和内存地址空间，以及它在运行时所需要的I/O设备、已打开的文件、信号量等；</p><p>2）进程同时又是一个可独立调度和分派的基本单位，一个进程要能独立运行，它还必须是一个可独立调度和分派的基本单位。每个进程在系统中有唯一的PCB，系统可通过PCB感知进程的存在，也可以根据PCB中的信息对进程进行调度，还可将断点信息保存在其PCB中。反之，再利用进程PCB中的信息来恢复进程运行的现场。</p><p>正是由于进程有这两个基本属性，才能使进程成为一个能够独立运行的基本单位，从而也就构成了程序并发执行的基础。</p><p>为使程序能够并发执行，系统必须进行创建进程、撤销进程、进程切换等一系列操作，因此系统也必须为之付出较大的时空开销。这就限制了系统中所设置进程的数目，而且进程切换也不宜过于频繁，从而限制了并发程度的进一步提高。</p><p>为使多个程序能够更好地并发执行，同时又尽量减少系统的开销，可以将进程的上述两个基本属性分开，由OS分开处理。亦即并不把调度和分派的基本单位也同时作为拥有资源的单位，以做到“轻装上阵”；而对于拥有资源的基本单位，又不对之施以频繁的切换。由此产生了线程的概念。</p><blockquote><p>也就是说，进程作为拥有资源的单位，频繁的对它进行切换和调度会产生大量的时空开销，为了减少开销，应该将拥有资源的单位和作为进程调度的单位分开，即进程作为拥有资源的基本单位，而将线程作为调度和分派的基本单位，以减少程序在并发执行时的时空开销。</p></blockquote><h5 id="2-进程与线程的比较"><a href="#2-进程与线程的比较" class="headerlink" title="2. 进程与线程的比较"></a>2. 进程与线程的比较</h5><ol><li><p>调度的基本单位</p><p>在传统的OS中，进程作为独立调度和分派的基本单位，因而进程是能够独立运行的基本单位。每次被调度时都需要进行上下文切换，开销较大。而在引入线程的OS中，将线程作为调度和分派的基本单位，因而线程是能够独立运行的基本单位。当线程切换时，仅需保存和设置少量寄存器内容，切换代价远低于进程。</p></li><li><p>并发性</p><p>在引入线程的OS中，不仅进程之间可以并发执行，而且在一个进程的多个线程之间也能并发执行。同样，不同进程中的线程也能并发执行。这使得操作系统具有更好的并发性，从而能更有效地提高系统资源的利用率和系统的吞吐量。</p></li><li><p>拥有资源</p><p>进程可以拥有资源，并作为系统中拥有资源的一个基本单位。然而，线程本身并不拥有资源，仅有一点必不可少的、能满足独立运行的资源。线程除了拥有自己的必要资源意外，还允许多个线程共享该进程所拥有的资源。</p></li><li><p>独立性</p><p>在同一个进程中不同线程的独立性要比不同进程之间的独立性低得多。这是因为，为防止进程之间彼此破坏和干扰，每个进程都拥有一个独立的地址空间和其它资源，除了共享全局变量外，不允许其它进程访问。但是同一个进程间的不同线程往往是为了提高并发性以及进行相互之间的合作而创建的，它们共享进程的内存地址空间和资源。由一个线程打开的文件可供其它线程读、写。</p></li><li><p>系统开销</p><p>进程的创建、撤销和切换的代价远高于线程。</p></li><li><p>支持多处理机系统</p><p>单线程进程只能运行在一个处理机上，多线程进程可以将多个线程分配到多个处理机上，使它们<strong>并行</strong>执行。</p></li></ol><h5 id="3-线程的状态和线程控制块"><a href="#3-线程的状态和线程控制块" class="headerlink" title="3. 线程的状态和线程控制块"></a>3. 线程的状态和线程控制块</h5><p>线程运行的三个状态：执行状态、就绪状态、阻塞状态。</p><p><img src="source/images/操作系统1：进程控制与描述/1774310-20210801233034606-794137008.png" alt="img"></p><p>线程控制块TCB：记录了用于控制和管理线程的所有信息，包括线程标识符、一组寄存器（程序计数器PC、状态寄存器和通用寄存器）、线程运行状态、优先级、线程专有存储区、信号屏蔽、堆栈指针。</p><p>多线程OS中的进程属性：</p><ol><li>进程是一个可拥有资源的基本单位。</li><li>多个线程可并发执行。</li><li>线程作为独立运行的基本单位，进程不再是可执行的实体。</li></ol><h4 id="2-8-线程的实现"><a href="#2-8-线程的实现" class="headerlink" title="2.8 线程的实现"></a>2.8 线程的实现</h4><h5 id="1-线程的实现方式"><a href="#1-线程的实现方式" class="headerlink" title="1. 线程的实现方式"></a>1. 线程的实现方式</h5><p>1）内核支持线程KST（Kernel Supported Threads）</p><p>在OS中的所有<strong>进程</strong>，无论是系统进程还是用户进程，都是在操作系统内核的支持下运行的，是与内核紧密相关的。</p><p>而内核支持<strong>线程</strong>KST，同样也是在内核的支持下运行的，它们的创建、阻塞、切换和撤销等，都在内核空间实现。</p><p>为了对内核线程进行控制和管理，在内核空间为每一个内核线程设置了一个线程控制块，内核根据该控制块而感知线程的存在，并对其加以控制。</p><p>内核级线程实现方式的优点：</p><ol><li>在多处理器系统中，内核能够同时调度同一进程中的多个线程并行执行；</li><li>如果某个线程被阻塞，内核可以调度该进程的其他线程占有处理机运行，也可以运行其它进程中的线程；</li><li>内核支持线程具有很小的数据结构和堆栈，线程切换较快、开销较小；</li><li>内核本身也可以采用多线程技术，提高系统的执行速度和效率。</li></ol><p>主要缺点：线程调度和管理是在内核实现的，用户的线程运行在用户态，当进行线程切换时，需要切换到内核态，<strong>模式切换的开销较大</strong>。</p><p>2）用户级线程ULT（User Level Threads）</p><p>用户级线程是在用户空间中实现的。对线程的创建、撤销、同步与通信等功能，都无需内核的支持，即用户级线程是与内核无关的。由于这些线程的任务控制块都是设置在用户空间，而线程所执行的操作也无需内核的帮助，因此内核完全不知道用户级线程的存在。</p><p>值得说明的是，对于设置了用户级线程的系统，其调度仍是以进程为单位进行的。</p><p>用户级线程实现方式的优点：</p><ol><li>线程切换不需要转到内核空间。</li><li>不同进程可以根据自身需要选择不同的调度算法。</li><li>用户级线程的实现与OS平台无关。</li></ol><p>主要缺点：一、<strong>系统调用的阻塞问题</strong>，当线程执行一个系统调用时，由于<strong>内核不知道进程中多个用户级线程的存在</strong>，因此会阻塞整个进程，使进程中的其它线程也被阻塞；二、因为内核不知道进程中多个用户级线程的存在，内核每次仅为一个进程分配一个CPU，因此进程中仅有一个线程能执行。</p><p>3）组合方式</p><p>在组合方式线程系统中，内核支持多个内核级线程的建立、调度和管理，同时允许用户应用程序建立、调度和管理用户级进程。组合方式线程中，同一个进程内的多个线程可以同时在多处理器上并行执行，而且在阻塞一个线程时并不需要将整个进程阻塞。所以，组合方式多线程机制能够结合用户级线程与内核级线程的优点，并克服了其各自的不足。</p><p>由于用户级线程与内核支持线程连接方式的不同，从而形成了三种不同的模型：</p><ol><li><p>多对一模型，即将多个用户线程映射到一个内核控制线程。这些用户线程一般属于一个用户进程，运行在该进程的用户空间，对这些线程的调度和管理也是在该进程的用户空间中完成。仅当用户线程需要访问内核时，才将其映射到一个内核控制线程上，但每次只允许一个用户级线程进行映射。</p><p>优点：线程管理的开销小、效率高；</p><p>缺点：如果一个线程在访问内核时发生阻塞，则整个进程都将被阻塞；此外，在任一时刻，只有一个线程能访问内核多个线程不能同时在多个处理机上运行。</p><p><img src="../../../../Download/文档/操作系统笔记/source/images/第二章 进程的描述与控制/f5ff73a1fd0fe2f80271010fc81e61aa.png%23pic_center" alt="img" style="zoom:50%;"></p></li><li><p>一对一模型，即将每一个用户级线程都映射到一个内核支持线程。</p><p>优点：当一个线程被阻塞时，允许调度另一个线程运行。此外，它允许多个线程并行地运行在多处理机系统上。</p><p>缺点：每创建一个用户线程，相应地就需要创建一个内核线程，开销较大，因此需要限制整个系统的线程数。</p><p><img src="../../../../Download/文档/操作系统笔记/source/images/第二章 进程的描述与控制/437f99eaffb30bb7511379659c218070.png%23pic_center" alt="img" style="zoom:50%;"></p></li><li><p>多对多模型，将多个用户线程映射到更少数量的内核线程上。</p><p>该模型结合了一对一模型和多对一模型的优点，它可以像一对一模型那样，使一个进程的多个线程并行地运行在多处理机系统上，也可以像多对一模型那样，减少线程的管理开销和提高效率。</p><p><img src="../../../../Download/文档/操作系统笔记/source/images/第二章 进程的描述与控制/80ea231f29681b9218a7c6b624ff4bc5.png%23pic_center%23pic_center" alt="img" style="zoom:50%;"></p><p><img src="../../../../Download/文档/操作系统笔记/source/images/第二章 进程的描述与控制/7b5f984bea2fefe518636eebe7a4f4a2.png%23pic_center%23pic_center" alt="img" style="zoom:50%;"></p></li></ol><h5 id="2-线程的实现"><a href="#2-线程的实现" class="headerlink" title="2. 线程的实现"></a>2. 线程的实现</h5><p>1）内核支持线程的实现</p><p>在仅设置了内核支持线程的OS中，一种可能的线程控制方法是，系统在创建一个新进程时，便为它分配一个任务数据区PTDA，其中包含若干线程控制块TCB空间。在每一个TCB中可保存线程标识符、优先级、线程运行的CPU状态等信息。虽然这些信息与用户级线程TCB中的信息相同，但现在却是被保存在内核空间中。</p><p>每当进程要创建一个线程时，便为新线程分配一个TCB,将有关信息填入该TCB中，并为之分配必要的资源。在撤销一个线程时，也应该回收该线程的所有资源和TCB。</p><p>2）用户级线程的实现</p><p>一、运行时系统（Running System）</p><p>　　所谓“运行时系统”，实质是用于管理和控制线程的函数集合，包括创建、撤销、线程的同步和通信的函数以及调度的函数。正因为这些函数，才能使用户线程与内核无关，所有函数都驻留在用户空间中，作为用户线程和内核之间的接口。在进行线程切换时，不需要转入核心态，而是由运行时系统中的线程切换来执行切换任务。由于用户线程不能使用系统调用，所以当线程需要系统资源时，将请求传送给运行时系统，由后者通过相应的系统调用来获取系统资源。</p><p>二、内核控制线程</p><p>　　这种线程又称为轻型进程LWP（Light Weight Process）。每一进程可拥有多个LWP，同用户级线程一样，每个LWP都有自己的数据结构（如TCB），其中包括线程标识符、优先级、状态，另外还有栈和局部存储区等。它们可以共享进程所拥有的资源。LWP可通过系统调用来获得内核提供的服务，这样一个用户级线程运行时，只要将它们连接到一个LWP上，此时它便具有了内核支持线程的所有属性，这种线程实现方式就是组合方式。</p><p>　　在一个系统中的用户线程数量可能很大，为了节省开销，不可能设置过多的LWP，而把这些LWP做成一个缓冲池，称为“线程池”。用户进程中的任一用户线程都可以连接到LWP池中的任何一个LWP上，为使每一用户级线程都利用LWP与内核通信，可以使多个用户级线程多路复用一个LWP，但只有当前连接到LWP上的线程才能与内核通信，其余进程或者阻塞，或者等待LWP。而每一个LWP都要连接到一个内核级线程上，这样，通过LWP可把用户级线程与内核线程连接起来，用户线程可通过LWP来访问内核，但内核所看到的总是多个LWP而看不到用户级线程，亦即，由LWP实现了内核与用户级线程之间的隔离，从而使用户级线程与内核无关。如下图所示。</p><p><img src="source/images/操作系统1：进程控制与描述/1008396-20170521154622041-286899160.png" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统0：引论</title>
      <link href="/2022/10/27/cao-zuo-xi-tong-0-yin-lun/"/>
      <url>/2022/10/27/cao-zuo-xi-tong-0-yin-lun/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章-操作系统引论"><a href="#第一章-操作系统引论" class="headerlink" title="第一章 操作系统引论"></a>第一章 操作系统引论</h1><blockquote><p>操作系统（Operating System，OS）是配置在计算机硬件中的第一层软件，是对硬件系统的首次扩充。其主要作用是管理系统资源，提高系统资源的利用率和吞吐量，并为用户和应用程序提供一个简单的接口，便于用户使用。</p></blockquote><h4 id="1-1-操作系统的目标和作用"><a href="#1-1-操作系统的目标和作用" class="headerlink" title="1.1 操作系统的目标和作用"></a>1.1 操作系统的目标和作用</h4><h5 id="1-目标"><a href="#1-目标" class="headerlink" title="1. 目标"></a>1. 目标</h5><ol><li>方便性：用户在没有配置操作系统的裸机上运行程序，就必须使用机器语言书写。如果配置了操作系统，用户可以使用编译命令将用户采用高级语言写的程序翻译成机器代码，极大的方便了用户。</li><li>有效性：一、提高了系统资源的利用率；二、提高了系统的吞吐量。</li><li>可扩充性：OS结构由最初的无结构发展成模块化结构，进而发展成层次化结构，近年来已广泛采用微内核结构。微内核结构能够方便地增添新的功能和模块，以及对原有功能和模块进行修改，具有良好的可扩充性。</li><li>开放性：所谓开放性，是指系统能够遵循世界标准规范，特别是遵循开放系统互连OSI国际标准。事实上，凡是遵循国际标准所开发的硬件和软件都能够彼此兼容，方便的实现互联。</li></ol><h5 id="2-作用"><a href="#2-作用" class="headerlink" title="2. 作用"></a>2. 作用</h5><ol><li><p><strong>OS作为用户与计算机硬件系统之间的接口</strong>：用户可以通过命令方式、系统调用方式和图标—窗口方式来实现与操作系统的通信，并取得它的服务。</p><p><img src="source/images/操作系统0：引论/1774310-20210730035401499-1072150777.png" alt="img" style="zoom:67%;"></p></li><li><p><strong>OS作为计算机系统资源的管理者</strong>：计算机系统含有多种硬件和软件资源，可归纳为：处理机、存储器、I/O设备和文件（程序和数据）。相应地，操作系统的主要功能也正是对这四类资源进行有效的管理。</p><p>处理机管理是用于分配和控制处理机；存储器管理主要负责内存分配与回收；I/O设备管理负责I/O设备的分配（回收）与操纵；文件管理是用于实现对文件的存取、共享和保护。</p><p>当对系统中的共享资源发生竞争和冲突时，操作系统必须对使用资源的请求进行授权，协调共享资源的使用。</p></li><li><p><strong>OS系统实现了对计算机资源的抽象</strong>：对于一台完全没有软件的计算机系统（即裸机），由于它对用户提供的仅是硬件物理接口，因此用户必须对物理接口的实现细节有充分的了解，增加了计算机推广的难度。</p><p>为了方便用户使用I/O设备，人们在裸机上覆盖了一层I/O管理软件，由它来实现对I/O设备的操作细节，并向上将I/O设备抽象为一组数据结构以及一组I/O操作命令，如read和write这样的命令，这样用户即可利用这些数据结构和操作命令来进行数据输入和输出，而无需关心I/O是如何具体实现的。</p><p>在裸机上铺设的I/O软件隐藏了I/O设备的具体细节，向上提供了一组抽象的I/O设备；I/O设备管理软件实现了对计算机硬件操作的第一个层次的抽象。同理，文件管理软件实现了对硬件资源操作的第二个层次的抽象。</p><p>依此类推，OS是铺设在计算机硬件上多层软件的集合，它们不仅增强了系统的功能，还隐藏了对硬件操作的具体细节，实现了对计算机硬件操作的多个层次的抽象模型。用户可以使用抽象模型提供的接口使用计算机，而无需关心物理接口的实现细节。</p></li></ol><h4 id="1-2-操作系统的发展过程"><a href="#1-2-操作系统的发展过程" class="headerlink" title="1.2 操作系统的发展过程"></a>1.2 操作系统的发展过程</h4><h5 id="1-未配置操作系统的计算机系统"><a href="#1-未配置操作系统的计算机系统" class="headerlink" title="1. 未配置操作系统的计算机系统"></a>1. 未配置操作系统的计算机系统</h5><ol><li><p>人工操作方式：用户独占全机；CPU等待人工操作；人机矛盾。</p></li><li><p>脱机输入/输出方式（Off-Line I/O）：脱机I/O技术，事先将装有用户程序和数据的纸带装入纸带输入机，在一台外围机的控制下，把纸带上的数据输入到磁带上，当CPU需要这些数据时，再从磁带上高速地调入内存。脱机I/O方式的优点：减少了CPU的空闲时间；提高了I/O速度。</p><p><img src="source/images/操作系统0：引论/1774310-20210730215118715-1421467413-16614914790776.png" alt="img" style="zoom:67%;"></p></li></ol><h5 id="2-单道批处理系统（Simple-Batch-Processing-System）"><a href="#2-单道批处理系统（Simple-Batch-Processing-System）" class="headerlink" title="2. 单道批处理系统（Simple Batch Processing System）"></a>2. 单道批处理系统（Simple Batch Processing System）</h5><p>为充分提高计算机系统的利用率，应尽量保持系统的连续运行，即在处理完一个作业后，紧接着处理下一个作业，以减少机器的空闲等待时间。</p><p>为了实现对作业的连续处理，需要先把一批作业以脱机方式输入到磁带上，并在系统中配上监督程序（Monitor），在它的控制下，使这批作业能够一个接一个地连续处理。</p><p>虽然系统对作业地处理是成批进行的，但在内存中始终只保持一道作业，故称为单道批处理系统。单道批处理系统是在解决人机矛盾和CPU与I/O设备速度不匹配矛盾的过程中形成的。换言之，批处理系统旨在提高系统资源的利用率和系统的吞吐量。</p><p>单道批处理系统的缺点：系统中的资源得不到充分的利用。这是因为在内存中仅有一道程序，每次该程序在运行中发出I/O请求后，CPU便处于等待状态，必须在其I/O结束后才能继续运行。又因I/O设备的低速性，更使CPU的利用率显著降低。</p><p><img src="source/images/操作系统0：引论/1774310-20210730215827806-991523722.png" alt="img" style="zoom: 80%;"></p><h5 id="3-多道批处理系统（Multiprogrammed-Batch-Processing-System）"><a href="#3-多道批处理系统（Multiprogrammed-Batch-Processing-System）" class="headerlink" title="3. 多道批处理系统（Multiprogrammed Batch Processing System）"></a>3. 多道批处理系统（Multiprogrammed Batch Processing System）</h5><p>为进一步提高系统资源的利用率和系统吞吐量，在20世纪60年代中期引入了多道程序设计技术，由此形成了多道批处理系统。在多道批处理系统中，用户所提交的作业先存放在外存上，并排形成一个队列，称为“后备队列”。然后由作业调度程序按一定的算法，从后备队列中选择若干个作业调入内存，使它们共享CPU和系统中的各种资源。</p><p><img src="source/images/操作系统0：引论/1774310-20210730220456830-48629214.png" alt="img" style="zoom: 67%;"></p><p>由于同时在内存中装有若干道程序，这样便可以在运行一个程序时，利用其因I/O操作而暂停执行时的CPU空档时间再调度另一道程序运行。如此使多道程序交替运行，这样便可以保持CPU处于忙碌状态。</p><p>多道批处理系统的优缺点：</p><ol><li>资源利用率高：引入多道批处理能使多道程序交替运行，以保持CPU处于忙碌状态；在内存中装入多道程序可以提高内存的利用率；此外还可以提高I/O设备的利用率。</li><li>系统吞吐量大：CPU和其它资源保持忙碌状态；仅当作业完成时或运行不下去时才进行切换，系统开销小。</li><li>平均周转时间长：由于作业要排队依次进行处理，因而作业的周转时间比较长。</li><li>无交互能力：用户一旦把作业提交给系统，直至作业完成，用户都不能与自己的作业进行交互，修改和调试程序极不方便。</li></ol><p>多道批处理系统需要解决的问题：</p><ol><li>处理机争用问题；</li><li>内存分配和保护问题；</li><li>I/O设备分配问题；</li><li>文件的组织和管理问题；</li><li>作业管理问题；</li><li>用户与系统的接口问题。</li></ol><p>为此，应在计算机中增加一组软件，用以对以上问题进行妥善、有效的处理。这组软件应包括：能有效地组织和管理四大资源的软件、合理地对各类作业进行调度和控制它们运行的软件，以及方便用户使用计算机的软件。正是这样一组软件构成了操作系统。</p><p>据此，我们可以把操作系统定义为：</p><blockquote><p>操作系统是一组能有效地组织和管理计算机硬件和软件资源，合理地对各类作业进行调度，以及方便用户使用的程序的集合。</p></blockquote><h5 id="4-分时操作系统（Time-Sharing-System）"><a href="#4-分时操作系统（Time-Sharing-System）" class="headerlink" title="4. 分时操作系统（Time Sharing System）"></a>4. 分时操作系统（Time Sharing System）</h5><p>如果说推动多道批处理系统形成和发展的主要动力是提高资源利用率和系统吞吐量，那么推动分时系统形成和发展的主要动力则是为了满足人们对人机交互的需求。用户的需求主要表现在：</p><ol><li>人机交互：用户希望能像早期使用计算机时一样，独占全机并对它进行直接控制，以便能方便地对程序中的错误进行修改。</li><li>共享主机：一台计算机同时供多个用户共享使用时，每人都希望能像独占时一样，不仅可以随时与计算机进行交互，而且还不会感觉到其他用户存在。</li></ol><p>由上述不难得知：</p><blockquote><p>分时系统是指，在一台主机上连接了多个配有显示器和键盘的终端并由此所组成的系统，该系统允许多个用户同时通过自己的终端，以交互方式使用计算机，共享主机中的资源。</p></blockquote><p>在多道批处理系统中，用户无法与自己的作业交互的主要原因是：作业都先驻留在外存上，即使之后被调入内存，也要经过较长的时间的等待后方能运行。因此用户无法与自己的作业进行交互。</p><p>为了实现人机交互，必须解决的关键问题是：如何使用户能与自己的作业进行交互。为此，系统首先必须能提供多个终端，同时给多个用户使用；其次，当用户在自己的终端上键入命令时，系统应能及时接收，并及时处理该命令，再将结果返还给用户；此后，用户可以根据系统返回的响应情况，再继续键入下一条命令，此即人机交互。</p><p>亦即，允许有多个用户同时通过自己的键盘键入命令，系统也应能全部接收并及时处理。</p><ol><li><p>及时接收</p><p>要做到及时接收多个用户键入的命令或数据，只需在系统中配置一个多路卡即可。多路卡的作用是实现分时多路复用，即主机以很快的速度扫描各终端，在每个终端处停留很短的时间，如30ms，用于接收从终端发来的数据。因此在很短的时间内就能完成对多个终端的扫描，即主机能用很短的时间分时接收各用户从终端上输入的数据一次。</p><p>此外，为了能使从终端上输入的数据被依次逐条地进行处理，还需要为每个终端配置一个缓冲区，用来暂存用户输入的命令或数据。</p></li><li><p>及时处理</p><p>人机交互的关键在于，用户键入命令后，能对自己的作业及其运行及时地实施控制，或进行修改。因此，各个用户的作业都必须驻留在内存中，并能频繁地获得处理机运行。</p><p>由此可见，为实现人机交互，必须彻底地改变原来批处理系统的运行方式，转而采用新的处理方式：</p><ul><li>作业直接进入内存。</li><li>采用轮转运行方式。</li></ul><p>如果一个作业独占CPU连续运行，那么其他的作业就没有机会被调度运行。为避免一个作业长期独占处理机，引入了时间片的概念。一个时间片，就是一段很短的时间。系统规定一个作业每次只能运行一个时间片，然后就暂停该作业的运行，并立即调度下一个作业运行。如果在不长的时间内能使所有的作业都执行一个时间片的时间，便可以使每个用户都能及时地与自己的作业进行交互，从而可使用户的请求得到及时响应。</p></li></ol><p>分时系统的特征：</p><ol><li>多路性：系统允许将多个终端同时连接到一台主机上并按分时原则为每个用户服务。</li><li>独立性：每个用户在自己的终端上进行操作，彼此之间互不干扰。</li><li>及时性：用户的请求能在很短的时间内获得响应。</li><li>交互性：用户可通过终端与系统进行广泛的人机对话。</li></ol><h5 id="5-实时操作系统"><a href="#5-实时操作系统" class="headerlink" title="5. 实时操作系统"></a>5. 实时操作系统</h5><p>实时计算：系统的正确性，不仅由计算的逻辑结果来确定，而且还取决于产生结果的时间。事实上实时系统最主要的特征，是将时间作为关键参数，它必须对所接收到的某些信号做出“及时”或“实时”的反应。</p><p>由此得知：</p><blockquote><p>实时系统是指系统能够及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。</p></blockquote><p>实时系统的类型：工业（武器）控制系统、信息查询系统、多媒体系统、嵌入式系统。</p><p>实时任务的类型：周期性实时任务和非周期性实时任务；硬实时任务和软实时任务。</p><p>实时系统与分时系统特征的比较：</p><ol><li>多路性：实时系统与分时系统都按分时原则为多个终端用户服务；</li><li>独立性：各任务彼此独立，互不干扰；</li><li>及时性：分时系统为实现人机交互必须具有及时性，而实时系统为完成实时任务，对及时性要求更高；</li><li>交互性：分时系统为完成人机交互对其交互性要求更高；</li><li>可靠性：分时系统要求可靠，实时系统要求高度可靠，任何差错都会产生严重的后果。</li></ol><h5 id="6-微机操作系统的发展"><a href="#6-微机操作系统的发展" class="headerlink" title="6. 微机操作系统的发展"></a>6. 微机操作系统的发展</h5><p>随着超大规模集成电路和计算机体系结构的发展，以及应用需求的不断提高，操作系统仍在继续发展。由此形成了微机操作系统、网络操作系统等。</p><p>配置在微型机上的操作系统称为微机操作系统，按运行方式分为：</p><ol><li><p>单用户单任务操作系统：CP/M，MS-DOS</p><p>只允许一个用户上机，且只允许用户程序作为一个任务运行。</p></li><li><p>单用户多任务操作系统：Windows</p><p>只允许一个用户上机，但允许用户把程序分为若干个任务，使它们并发执行，从而有效地改善了系统性能。</p></li><li><p>多用户多任务操作系统：UNIX OS，Solaris OS，Linux OS</p><p>允许多个用户通过各自的终端，使用同一台机器，共享主机系统中的各种资源，而每个用户程序又可以进一步分为几个任务，使它们能并发执行，从而可进一步提高系统资源利用率和系统吞吐量。</p></li></ol><h4 id="1-3-操作系统的基本特性"><a href="#1-3-操作系统的基本特性" class="headerlink" title="1.3 操作系统的基本特性"></a>1.3 操作系统的基本特性</h4><p>多道批处理系统具有较高的资源利用率和系统吞吐量；分时系统能获得及时响应，具有较强的人机交互性；实时系统具有实时特征；这三种基本操作系统除了具有各自的特征之外，还共同具有并发、共享、虚拟和异步四个基本特征。</p><h5 id="1-并发（Concurrence）"><a href="#1-并发（Concurrence）" class="headerlink" title="1. 并发（Concurrence）"></a>1. 并发（Concurrence）</h5><ol><li><p>并行与并发</p><p><strong>并行性是指多个事件在同一时刻发生；而并发性是指多个事件在同一时间段内发生。</strong></p><p>在多道程序环境下，并发性是指在一段时间内宏观上有多个程序在同时运行，但在单处理机系统中，每个时刻却仅能有一道程序执行，故微观上这些程序只能是分时交替执行。</p><p>倘若在计算机系统中有多个处理机，这些可以并发执行的程序便可被分配到多个处理机上，实现并行执行。</p></li><li><p>引入进程</p><p>在一个未引入进程的系统中，在属于同一个应用程序的计算程序和I/O程序之间只能顺序执行，但在为计算程序和I/O程序分别建立一个进程（Process）后，这两个程序便可以并发执行。</p><p>所谓进程，是指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆栈等组成的，是一个能独立运行的活动实体。多个进程之间可以并发执行和交换信息。</p></li></ol><h5 id="2-共享（Sharing）"><a href="#2-共享（Sharing）" class="headerlink" title="2. 共享（Sharing）"></a>2. 共享（Sharing）</h5><p>在OS环境下的资源共享也称为资源复用，是指系统中的资源可供内存中多个并发执行的进程共同使用。</p><p>为避免多道程序对共享资源的抢夺，系统必须对资源共享进行妥善管理，实现资源共享的两种方式：</p><ol><li><p><strong>互斥共享方式</strong></p><p>把在一段时间内只允许一个进程访问的资源称为临界资源（或独占资源），把在一段时间内只允许一个进程访问临界资源的资源共享称为互斥共享方式。</p></li><li><p><strong>同时访问方式</strong></p><p>系统中还有另一类资源，允许在一段时间内由多个进程“同时”对它们进行访问。这里所谓的“同时”是宏观上的，微观上对这些资源的访问是分时交替进行的。</p></li></ol><p>并发和共享是多用户（多任务）操作系统的两个最基本的特征。它们又是互为存在的条件。即一方面资源共享是以进程的并发执行为条件的，若系统不允许并发执行也就不存在资源共享问题；另一方面，若系统不能对资源共享实施有效管理，以协调好诸进程对共享资源的访问，也必然会影响到诸进程间并发执行的程度，甚至根本无法并发执行。</p><h5 id="3-虚拟（Virtual）"><a href="#3-虚拟（Virtual）" class="headerlink" title="3. 虚拟（Virtual）"></a>3. 虚拟（Virtual）</h5><p>在操作系统中，把通过某种技术将一个物理实体变为若干个逻辑上的对应物的功能称为“虚拟”。</p><p>在OS中利用时分复用技术和空分复用技术来实现虚拟。</p><ol><li><p><strong>时分复用技术</strong>（Time Division Multiplexing,TMD）</p><p>利用处理机的空闲时间运行其它程序，提高了处理机的效率。</p><p><strong>虚拟处理机技术</strong>：利用多道程序设计技术，为每道程序建立至少一个进程，让多道程序并发执行。此时虽然系统中只有一台处理机，但通过分时复用的方法，能实现同时（宏观上）为多个用户服务，使每个终端都认为是有一个处理机专门在为它服务。亦即，利用多道程序设计技术，可将一台物理上的处理机虚拟为多台逻辑上的处理机，在每台逻辑处理机上运行一道程序。我们将用户感觉到的处理机称为虚拟处理机。</p><p><strong>虚拟设备技术</strong>：同理，我们也可以通过分时复用的方法，将一台物理I/O设备虚拟为多台逻辑上的I/O设备，并允许每个用户占用一台逻辑上的I/O设备。宏观上实现为多个用户服务，微观上仍是分时交替使用。</p></li><li><p><strong>空分复用技术</strong>（Space Division Multiplexing,SMD）</p><p>利用存储器的空闲空间分区域存放和运行其它的多道程序，以此来提高内存的利用率。</p><p>20世纪初，电信行业就已使用频分复用技术来提高信道的利用率。频分复用技术，是指将一个频率范围比较宽的信道划分成多个频率范围比较窄的信道，称为频带，其中的任何一条频带都仅供一对用户通话。</p><p>再后来在计算机中也把空分复用技术用于对存储空间的管理，用以提高存储空间的利用率。但是单纯的空分复用技术只能提高内存的利用率，并不能实现在逻辑上扩大存储器容量的功能，还必须引入虚拟存储技术才能达到该目的。</p><p><strong>虚拟存储技术</strong>在本质上是实现内存的分时复用，即它可以通过分时复用内存的方式，使一道程序仅在远小于它的内存空间中运行。实质上就是每次只把用户程序的一部分调入内存运行，运行完成后将该部分换出，再换入另一部分到内存中运行，通过这样的置换功能，便实现了用户程序的各个部分分时地进入内存运行。</p></li></ol><p>应当着重指出：虚拟的实现，如果是采用分时复用的方法，即对某一物理设备进行分时使用，设N是某物理设备所对应的虚拟的逻辑设备数，则每台虚拟设备的平均速度必然等于或低于物理设备速度的1/N。类似地，如果是利用空分复用地方法来实现虚拟，此时一台虚拟设备平均占用的空间也必然等于或低于物理设备所拥有空间的1/N。</p><h5 id="4-异步（Asynchronism）"><a href="#4-异步（Asynchronism）" class="headerlink" title="4. 异步（Asynchronism）"></a>4. 异步（Asynchronism）</h5><p>由于资源等因素的限制，使进程的执行通常都不可能“一气呵成”，而是以“停停走走”的方式运行。</p><p>进程总是以人们不可预知的速度向前推进的，此即进程的异步性。</p><h4 id="1-4-操作系统的主要功能"><a href="#1-4-操作系统的主要功能" class="headerlink" title="1.4 操作系统的主要功能"></a>1.4 操作系统的主要功能</h4><p>引入操作系统的主要目的是，为多道程序的运行提供良好的运行环境，以保证多道程序能有条不紊地、高效地运行，并能最大程度地提高系统中各种资源的利用率，方便用户的使用。</p><h5 id="1-处理机管理功能"><a href="#1-处理机管理功能" class="headerlink" title="1. 处理机管理功能"></a>1. 处理机管理功能</h5><p>在多道程序系统中，处理机的分配和运行都是以进程为基本单位的，因而对处理机的管理可归结于对进程的管理。处理机管理的主要功能有：创建和撤销进程，对诸进程的运行进行协调，实现进程之间的信息交换，以及按照一定的算法把处理机分配给进程。</p><ol><li><p><strong>进程控制</strong>：</p><p>为作业创建进程、撤销已结束的进程，以及控制进程在运行过程中的状态转换。</p></li><li><p><strong>进程同步</strong>：</p><p>一、进程互斥方式，诸进程在对临界资源进行访问时应使用互斥方式；</p><p>二、进程同步方式，在相互合作去完成共同任务的诸进程间，由同步机构对它们的执行次序加以协调。</p></li><li><p><strong>进程通信</strong>：</p><p>通常采用直接通信方式，即由源进程利用发送命令直接将消息（message）挂到目标进程的消息队列上，之后由目标进程利用接收命令从其消息队列中取出消息。</p></li><li><p><strong>调度</strong>：包括作业调度和进程调度。</p><p>作业调度：作业调度的基本任务是从后备队列中按照一定的算法选择出若干个作业，为它们分配运行所需的资源，在将这些作业调入内存后，分别为它们建立进程，使它们都成为可能获得处理机的就绪程序，并将它们插入就绪队列中。</p><p>进程调度：进程调度的任务是从进程的就绪队列中按照一定的算法选出一个进程，将处理机分配给它，并为它设置运行现场，使其投入执行。</p></li></ol><h5 id="2-存储器管理功能"><a href="#2-存储器管理功能" class="headerlink" title="2. 存储器管理功能"></a>2. 存储器管理功能</h5><p>存储器管理的主要任务，是为多道程序的运行提供良好的环境，提高存储器的利用率，方便用户使用，并能从逻辑上扩充内存。</p><ol><li><p><strong>内存分配</strong></p><p>为每道程序分配内存空间；提高存储器的利用率，尽量减少不可用的内存空间（碎片）；允许动态分配内存；</p><p>OS系统在分配内存时，可采取静态和动态两种方式。</p></li><li><p><strong>内存保护</strong></p><p>一、确保每道用户程序都仅在自己的内存空间内运行，彼此互不干扰；</p><p>二、绝不允许用户程序访问操作系统的程序和数据，也不允许用户程序转移到其它非共享用户程序中去执行。</p></li><li><p><strong>地址映射</strong></p><p>能够将地址空间中的逻辑地址转换为内存空间中与之对应的物理地址。</p></li><li><p><strong>内存扩充</strong></p><p>借助虚拟存储技术，从逻辑上扩充内存容量。内存扩充机制：</p><p>一、请求调入功能，系统允许在仅装入部分用户程序和数据的情况下，便能启动该程序运行。在程序运行过程中，若发现要继续运行时所需的程序和数据尚未装入内存，可向OS发出请求，由OS从磁盘中将所需部分调入内存，以便继续运行。</p><p>二、置换功能，系统能将内存中的一部分暂时不用的程序和数据调换至硬盘上，以腾出内存空间，然后将所需调入的部分装入内存。</p></li></ol><h5 id="3-设备管理功能"><a href="#3-设备管理功能" class="headerlink" title="3. 设备管理功能"></a>3. 设备管理功能</h5><p>设备管理的主要任务：（1）完成用户进程所提出的I/O请求，为用户进程分配所需的I/O设备，并完成指定的I/O操作；（2）提高CPU和I/O设备的利用率，提高I/O速度，方便用户使用I/O设备。</p><ol><li><p><strong>缓冲管理</strong></p><p>在I/O设备和CPU之间引入缓冲，可有效地缓解CPU和I/O设备速度不匹配的矛盾，提高CPU之间的利用率，进而提高系统的吞吐量。</p></li><li><p><strong>设备分配</strong></p><p>根据用户进程的I/O请求、系统现有资源情况以及按照某种设备分配策略，为之分配所需的设备。在设备使用完之后，应立即由系统回收。</p></li><li><p><strong>设备处理</strong></p><p>设备处理程序又称设备驱动程序。其基本任务是实现CPU和设备控制器之间的通信。即由CPU向设备控制器发出I/O命令，要求它完成指定的I/O操作；反之，由CPU接收从设备控制器发来的中断请求，并给予迅速的响应和相应地处理。</p></li></ol><h5 id="4-文件管理功能"><a href="#4-文件管理功能" class="headerlink" title="4. 文件管理功能"></a>4. 文件管理功能</h5><p>文件管理的主要任务是：对用户文件以及系统文件进行管理以方便用户使用，并保证文件的安全性。</p><ol><li>文件存储空间的管理</li><li>目录管理</li><li>文件读/写管理和保护</li></ol><h5 id="5-操作系统与用户之间的接口"><a href="#5-操作系统与用户之间的接口" class="headerlink" title="5. 操作系统与用户之间的接口"></a>5. 操作系统与用户之间的接口</h5><ol><li>用户接口：联机用户接口、脱机用户接口、图形用户接口</li><li>程序接口：程序接口是为用户程序在执行中访问系统资源而设置的，是用户程序取得操作系统服务的唯一途径。它是由一组系统调用组成的，每一个系统调用都是一个能完成特定功能的子程序。</li></ol><h5 id="6-现代操作系统的新功能"><a href="#6-现代操作系统的新功能" class="headerlink" title="6. 现代操作系统的新功能"></a>6. 现代操作系统的新功能</h5><ol><li>系统安全</li><li>网络的功能和服务</li><li>支持多媒体</li></ol><h4 id="1-5-OS结构设计"><a href="#1-5-OS结构设计" class="headerlink" title="1.5 OS结构设计"></a>1.5 OS结构设计</h4><h5 id="1-传统操作系统结构"><a href="#1-传统操作系统结构" class="headerlink" title="1. 传统操作系统结构"></a>1. 传统操作系统结构</h5><ol><li><p>无结构操作系统</p></li><li><p>模块化结构OS</p><p>模块化程序设计技术基于“分解”和“模块化”的原则来控制大型软件的复杂度。OS按其功能精心地划分为若干个具有一定独立性和大小的模块，每个模块具有某方面的管理功能，并仔细地规定好各模块间的接口，使各模块间能通过接口实现交互。然后再将模块进一步划分为若干个具有一定功能的子模块，同样也规定好其接口。</p><p>我们把这种设计方法称为模块—接口法，由此构成的操作系统就是具有模块化结构的操作系统。</p><p>在模块—接口法中，关键问题是模块的划分和规定好模块之间的接口。</p><p>衡量模块的独立性有以下两个标准：</p><ul><li>内聚性：指模块内部各部分间联系的紧密程度。</li><li>耦合度：指模块间相互联系和相互影响的程度。</li></ul><p>模块—接口法的优缺点：</p><p>优点：较之无结构OS提高了OS设计的正确性、可理解性和可维护性；增强OS的适应性；加速OS的开发过程。</p><p>缺点：对各模块接口规定很难满足实际需求；各模块的设计是无序的，可靠性不足。</p></li><li><p>分层式结构OS</p><p>为了将模块—接口法中“决定顺序”的无序性变为有序性，引入了有序分层法，有序分层法的设计任务是：在目标系统与裸机系统之间自底向上铺设若干层软件，使目标系统最终能在铺设了若干层软件之间的宿主系统上运行。</p><p>自底向上的分层设计的基本原则是：每一步的设计都建立在可靠的基础之上。为此规定，每一层仅能使用其底层所提供的功能或服务，这样可以使系统的调试和验证都变得更加容易。在对某一底层软件经过精心设计和几乎是穷尽无疑的测试后，可以认为其是正确可靠的，而与其它所有的高层软件无关。如此一层一层地自底向上增添软件层，每一层都实现若干功能，最后总能构成一个满足需要的OS。</p><p>有序分层法所构成的操作系统，将一个操作系统分为若干层次，每层又由若干个功能模块组成，各层之间只存在单向的依赖关系，即高层仅依赖于紧邻它的底层。</p><p>分层结构的优缺点：</p><p>优点：易保证系统的正确性；易扩充和易维护。</p><p>缺点：OS每执行一个功能，都要自上而下地穿越多个层次，这无疑会增加系统地通信开销，降低系统效率。</p></li></ol><h5 id="2-C-S模式与P2P模式简介"><a href="#2-C-S模式与P2P模式简介" class="headerlink" title="2. C/S模式与P2P模式简介"></a>2. C/S模式与P2P模式简介</h5><p>客户/服务器（Client/Server）模式，简称为C/S模式。</p><blockquote><p>客户/服务器是指通信中所涉及的两个应用进程，客户/服务器方式所描述的是进程之间的服务和被服务的关系。</p><p>客户是服务请求方，服务器是服务提供方。服务器总是处于运行状态，并等待客户的服务请求，服务器具有固定端口号，而运行服务器的主机具有固定的IP地址。</p></blockquote><p>与C/S模式对应的是P2P模式，即对等模式（peer to peer）。</p><blockquote><p>在p2p方式中，没有固定的服务器请求者和服务提供者，分布在网络边缘各端系统中的应用进程是对等的，被称为对等方，对等方相互之间直接通信，每个对等方既是服务的请求者，也是服务的提供者.</p></blockquote><p>C/S模式的优缺点：</p><p>优点：数据分布式处理和存储；便于集中管理；灵活性和可扩充性高；易于改编应用软件。</p><p>缺点：存在不可靠性和瓶颈问题，一旦服务器故障将导致整个网络瘫痪。</p><h5 id="3-面向对象"><a href="#3-面向对象" class="headerlink" title="3. 面向对象"></a>3. 面向对象</h5><p>面向对象是一种对现实世界理解和抽象的方法。</p><h5 id="4-微内核OS结构"><a href="#4-微内核OS结构" class="headerlink" title="4. 微内核OS结构"></a>4. 微内核OS结构</h5><p>在进行现代操作系统结构设计时，大多采用基于客户/服务器模式的微内核结构，将操作系统划分为两大部分：微内核和多个服务器。微内核OS的设计思想：</p><ol><li><p>足够小的内核</p><p>微内核是指精心设计的、能实现现代操作系统最基本核心功能的小型内核。微内核并非是完整的OS，而只是将操作系统最基本、最核心的部分放入内核中，这些操作系统最基本的部分只是为构建通用OS提供一个重要基础，这样就可以确保把操作系统内核做得很小。</p></li><li><p>基于客户/服务器模式</p><p>将操作系统最基本的部分放入内核中，而把操作系统中绝大部分功能都放在微内核外面的一组服务器（进程）中实现，如进程服务器、虚拟存储服务器和I/O设备管理服务器等，都是被作为进程来实现的，运行在用户态，客户与服务器之间借助微内核提供的消息传递机制来实现信息交互。</p><p><img src="source/images/操作系统0：引论/1774310-20210730211335521-129651715.png" alt="img" style="zoom:67%;"></p></li><li><p>应用“机制与策略分离”原理</p><p>所谓机制，是指实现某一功能的具体执行机构。而策略，则是在机制的基础上借助于某些参数和算法来实现该功能的优化，或达到不同的功能目标。在微内核OS中，使用机制与策略相分离的原理，仅将机制放在OS的微内核中，从而将内核做得更小。</p></li><li><p>采用面向对象技术</p><p>我们不仅可以通过结构设计来分解操作系统的复杂度，还可以基于面向对象技术中的抽象和隐蔽原则控制系统的复杂性，再进一步利用对象、封装和继承等概念来确保操作系统的正确性、可靠性、易修改性和易扩展性，并提高操作系统的设计速度。</p></li></ol><p>微内核的基本功能：</p><ol><li><p>进程（线程）管理</p><p>微内核中包括进程优先级队列、进程通信、进程切换、线程调度以及多处理机之间的同步等功能。</p></li><li><p>低级存储器管理</p><p>在微内核中，只配置最基本的低级存储器管理机制，如用于实现将用户空间的逻辑地址映射为内存空间的物理地址的页表机制和地址变换机制，这一部分是依赖硬件的，因此放入微内核。</p></li><li><p>中断和陷入处理</p><p>将于硬件紧密相关的一小部分放入微内核中处理，如捕获中断和陷入事件，并进行相应地前期处理，如进行中断现场保护，识别中断和陷入的类型，并将有关消息发送给相应服务器。</p><p>在微内核OS中，将进程管理、存储器管理以及I/O管理这些功能一分为二，属于机制的很小一部分放入微内核中另外绝大部分在微内核外的各种服务器中来实现。</p></li></ol><p>微内核操作系统的优点：</p><ol><li>提高了系统的可扩展性。</li><li>增强了系统的可靠性。</li><li>可移植性强。</li><li>提供了对分布式系统的支持。</li><li>融入了面向对象技术。</li></ol><p>在微内核操作系统中，由于采用了非常小的内核，客户/服务器模式和消息传递机制虽然给微内核操作系统带来了许多优点，但由此也使微内核OS存在潜在缺点，其中最主要的是，较之早期的操作系统，微内核OS的运行效率有所下降。</p><p>效率降低的最主要原因是，在完成一次客户对操作系统提出的服务请求时，需要利用消息实现多次交互和进行用户态/内核态与上下文的多次切换。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计组第3章-存储系统</title>
      <link href="/2022/07/27/ji-zu-di-3-zhang-cun-chu-xi-tong/"/>
      <url>/2022/07/27/ji-zu-di-3-zhang-cun-chu-xi-tong/</url>
      
        <content type="html"><![CDATA[<h3 id="第三章-存储系统"><a href="#第三章-存储系统" class="headerlink" title="第三章 存储系统"></a>第三章 存储系统</h3><h4 id="考纲内容"><a href="#考纲内容" class="headerlink" title="考纲内容"></a>考纲内容</h4><blockquote><p>（一）存储器的分类</p><p>（二）层次化存储器的基本结构</p><p>（三）半导体随机存储器</p><p>​        SRAM、DRAM、Flash存储器</p><p>（四）主存储器</p><p>​        DRAM芯片与内存条、多模块存储器、主存和CPU之间的连接</p><p>（五）外部存储器</p><p>​        磁盘存储器、固态硬盘（SSD）</p><p>（六）高速缓冲存储器（Cache）</p><p>​        Cache的基本原理；Cache和主存之间的映射方式</p><p>​        Cache中主存块的替换算法；Cache写策略</p><p>（七）虚拟存储器</p><p>​        虚拟存储器的基本概念</p><p>​        页式虚拟存储器：基本原理、页表、地址转换、TLB（快表）</p><p>​        段式虚拟存储器的基本原理；段页式虚拟存储器的基本原理</p></blockquote><h4 id="3-1-存储器概述"><a href="#3-1-存储器概述" class="headerlink" title="3.1 存储器概述"></a>3.1 存储器概述</h4><h5 id="1-存储器的层次结构"><a href="#1-存储器的层次结构" class="headerlink" title="1. 存储器的层次结构"></a>1. 存储器的层次结构</h5><p><img src="/images/计组第3章-存储系统/image-20220710162950624.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710163119440.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710163158290.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710164124133.png" alt=""></p><p>实际上，存储器层次结构主要体现在<code>Cache—主存层</code>和<code>主存—辅存层</code>，前者主要解决<strong>CPU和主存速度不匹配的问题</strong>，后者主要解决<strong>存储系统的容量问题</strong>。在存储体系中，Cache、主存能够与CPU直接交换信息，辅存则要通过主存与CPU交换信息。存储器层次结构的主要思想是上一层存储器作为低一层存储器的高速缓存，上一层内容只是下一层经常使用到的内容的副本。</p><h5 id="2-存储器的分类"><a href="#2-存储器的分类" class="headerlink" title="2. 存储器的分类"></a>2. 存储器的分类</h5><ul><li>按存储介质分类：半导体存储器、磁表面存储器、光存储器</li><li>按存取方式分类：随机存取存储器(RAM、ROM)、顺序存取存储器(磁带)、直接存取存储器(磁盘、光盘)</li></ul><p><img src="/images/计组第3章-存储系统/image-20220710165435322.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710165509725.png" alt=""></p><p><strong>顺序存取存储器（SAM）</strong>：磁带、电影胶片</p><p>访问时，读/写部件按顺序查找目标地址，访问时间与数据的存储位置有关。</p><p><strong>直接存取存储器（DAM）</strong>：硬盘</p><p>访问时，读/写部件先粗定位一个小区域，再在该区域内顺序查找。</p><h5 id="3-存储器的性能指标"><a href="#3-存储器的性能指标" class="headerlink" title="3. 存储器的性能指标"></a>3. 存储器的性能指标</h5><ul><li>存储容量 = 存储字数 × 字长</li><li>单位成本：每位价格 = 总成本/总容量</li><li>存储速度：<strong>数据传输率 = 数据的宽度/存储周期</strong><ul><li>存取时间：存储器收到读写命令到存储器读出/写入信息所需要的时间</li><li>存取周期：<strong>存取周期 = 存取时间 + 恢复期</strong></li><li>主存带宽：又称为数据传输率</li></ul></li></ul><p><img src="/images/计组第3章-存储系统/image-20220711152647054.png" alt=""></p><h4 id="3-2-主存储器"><a href="#3-2-主存储器" class="headerlink" title="3.2 主存储器"></a>3.2 主存储器</h4><h5 id="1-SRAM芯片和DRAM芯片"><a href="#1-SRAM芯片和DRAM芯片" class="headerlink" title="1. SRAM芯片和DRAM芯片"></a>1. SRAM芯片和DRAM芯片</h5><h6 id="1-SRAM的工作原理"><a href="#1-SRAM的工作原理" class="headerlink" title="1. SRAM的工作原理"></a>1. SRAM的工作原理</h6><p><img src="/images/计组第3章-存储系统/image-20220710170638568.png" alt=""></p><p>通常把存放一个二进制位的物理器件称为存储元，它是存储器最基本的结构。</p><p><strong>静态随机存储器SRAM的存储元是双稳态触发器（六晶体管MOS），依靠双稳态电路内部交叉反馈电路形成互锁，通过电源对电路的持续供电以存储信息，不需要刷新，为非破坏性读出，不需要重写。</strong></p><p><img src="/images/计组第3章-存储系统/image-20220710171018980.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710171508165.png" alt=""></p><h6 id="2-DRAM的工作原理"><a href="#2-DRAM的工作原理" class="headerlink" title="2. DRAM的工作原理"></a>2. DRAM的工作原理</h6><p><strong>动态随机访问存储器DRAM依靠存储单元中形成的栅极电容来保存信息，不需要持续电源，因此需要定期逐行刷新。</strong>MOS：金属氧化物半导体，加高电平即导通，低电平即阻断。</p><p><img src="/images/计组第3章-存储系统/image-20220710172412606.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710172450820.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710172518487.png" alt=""></p><p><strong>动态存储器的刷新：</strong></p><p><strong>定期向电容补充电荷叫做刷新。</strong>因为动态存储器依靠电容电荷存储信息，没有电源持续供电，电荷会泄露，故需定期向电容补充电荷，才能维持存储信息不变。</p><p><img src="/images/计组第3章-存储系统/image-20220710175156513.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710175305647.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710175332757.png" alt=""></p><h6 id="3-DRAM芯片读写周期"><a href="#3-DRAM芯片读写周期" class="headerlink" title="3. DRAM芯片读写周期"></a>3. DRAM芯片读写周期</h6><p><img src="/images/计组第3章-存储系统/image-20220710184205175.png" alt=""></p><h6 id="4-SRAM与DRAM的比较"><a href="#4-SRAM与DRAM的比较" class="headerlink" title="4. SRAM与DRAM的比较"></a>4. SRAM与DRAM的比较</h6><p><img src="/images/计组第3章-存储系统/image-20220710184607749.png" alt=""></p><h6 id="5-存储器芯片的内部结构"><a href="#5-存储器芯片的内部结构" class="headerlink" title="5. 存储器芯片的内部结构"></a>5. 存储器芯片的内部结构</h6><p><img src="/images/计组第3章-存储系统/image-20220724162255581.png" alt=""></p><ol><li>存储体（存储矩阵 ）。存储体是存储单元的集合，它由行选择线(X)和列选择线(Y)来选择所访问单元，存储体上的相同行、列上的位同时被读出或写入。</li><li>地址译码器：用来将地址转换为译码输出线上的高电平，以便驱动相应的读写电路。</li><li>I/O控制电路：用以控制被选中单元的读出或写入，具有放大信息的作用。</li><li>片选控制信号。</li><li>读/写控制信号。</li></ol><h6 id="6-半导体存储器的逻辑设计"><a href="#6-半导体存储器的逻辑设计" class="headerlink" title="6. 半导体存储器的逻辑设计"></a>6. 半导体存储器的逻辑设计</h6><p><img src="/images/计组第3章-存储系统/image-20220710190056581.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710190134519.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710190200719.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710190229562.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710190301146.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710190355822.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220710190421670.png" alt=""></p><h5 id="2-只读存储器ROM"><a href="#2-只读存储器ROM" class="headerlink" title="2. 只读存储器ROM"></a>2. 只读存储器ROM</h5><p>只读存储器（ROM）有两个显著的优点：</p><ul><li>结构简单，所以位密度比可读写存储器高。</li><li>具有<strong>非易失性</strong>，所以可靠性高。</li></ul><p>ROM的类型：</p><ol><li>掩模式只读存储器MROM：内容由半导体制造厂商按用户的需求在芯片生产过程中直接写入，之后无法改变</li><li>一次可编程只读存储器PROM：可以利用专门的设备写入一次，之后内容无法改变。</li><li>可擦除可编程存储器EPROM：可写入几十次，用紫外线照射擦除。</li><li>电擦除型可编程只读存储器EEPROM：使用高压电实现比特级擦除。</li><li>Flash存储器：即闪存，是一种快速擦写型ROM，典型应用有U盘、SSD固态硬盘等。其主要特点是既可在不加电的情况下长期保存信息，又能在线进行快速擦除与重写。</li><li>固态硬盘SSD：基于闪存，保留了Flash存储器长期保存信息、快速擦除与重写的特性，对比传统硬盘也具有读写速度快、低功耗等特点，缺点是价格较高。</li></ol><h5 id="3-主存储器的基本组成"><a href="#3-主存储器的基本组成" class="headerlink" title="3. 主存储器的基本组成"></a>3. 主存储器的基本组成</h5><p><img src="/images/计组第3章-存储系统/image-20220710191407193.png" alt=""></p><p>指令执行过程中需要访问主存时，CPU首先把被访问单元的地址送到地址寄存器MAR中，然后通过地址线将主存地址送到主存中的地址寄存器，以便地址译码器译码选中相应单元，同时CPU将读写信号通过控制线送到主存的读写控制电路。</p><p>如果是写操作，那么CPU同时将要写的信号送入MDR中，在读写控制电路的控制下，经过数据线将信号写入选中的单元；</p><p>若果是读操作，那么主存读出选中单元的内容送到数据线，然后送到MDR中。</p><p><strong>数据线的宽度与MDR的宽度相同，地址线的宽度与MAR的宽度相同。地址线的位数决定了主存地址空间的最大可寻址范围。</strong></p><h5 id="4-多模块存储器"><a href="#4-多模块存储器" class="headerlink" title="4. 多模块存储器"></a>4. 多模块存储器</h5><p>多模块存储器是一种空间并行技术，利用多个结构完全相同的存储模块并行工作来提高存储器的吞吐率。常用的有单体多字存储器和多体位交叉存储器。</p><blockquote><p>注意：CPU的速度比存储器快，若同时从存储器中取出n条指令，就可以充分利用CPU资源，提高运行速度。多体交叉存储器就是基于这种思想提出的。</p></blockquote><h6 id="1-单体多字存储器"><a href="#1-单体多字存储器" class="headerlink" title="1. 单体多字存储器"></a>1. 单体多字存储器</h6><p>单体多字存储器的特点是存储器中只有一个存储体，每个存储单元存储m个字，总线宽度也为m个字。一次并行读出m个字，地址必须顺序排列并处于同一存储单元。</p><h6 id="2-多体并行存储器"><a href="#2-多体并行存储器" class="headerlink" title="2. 多体并行存储器"></a>2. 多体并行存储器</h6><p>多体并行存储器由多体模块组成。每个模块都有相同的容量和存取速度，各模块都有独立的读写控制电路、地址寄存器和数据寄存器。它们既能并行工作，又能交叉工作。</p><p>多体并行存储器分为高位交叉编址和低位交叉编址。</p><p><strong>高位交叉编址（顺序方式）</strong>：高位地址表示体号，低位地址为体内地址。访问一个连续主存块时总是先在一个模块内访问，等待该模块访问结束才转到下一个模块，各模块不能被并行访问。</p><p><img src="/images/计组第3章-存储系统/image-20220724163124596.png" alt=""></p><p><strong>低位交叉编址（交叉方式）</strong>：低位地址为体号，高位地址为体内地址。每个模块按”模m“编址，模块号=单元地址%m，假定有m个模块，每个模块有k个单元，则$M_{0}=Pm,M_{1}=Pm+1,\cdot\cdot\cdot$,$0=&lt;P&lt;=k+1$。</p><p>低位交叉方式下，总是把高位的体内地址送到由低位地址确定的模块内进行译码，程序连续存放在相邻的模块中，因此称采用此编制方式的存储器为交叉存储器。</p><p><img src="/images/计组第3章-存储系统/image-20220724163237158.png" alt=""></p><p>采用低位交叉编址后，可在不改变每个模块的存取周期的前提下，用流水线的方式并行存取，提高存储器的带宽。</p><p>交叉存取度m = 存取周期T / 总线传送周期r；存储体的模块数必须大于等于m。</p><p>顺序存储器  $t_{1}=m T$</p><p>交叉存储器 $t_{2} = T + (m-1)r$。</p><h5 id="5-本节小结"><a href="#5-本节小结" class="headerlink" title="5. 本节小结"></a>5. 本节小结</h5><ol><li>芯片引脚数 = 地址线数 + 数据线数 + 片选线数 + 读写控制线数</li><li>一根线就是一个二进制位，高电平时为1，低电平时为0</li><li><strong>n根地址线可以表示$2^{n}$个存储单元，故若有$2^{n}$个存储单元，则地址线数 = n</strong></li><li><strong>数据线数 = 存储字长，即1个存储单元的位数</strong></li><li>读写控制线为1或2根，皆有可能，片选线数为1根</li><li>DRAM采用地址引脚复用技术，地址线减半，数据线不变，增加了两根线即行通选和列通选，片选线以行通选代替</li><li>分散刷新延长了存取周期，不存在死时间。</li></ol><h4 id="3-3-主存储器与CPU的连接"><a href="#3-3-主存储器与CPU的连接" class="headerlink" title="3.3 主存储器与CPU的连接"></a>3.3 主存储器与CPU的连接</h4><h5 id="1-连接原理"><a href="#1-连接原理" class="headerlink" title="1. 连接原理"></a>1. 连接原理</h5><p>主存储器通过数据总线、地址总线和控制总线与CPU连接；</p><p>数据总线的位数与工作频率的乘积正比于数据传输率；</p><p>地址总线的位数决定了可寻址的最大内存空间；</p><p>控制总线（读/写）指出总线周期的类型和本次输入/输出操作完成的时刻。</p><h5 id="2-主存容量扩展"><a href="#2-主存容量扩展" class="headerlink" title="2. 主存容量扩展"></a>2. 主存容量扩展</h5><p>由于单个存储芯片的容量是有限的，它在字数或字长方面与实际存储器的需求都有差距，因此需要在字和位两方面进行扩充才能满足实际存储器的容量要求。通常采用位扩展法、字扩展法和字位同时扩展法来扩展主存容量。</p><ol><li><p><strong>位扩展法</strong>：用多个存储器件对字长进行扩充，增加存储字长。位扩展的连接方式是将多个存储芯片的地址端、片选端和读写控制端相应并联，数据端分别引出。</p><blockquote><p>注意：仅采用位扩展时，各芯片连接地址线的方式相同，但连接数据线的方式不同，在某一时刻选中所有的芯片，所以片选信号（CS非）要连接到所有的芯片。</p></blockquote><p><img src="/images/计组第3章-存储系统/image-20220724163553716.png" alt=""></p></li><li><p><strong>字扩展法</strong>：字扩展将芯片的地址线、数据线、读写控制线相应并联，而由片选信号来区分各芯片的地址范围。</p><blockquote><p>注意：仅采用字扩展时，各芯片连接地址线的方式相同，连接数据线的方式也相同，但在某一时刻只需选中部分芯片，所以通过片选信号（CS非）连接到相应的芯片。</p></blockquote><p><img src="/images/计组第3章-存储系统/image-20220724163643199.png" alt=""></p></li><li><p><strong>字位同时扩展法</strong>：同时增加存储字的数量和存储字长。</p><blockquote><p>数据线的连接方式不同，而且片选信号也要连接到相应的芯片。</p></blockquote><p><img src="/images/计组第3章-存储系统/image-20220724163750209.png" alt=""></p></li></ol><h5 id="3-存储容量的地址分配和片选"><a href="#3-存储容量的地址分配和片选" class="headerlink" title="3. 存储容量的地址分配和片选"></a>3. 存储容量的地址分配和片选</h5><p>CPU要实现对存储单元的访问，首先要进行片选，然后进行字选。</p><p>片选信号的产生分为线选法和译码片选法。</p><ol><li><p><strong>线选法</strong>：用除片内寻址外的高位地址线直接分别连接至各个存储芯片的片选端，当某地址线信号为”0“时，就选中与之对应的存储芯片（CS非低电平有效）。这些片选地址每次寻址时只能有一位有效，保证每次只选中一个芯片。</p><p>优点：不需要地址译码器，线路简单。</p><p>缺点：地址空间不连续，选片的地址必须分时为低电平，不能充分利用系统的存储器空间。</p></li><li><p><strong>译码片选法</strong>：用除片内寻址外的高位地址线通过地址译码器芯片产生片选信号。</p></li></ol><h5 id="4-存储器与CPU的连接"><a href="#4-存储器与CPU的连接" class="headerlink" title="4. 存储器与CPU的连接"></a>4. 存储器与CPU的连接</h5><ol><li>合理选择存储芯片：主要指芯片类型和数量的选择；</li><li>地址线的连接：通常用CPU地址线的低位进行字选，高位进行片选；</li><li>数据线的连接：CPU的数据线数与存储器的数字线数不相等时，必须对存储芯片进行扩位；</li><li>读/写命令线的连接：一般可以直接相连，高电平为读，低电平为写；</li><li>片选线的连接：是CPU与存储芯片连接的关键，存储器有许多存储芯片叠加而成，哪一片被选中完全取决于该存储芯片的片选控制端（CS非）能否接收到来自CPU的有效片选信号。</li></ol><h4 id="3-4-外部存储器"><a href="#3-4-外部存储器" class="headerlink" title="3.4 外部存储器"></a>3.4 外部存储器</h4><h5 id="1-磁盘存储器"><a href="#1-磁盘存储器" class="headerlink" title="1. 磁盘存储器"></a>1. 磁盘存储器</h5><ol><li><p>磁盘存储器的优缺点：存储容量大、位价格低；记录介质可重复使用；记录信息可长期保存而不丢失；非破坏性读出，读出时不需要再生；缺点是存取速度慢，机械结构复杂，对工作环境要求较高。</p></li><li><p>磁盘设备的组成：磁盘存储器由磁盘驱动器、磁盘控制器和盘片组成；一块硬盘含有若干记录面，每个记录面划分为若干磁道，而每条磁道又划分为若干扇区，<strong>扇区是磁盘读写的最小单位</strong>。</p></li><li><p>磁头数即记录面数，表示硬盘共有多少个磁头；柱面数表示硬盘每面盘片上有多少条磁道；扇区数表示每条磁道上有多少个扇区。</p></li><li><p>磁记录原理：磁头和磁性记录介质相对运动时，通过电磁转换完成读写操作。</p></li><li><p>磁盘的性能指标：记录密度；磁盘容量；平均存取时间；数据传输率；</p><p>数据传输率=磁盘转速r(转/秒) × 磁道容量N(字节)</p></li><li><p>磁盘地址=驱动器号+柱面(磁道)号+盘面号+扇区号</p></li><li><p>读一个扇区中数据所用的时间 = 找磁道的时间 + 找扇区的时间 + 磁头扫过一个扇区的时间</p></li><li><p><strong>磁盘阵列</strong></p><p><strong>PAID（独立冗余磁盘阵列）是指将多个独立的物理磁盘组成一个独立的逻辑磁盘，数据在多个物理盘上分割交叉存储、并行访问，具有更好的存储性能、可靠性和安全性。</strong></p><p>RAID0: 无冗余和无校验的磁盘阵列</p><p>RAID1: 镜像磁盘阵列</p><p>RAID2: 采用纠错的海明码的磁盘阵列</p><p>RAID3: 位交叉奇偶校验的磁盘阵列</p><p>RAID4: 块交叉奇偶校验的磁盘阵列</p><p>RAID5: 无独立校验的奇偶校验磁盘阵列</p><p>总之，RAID通过同时使用多个磁盘，提高了传输率；通过在多个磁盘上并行存取来大幅提高存储系统的数据吞吐量；通过镜像备份，提高安全可靠性；通过数据校验，提供容错能力。</p></li></ol><h5 id="2-固态硬盘"><a href="#2-固态硬盘" class="headerlink" title="2. 固态硬盘"></a>2. 固态硬盘</h5><p>固态硬盘是一种基于闪存技术的存储器。它与U盘并没有本质上的区别，只是容量更大、存储性能更好。</p><p>固态硬盘的特点：基于闪存的存储技术、随机写很慢、随机读写性能明显高于磁盘、容易磨损。</p><h4 id="3-5-高速缓冲存储器"><a href="#3-5-高速缓冲存储器" class="headerlink" title="3.5 高速缓冲存储器"></a>3.5 高速缓冲存储器</h4><h5 id="1-程序访问的局部性原理"><a href="#1-程序访问的局部性原理" class="headerlink" title="1. 程序访问的局部性原理"></a>1. 程序访问的局部性原理</h5><p><img src="/images/计组第3章-存储系统/image-20220724180300224.png" alt="" style="zoom: 67%;"></p><h5 id="2-Cache的基本工作原理"><a href="#2-Cache的基本工作原理" class="headerlink" title="2. Cache的基本工作原理"></a>2. Cache的基本工作原理</h5><p>Cache位于存储器层次结构的顶层，通常由SRAM构成。为便于Cache和主存交换信息，Cache和主存通常被划分为大小相等的块，Cache块又称Cache行，每块由若干字节组成，块的长度称为块长（Cache行长）。</p><p><img src="/images/计组第3章-存储系统/image-20220724181021396.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220724181049649.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220724181150167.png" alt=""></p><h5 id="3-Cache和主存的映射方式"><a href="#3-Cache和主存的映射方式" class="headerlink" title="3. Cache和主存的映射方式"></a>3. Cache和主存的映射方式</h5><p><img src="/images/计组第3章-存储系统/image-20220724181329933.png" alt=""></p><ol><li><p><strong>全相联映射</strong></p><p><strong>主存中的每一块可以装入Cache中的任何位置</strong>，每行的标记用于指出该行取自主存的哪一块，所以CPU访存时需要与所有Cache行的标记进行比较。<strong>标记 = 主存块地址</strong>，主存地址 = 主存块地址（标记） + 块内地址。</p><p>优点：比较灵活，冲突率低，空间利用率高，命中率高；</p><p>缺点：标记长，标记的比较速度慢，实现成本高通常采用价格昂贵的相联存储器。</p><p><img src="/images/计组第3章-存储系统/image-20220724182111571.png" alt=""></p></li><li><p><strong>直接映射</strong></p><p>主存中的每一块只能装入Cache块中的唯一位置。若这个位置已有内容，则产生块冲突，原来的块将被无条件替换出去（<strong>无需使用替换算法</strong>）。</p><p>直接映射规则：<strong>Cache行号 = 主存块号 % Cache总行数</strong></p><p>主存地址结构：<strong>主存块地址 = 标记 + Cache行号</strong>，主存地址 = 标记 + Cache行号 + 块内地址。</p><p>假设Cache共有$2^{c}$行，主存有$2^{m}$块，则每个Cache行会对应$2^{m-c}$块，故需要设置一个长为m-c的标记，以确定该Cache行的内容来自$2^{m-c}$块中的哪一块。而主存块号的低c位正好是它要装入的Cache行号。</p><p>直接映射实现简单，但不够灵活，块冲突概率最高，空间利用率最低。</p><p><img src="/images/计组第3章-存储系统/image-20220724190305533.png" alt=""></p></li><li><p><strong>组相联映射</strong></p><p>将Cache分成Q个大小相等的组，每个主存块可装入固定组中的任意一行，即组间采用直接映射、而组内采用全相联映射的方式。它是对全相联映射和直接映射的一种折中，当Q=1时变为全相联映射，当Q=Cache行数时变为直接映射。假设每组有r个Cache行，则称之为r路组相联。</p><p>组相联的映射关系为：<strong>Cache组号 = 主存块号 % Cache组数Q</strong></p><p>选定适当的分组数量，可使组相联映射的成本接近直接映射，而性能上仍接近全相联映射。</p><p>组相联映射的主存地址结构为：<strong>主存块地址 = 标记 + 组号</strong>，主存地址 = 标记 + 组号 + 块内地址。</p><p>组间作区分，组内不作区分，给定一个主存块，根据主存块号%Cache组数Q确定组号，然后映射至该组内空闲的Cache块，若Cache块均已装满，则根据替换算法进行替换。</p><p><img src="/images/计组第3章-存储系统/image-20220724192557766.png" alt=""></p></li></ol><h5 id="4-Cache中主存块的替换算法"><a href="#4-Cache中主存块的替换算法" class="headerlink" title="4. Cache中主存块的替换算法"></a>4. Cache中主存块的替换算法</h5><p>在采用全相联映射或组相联映射方式时，从主存向Cache传送一个新块，当Cache或Cache组中的空间已被占满时，就需要使用替换算法置换Cache行。而采用直接映射方式时，由于新主存块的Cache行位置是固定的，所以直接将该位置替换即可，无需考虑替换算法。</p><p>常见的替换算法有：随机（RAND）替换算法；先进先出法（First in First out）;近期最少使用法（Least recently Used）;最不经常使用法（Least Frequently Used）。</p><ol><li><p><strong>随机算法（RAND）</strong>：随机替换。没有依据程序的局部性原理，所以可能会降低命中率。</p></li><li><p><strong>先进先出算法（FIFO）</strong>：选择最早调入的行进行替换。最早调入的内容也可能是目前经常要用的，所以也没有依据程序的局部性原理。</p></li><li><p><strong>近期最少使用算法（LRU）</strong>：依据<strong>程序访问的局部性原理</strong>，选择近期长久未访问过的Cache行作为替换的行，平均命中率比FIFO要高，是堆栈类算法。LRU算法对每个Cache行设置一个计数器，记录未访问的时间长短，命中某一行时，该行计数值清零，其余行计数值加一，计数值越大说明，说明近期使用到的概率越低。</p><p>当集中访问的存储区超过Cache组的大小时，命中率可能变得很低，这种现象称为<strong>抖动</strong>。</p></li><li><p><strong>最不经常使用算法（LFU）</strong>：将一段时间内被访问次数最少的Cache行换出。同样设置一个计数器，记录每一行被访问的次数，需要替换时，将计数值最小的行换出。LFU算法看似合理其实也有一定的缺陷，因为总的使用次数最少并不意味着近期使用的次数也最少，根据程序访问的局部性原理，我们应该以近期的使用次数作为衡量标准。</p></li></ol><h5 id="5-Cache写策略"><a href="#5-Cache写策略" class="headerlink" title="5. Cache写策略"></a>5. Cache写策略</h5><p>因为Cache中的内容是主存块副本，当对Cache中的内容进行更新时，就需选用写操作策略使Cache内容与主存内容保持一致。此时分两种情况。</p><p>对于<strong>Cache写命中（write hit）</strong>，有两种处理方法：</p><ol><li><p><strong>全写法（写直通法、write-through）</strong>。当CPU对Cache写命中时，必须把数据同时写入Cache和主存当某一块需要替换时，因为已经写入主存，所以直接替换即可。这种方法实现简单，主存与Cache即时同步，能随时保持主存数据的正确性，缺点是增加了访存次数，降低了Cache的效率。</p><p>为减少全写法直接写入主存的时间损耗，在Cache和主存之间添加了一个写缓冲（Write Buffer）。CPU同时将数据写入Cache和写缓冲中，写缓冲再控制将内容写入主存。写缓冲是一个FIFO队列，可以解决速度不匹配的问题，但若出现频繁写时，会使写缓冲饱和溢出。</p></li><li><p><strong>回写法（write-back）</strong>。当CPU对Cache写命中时，只把数据写入Cache中，而不立即写入主存，只有当此块被换出时才写回主存。这种方法减少了访存次数，但存在数据不一致的隐患。为了减少写回主存的开销，每个Cache行设置一个修改位（脏位）。若修改位为1，则说明对应Cache行中的块被修改过，替换时需要写回主存；若修改位为0，则说明数据未被修改过，替换时无需写回主存。</p></li></ol><p>对于<strong>Cache写不命中</strong>，也有两种处理方法：</p><ol><li><p><strong>写分配法（write-allocate）</strong>。加载主存中的块到Cache中，然后更新这个块。它试图利用程序的空间局部性原理，即在某个存储单元被访问时，它附近的存储单元也很可能即将被访问（因为程序往往是顺序存储的，一段程序的指令和数据通常集中存储在相邻的一片存储区域中），因此可以先将该存储单元所在的块调入Cache中，如果命中，则CPU无需再进行访存，直接与Cache交换数据，程序的执行速度大大提高。</p><p>但缺点是每次不命中都需要从主存中读取一块，如果CPU不需要再使用该块中的内容，则一方面浪费了Cache的空间，另一方面凭白多消耗了一次主存块调入Cache的时间。</p></li><li><p><strong>非写分配法（not-write-allocate）</strong>。只写入主存，不进行调块。虽然不会提高速度但至少也不会减慢速度。</p></li></ol><p><strong>非写分配法通常与全写法合用，写分配法通常与回写法合用。</strong>即写命中时如果同时将数据写入主存和Cache，则写不命中时，只写入主存，不进行调块。写命中时，如果只写入Cache，则写不命中时，进行调块，至Cache块被替换时再根据修改位写回主存。</p><p>随着新技术的发展（如指令预取），需要将指令Cache和数据Cache分离，分离的主要目的是减少指令流水线的资源冲突。</p><h4 id="3-6-虚拟存储器"><a href="#3-6-虚拟存储器" class="headerlink" title="3.6 虚拟存储器"></a>3.6 虚拟存储器</h4><h5 id="1-虚拟存储器的基本概念"><a href="#1-虚拟存储器的基本概念" class="headerlink" title="1. 虚拟存储器的基本概念"></a>1. 虚拟存储器的基本概念</h5><p><img src="/images/计组第3章-存储系统/image-20220724213434258.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220724213522820.png" alt=""></p><h5 id="2-页式虚拟存储器"><a href="#2-页式虚拟存储器" class="headerlink" title="2. 页式虚拟存储器"></a>2. 页式虚拟存储器</h5><p><img src="/images/计组第3章-存储系统/image-20220724213612239.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220724213650698.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220724213749639.png" alt=""></p><h5 id="3-段式虚拟存储器"><a href="#3-段式虚拟存储器" class="headerlink" title="3. 段式虚拟存储器"></a>3. 段式虚拟存储器</h5><p><img src="/images/计组第3章-存储系统/image-20220724214839881.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220724214917023.png" alt=""></p><h5 id="4-段页式虚拟存储器"><a href="#4-段页式虚拟存储器" class="headerlink" title="4. 段页式虚拟存储器"></a>4. 段页式虚拟存储器</h5><p><img src="/images/计组第3章-存储系统/image-20220724214958091.png" alt=""></p><p><img src="/images/计组第3章-存储系统/image-20220724215026995.png" alt=""></p><h5 id="5-虚拟存储器与Cache的比较"><a href="#5-虚拟存储器与Cache的比较" class="headerlink" title="5. 虚拟存储器与Cache的比较"></a>5. 虚拟存储器与Cache的比较</h5><p>相同之处：</p><ol><li>最终目标都是为了提高系统性能，两者都有容量、速度、价格的梯度；</li><li>都是把数据划分为小信息块，并作为基本的传递单位，虚存系统的信息块更大；</li><li>都有地址的映射、替换算法、更新策略等问题；</li><li>依据程序的局部性原理，应用“快速缓存”的思想，将活跃的数据放在相对高速的部件中。</li></ol><p>不同之处：</p><ol><li>Cache主要解决系统速度，而虚拟存储器则是解决主存容量；</li><li>Cache全由硬件实现，是硬件存储器，对所有程序员透明；而虚拟存储器则是由操作系统和硬件共同实现，，是逻辑上的存储器，对系统程序员不透明，但是对应用程序员透明；</li><li>对于不命中性能影响，因为CPU的速度约为Cache的10倍，主存的速度为硬盘的100倍以上，因此虚拟存储器系统不命中时对系统性能影响更大；</li><li>CPU与Cache和主存都建立了直接访问的通路，而辅存与CPU没有直接通路。也就是说在Cache不命中时主存能和CPU直接通信，同时将数据调入Cache；而虚拟存储器系统不命中时，只能先由硬盘调入主存，而不能直接和CPU通信。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计组第2章-数据的表示和运算</title>
      <link href="/2022/07/27/ji-zu-di-2-zhang-shu-ju-de-biao-shi-he-yun-suan/"/>
      <url>/2022/07/27/ji-zu-di-2-zhang-shu-ju-de-biao-shi-he-yun-suan/</url>
      
        <content type="html"><![CDATA[<h3 id="第二章-数据的表示和运算"><a href="#第二章-数据的表示和运算" class="headerlink" title="第二章 数据的表示和运算"></a>第二章 数据的表示和运算</h3><h4 id="考纲内容"><a href="#考纲内容" class="headerlink" title="考纲内容"></a>考纲内容</h4><blockquote><p>（一）数制与编码</p><p>​        进位计数制及其相互转换；定点数的编码表示</p><p>（二）运算方法和运算电路</p><p>​        基本运算部件：加法器，算术逻辑单元（ALU）</p><p>​        加/减运算：补码加/减运算器，标志位的生成</p><p>​        乘/除运算：乘/除运算的基本原理，乘法运算和除法电路的基本结构</p><p>（三）整数的表示和运算</p><p>​        无符号整数的表示和运算；带符号整数的表示和运算</p><p>（四）浮点数的表示和运算</p><p>浮点数的表示：IEEE754标准；浮点数的加/减运算</p></blockquote><h4 id="一、数制与编码"><a href="#一、数制与编码" class="headerlink" title="一、数制与编码"></a>一、数制与编码</h4><h5 id="1-进位计数制及其相互转换"><a href="#1-进位计数制及其相互转换" class="headerlink" title="1.进位计数制及其相互转换"></a>1.进位计数制及其相互转换</h5><p>在进位计数法中，一个数由若干个<strong>数位</strong>组成，每个数位都有其<strong>基数</strong>与<strong>位权</strong>。</p><p>这个数的十进制值由各个数位上的基数按位权展开并相加得到，称为<strong>按权展开相加法</strong>。</p><h6 id="1-二进制与八进制、十六进制的转换"><a href="#1-二进制与八进制、十六进制的转换" class="headerlink" title="(1) 二进制与八进制、十六进制的转换"></a>(1) 二进制与八进制、十六进制的转换</h6><p>一个二进制数（即一个二进制位）可以表示的数只有0和1两个，而一个八进制数可以表示的数有0~7共八个，刚好可以由3个二进制位来完全表示（<code>2**3=8</code>），故1个八进制位可以转换为3个二进制位，同理，1个十六进制位可以转换为4个二进制位。</p><p>而十六进制和八进制的相互转换可以通过二进制作为过渡。</p><h6 id="2-任意进制数转换为十进制数"><a href="#2-任意进制数转换为十进制数" class="headerlink" title="(2) 任意进制数转换为十进制数"></a>(2) 任意进制数转换为十进制数</h6><p>将任意进制数各个数位上的基数与它们的权值相乘，再把乘积累加，即可得到其十进制值，即按权展开相加法。</p><h6 id="3-十进制数转换为任意进制数"><a href="#3-十进制数转换为任意进制数" class="headerlink" title="(3) 十进制数转换为任意进制数"></a>(3) 十进制数转换为任意进制数</h6><p>整数部分：除基取余法。（自下向上）</p><p>小数部分：乘基取整法。（自上向下）</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220708135843597.png" alt=""></p><h5 id="2-定点数的编码表示"><a href="#2-定点数的编码表示" class="headerlink" title="2.定点数的编码表示"></a>2.定点数的编码表示</h5><p><strong>真值和机器数：以(+)(-)号来表示正负的数称为真值，以0和1来表示正负的称为机器数。</strong></p><p>BCD码：二进制编码的十进制数，有<code>2**4-10=6</code>位冗余，常见的BCD码有8421码。</p><p>1.机器数的定点表示</p><p>定点数与浮点数相对，包含定点小数和定点整数，定点小数即纯小数，范围在（-1,1）内，其整数部分为0，定点整数即纯整数，其小数部分为0。</p><p>定点小数的小数点位置在符号位之后，有效数值部分最高位之前；定点整数小数点在有效数值部分最低位之后。</p><p>定点数的编码表示主要有四种：原码、反码、补码、移码。</p><h6 id="1-原码-Sign-Magnitude"><a href="#1-原码-Sign-Magnitude" class="headerlink" title="(1) 原码(Sign-Magnitude)"></a>(1) 原码(Sign-Magnitude)</h6><p><strong>用机器数的最高位表示数的符号，0代替正号，1代替负号，其余各位不变，即得真值的原码。</strong></p><p>当真值为正数时，最高位为0，故<code>真值x = 原码[x]</code></p><p>当真值为负数时，其最高位为1，记真值为x(x&lt;0,包含负号)</p><blockquote><p>如果是整数，权值为<code>2**n</code>,n为整数位数，故<code>[x]原 = 2**n + |x|</code></p><p>如果是小数，权值为<code>2**0 = 1</code>,设小数位数为n，则<code>[x]原 = 1 + |x|</code></p></blockquote><p><strong>原码最高有效位是符号位，没有权值，仅用来确定剩下的位应该取正权还是负权</strong>：</p><script type="math/tex; mode=display">B2S_{w}(\vec{x})=(-1)^{x_{w-1}}(\sum_{i=0}^{w-2}x_{i}2^{i})</script><p>原码表示范围：$SMin_{w}=[1,111\cdot\cdot\cdot1]=-2^{w-1}+1$,$SMax_{w}=[0,111\cdot\cdot\cdot1]=2^{w-1}-1$,关于原点对称。</p><h6 id="2-补码-Two’s-complement"><a href="#2-补码-Two’s-complement" class="headerlink" title="(2) 补码(Two’s-complement)"></a>(2) 补码(Two’s-complement)</h6><p><strong>补码的最高位为负权</strong>，其余各位为正权，最高位为0代表正数，最高位为1代表负数。</p><p>对于向量</p><script type="math/tex; mode=display">\vec{x}=[x_{w-1},x_{w-2},\cdot\cdot\cdot,x_{0}]:</script><script type="math/tex; mode=display">B2T_{w}(\vec{x})=-x_{w-1}2^{w-1}+\sum_{i=0}^{w-2}x_{i}2^{i}</script><p>$B2T_{w}$（Binary to Two’s-complement，二进制转化为二进制的补码：将真值（二进制向量）的最高位权重取负，再与其余各数位按权展开相加，即可得到其补码的十进制值，根据除2取余法即可转换为二进制形式的补码，该补码位数不足8位时，正数最高位补0，负数最高位补1，其余位补0）。<strong>补码的最高有效位 $x_{w-1}$也称为符号位，它的权重为$-2^{w-1}$。</strong></p><p>当真值x为正数时，$x_{w-1}=0$,故$[x]补=\sum_{i=0}^{w-2}x_{i}2^{i}=真值x$;</p><p>当真值x为负数时，$x_{w-1}=1$, $B2T_{w}(\vec{x})=-2^{w-1}+\sum_{i=0}^{w-2}x_{i}2^{i}$,</p><p>如果是整数，真值的绝对值$|x|=[x]补+x_{w-1}2^{w}$，即相差了两个$x_{w-1}2^{w-1}$。</p><p>补码所能表示的范围：$TMin_{w}=[1,0,0,0,\cdot\cdot\cdot,0]=-2^{w-1}$,$TMax_{w}=[0,1,1,1,\cdot\cdot\cdot,1]=2^{w-1}-1$。</p><p>$TMax_{w}=-TMin_{w}-1$,补码的范围是不对称的，$TMin_{w}$没有与之对应的正数。</p><h6 id="3-反码-One’s-Complement"><a href="#3-反码-One’s-Complement" class="headerlink" title="(3)  反码(One’s Complement)"></a>(3)  反码(One’s Complement)</h6><p>除了最高有效位的权是$-(2^{w-1}-1)$而不是$-2^{w-1}$,它和补码是一样的：</p><script type="math/tex; mode=display">B2O_{w}(\vec{x})=-x_{w-1}(2^{w-1}-1)+\sum_{i=0}^{w-2}x_{i}2^{i}</script><p>由原码求反码：符号位不变，尾数取反；</p><p>由反码求补码：末位+1；</p><p><strong>故由原码求补码：符号位不变，尾数取反，末位加一。</strong></p><h6 id="4-移码"><a href="#4-移码" class="headerlink" title="(4)  移码"></a>(4)  移码</h6><p><strong>移码和补码：符号位相反，数值位相同。</strong></p><p>移码全0时，对应真值的最小值$-2^{n}$,移码全1时，对应真值的最大值$2^{n}-1$。</p><p>移码保持了数据原有的大小顺序，移码大真值就大，移码小真值就小。</p><h6 id="5-原码、反码、补码、移码总结："><a href="#5-原码、反码、补码、移码总结：" class="headerlink" title="(5) 原码、反码、补码、移码总结："></a>(5) 原码、反码、补码、移码总结：</h6><ul><li>原码、补码、反码的符号位相同，正数的机器数相同；</li><li>原码、反码的表示在数轴上对称，二者都存在+0和-0两个零；</li><li>补码、移码不对称，0的表示唯一，它们比原码、反码多出一个位置来表示一个数；</li><li><strong>将真值的(+)(-)负号用0和1来表示即得真值的原码；原码符号位不变、尾数取反即得反码；反码末位+1即得补码；补码符号位取反即得移码；</strong></li><li><strong>补码和真值的相互转换：连同符号位一起取反，末位加1。</strong></li><li><strong>[x]补转换为[-x]补：各位取反，末位+1。</strong></li></ul><h4 id="二、运算方法和运算电路"><a href="#二、运算方法和运算电路" class="headerlink" title="二、运算方法和运算电路"></a>二、运算方法和运算电路</h4><h5 id="1-基本运算部件"><a href="#1-基本运算部件" class="headerlink" title="1.基本运算部件"></a>1.基本运算部件</h5><p>在计算机中，运算器是由算术逻辑单元ALU、移位器、状态寄存器、和通用寄存器等组成。运算器的基本功能包括加、减、乘、除四则运算，与、或、非、异或等逻辑运算以及移位、求补等操作。ALU的核心部件是加法器。</p><h6 id="1-一位全加器"><a href="#1-一位全加器" class="headerlink" title="(1) 一位全加器"></a>(1) 一位全加器</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220706171044267.png" alt="" style="zoom:50%;"></p><p>全加器（FA）是最基本的加法单元，有加数A加数B与低位传来的进位$C_{i-1}$共三个输入，有本位和$S_{i}$和向高位的进位$C_{i}$共两个输出。全加器的逻辑表达式如下：</p><p>和表达式：$S_{i}=A_{i}⊕B_{i}⊕C_{i-1}$（有奇数个1时，$S_{i}=1$;否则$S_{i}=0$）</p><p>进位表达式：$C_{i}=A_{i}B_{i}+(A_{i}⊕B_{i})C_{i-1}$</p><h6 id="2-串行进位加法器"><a href="#2-串行进位加法器" class="headerlink" title="(2) 串行进位加法器"></a>(2) 串行进位加法器</h6><p>把n个加法器相连可以得到n位加法器，称为串行进位加法器。串行进位加法器是实现了两个n位二进制数$A=A_{n}A_{n-1}\cdot\cdot\cdot A_{1}$和$B=B_{n}B_{n-1}\cdot\cdot\cdot B_{1}$逐位相加的功能。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706172746396.png" alt="" style="zoom:50%;"></p><p>得到的和为$S=S_{n}S_{n-1}\cdot\cdot\cdot S_{1}$,进位输出为$C_{n}$.</p><p>由于加法器位数有限，如果超过了最高位数，高位自动丢失，所以实际是模$2^{n}$的加法运算。</p><p>在串行进位加法器中，低位运算所产生进位所需的时间将影响高位运算的时间。串行进位加法器的最长运算时间主要是由进位信号的传递时间决定的，位数越多延迟时间越长，而全加器本身的求和延迟只是次要因素，因此加快进位产生和提高传递的速度是提升性能的关键。</p><h6 id="3-并行进位加法器"><a href="#3-并行进位加法器" class="headerlink" title="(3) 并行进位加法器"></a>(3) 并行进位加法器</h6><p><strong>令$G_{i}=A_{i}B_{i}$,称为进位产生函数，即进位信号；$P_{i}=A_{i}⊕B_{i}$,称为进位传递函数，即进位传递信号。</strong></p><p>$C_{i}$仅与$A_{i}$、$B_{i}$和最低进位$C_{0}$有关，相互间的进位没有依赖关系。只要$A_{1}$~$A_{n}$ ,$B_{1}$~$B_{n}$和$C_{0}$同时到达，就可以几乎同时形成$C_{1}$ ~ $C_{4}$,并且同时生成各位的和。</p><p>实现上述逻辑的电路称为先行进位部件，简称CLA部件。通过这种进位方式实现的加法器称为全先行进位加法器。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220727212359897.png" style="zoom:80%;"></p><p>这种进位方式是快速的，与位数无关。但随着加法器位数的增加，$C_{i}$的逻辑表达式会变得越来越长，这会使电路结构越来越复杂，所以可以将加法器部件先分组，采取组内并行进位，组间再并行进位的方式，可以控制每个部分的复杂性，同时也进一步提高了运算速度。</p><h6 id="4-带标志加法器"><a href="#4-带标志加法器" class="headerlink" title="(4) 带标志加法器"></a>(4) 带标志加法器</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220727212622458.png" style="zoom:80%;"></p><p>在无符号加法器的基础上添加了溢出标志OF，符号标志SF，零标志ZF，进位/借位标志CF。值得注意的是，为了加快加法运算的速度，实际电路一定使用多级先行进位方式。</p><h6 id="5-算术逻辑单元ALU"><a href="#5-算术逻辑单元ALU" class="headerlink" title="(5) 算术逻辑单元ALU"></a>(5) 算术逻辑单元ALU</h6><p>ALU的核心是带标志加法器，同时也能执行与或非等逻辑运算。ALU基本结构如图所示，<code>ALUop</code>是操作控制端，用来决定ALU所执行的处理功能，<code>ALUop</code>的位数决定了操作的种类数量。</p><p>MUX是多路选择开关，它从多个输入信号中选择一个送到输出端。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220727212743794.png" style="zoom:80%;"></p><h5 id="2-定点数的移位运算"><a href="#2-定点数的移位运算" class="headerlink" title="2.定点数的移位运算"></a>2.定点数的移位运算</h5><h6 id="1-算术移位"><a href="#1-算术移位" class="headerlink" title="(1) 算术移位"></a>(1) 算术移位</h6><p><strong>算术移位：符号位不变、数码位置变化</strong>。</p><p>算术移位的对象是有符号数，在移位过程中符号位保持不变。</p><p>对于正数，由于<code>原码 = 反码 = 补码 = 真值</code>，因此移位后出现的空位全部补0。对于负数，因为原码、反码、补码的表示形式不同，因此当机器数移位时，对其空位的添补规则也不同。</p><blockquote><p>注意：不论是正数还是负数，移位后其符号位均不变，且移位后都相当于对真值补0。</p></blockquote><p>负数的算术移位添补规则：</p><div class="table-container"><table><thead><tr><th></th><th>码制</th><th style="text-align:left">添补代码</th></tr></thead><tbody><tr><td>正数</td><td>原码、反码、补码</td><td style="text-align:left">0</td></tr><tr><td></td><td>原码</td><td style="text-align:left">0</td></tr><tr><td>负数</td><td>反码</td><td style="text-align:left">左移添0，右移添1</td></tr><tr><td></td><td>补码</td><td style="text-align:left">1</td></tr></tbody></table></div><h6 id="2-逻辑移位"><a href="#2-逻辑移位" class="headerlink" title="(2) 逻辑移位"></a>(2) 逻辑移位</h6><p><strong>逻辑移位：数码位置变化。</strong></p><p>逻辑移位时将操作数视为无符号数。</p><p>移位规则：逻辑左移时，高位移丢，低位添0；逻辑右移时，低位移丢，高位添0。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706191610089.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706191752334.png" alt=""></p><h6 id="3-循环移位"><a href="#3-循环移位" class="headerlink" title="(3) 循环移位"></a>(3) 循环移位</h6><p>循环移位分为带进位标志位CF的循环移位和不带进位标志位的循环移位。循环移位的主要特点是，移出的数位又被移入数据中。循环移位适合于将数据的低字节数据和高字节数据互换。</p><h5 id="3-定点数的加减运算"><a href="#3-定点数的加减运算" class="headerlink" title="3.定点数的加减运算"></a>3.定点数的加减运算</h5><h6 id="1-补码的加减法运算"><a href="#1-补码的加减法运算" class="headerlink" title="(1) 补码的加减法运算"></a>(1) 补码的加减法运算</h6><p>定点数一般用补码表示，符号位参与运算。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706195529993.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706195624577.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706195651109.png" alt=""></p><h6 id="2-补码加减运算电路"><a href="#2-补码加减运算电路" class="headerlink" title="(2) 补码加减运算电路"></a>(2) 补码加减运算电路</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220706195752856.png" alt=""></p><h6 id="3-溢出判断方法"><a href="#3-溢出判断方法" class="headerlink" title="(3) 溢出判断方法"></a>(3) 溢出判断方法</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220706200603460.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706200618745.png" alt=""></p><p>逻辑一（根据符号判断）：无论是加法还是减法，只要<strong>参加操作的两个数符号相同，结果又与原操作数符号不同</strong>，则表示结果溢出。</p><p>根据溢出逻辑表达式，当溢出逻辑V=0时，表示无溢出；当溢出逻辑V=1时，表示有溢出。</p><p>逻辑二（根据进位判断）：若符号位的进位$C_{f}$与最高数位的进位C相同，$V=C_{f}⊕C=0$表示无溢出，<strong>若符号位的进位与最高位的进位不一致，V=1表示有溢出。</strong></p><p>逻辑三（根据双符号位判断）：采用双符号位时，若结果的两个符号位相同，$V=S_{f1}⊕S_{f2}=0$,表示无溢出，V=1表示溢出。<strong>01表示正溢，10表示负溢。</strong></p><h6 id="4-原码的加减法运算"><a href="#4-原码的加减法运算" class="headerlink" title="(4) 原码的加减法运算"></a>(4) 原码的加减法运算</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220706202418827.png" alt=""></p><h5 id="4-定点数的乘除运算"><a href="#4-定点数的乘除运算" class="headerlink" title="4.定点数的乘除运算"></a>4.定点数的乘除运算</h5><h6 id="1-◓原码一位乘法"><a href="#1-◓原码一位乘法" class="headerlink" title="(1) ◓原码一位乘法"></a>(1) ◓原码一位乘法</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220706205641762.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706205701414.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706205722544.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706205738465.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706205754110.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220706205806670.png" alt=""></p><h6 id="2-无符号数乘法运算电路"><a href="#2-无符号数乘法运算电路" class="headerlink" title="(2) 无符号数乘法运算电路"></a>(2) 无符号数乘法运算电路</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220707090213305.png" alt=""></p><h6 id="3-补码一位乘法"><a href="#3-补码一位乘法" class="headerlink" title="(3) 补码一位乘法"></a>(3) 补码一位乘法</h6><p>补码一位乘法是有符号数的乘法，采用相加和相减操作计算补码数据的乘积。</p><p>设$[X]补=x_{s}\cdot x_{1}x_{2}\cdot\cdot\cdot x_{n}$,$[Y]补=y_{s}\cdot y_{2}y_{2}\cdot\cdot\cdot y_{n}$,则运算规则如下：</p><ul><li>符号位参与运算，运算的数均以补码表示。</li><li>被乘数一般取双符号位参与运算，部分积取双符号位，初始值为0，乘数取单符号位。</li><li>乘数末位增设附加位$y_{n+1}$,初始值为0。</li><li>根据$y_{n}y_{n+1}$的取值来确定操作，见下图。</li></ul><p><img src="/images/计组第2章-数据的表示和运算/image-20220707090920563.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707090936191.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707090947715.png" alt=""></p><h6 id="4-符号扩展"><a href="#4-符号扩展" class="headerlink" title="(4) 符号扩展"></a>(4) 符号扩展</h6><ol><li><strong>无符号数使用零扩展</strong></li><li><strong>补码数使用符号扩展</strong></li></ol><p><img src="/images/计组第2章-数据的表示和运算/image-20220707093540297.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707093601666.png" alt=""></p><h6 id="5-原码除法运算"><a href="#5-原码除法运算" class="headerlink" title="(5) 原码除法运算"></a>(5) 原码除法运算</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220727221403134.png" alt=""></p><h6 id="6-◒补码不恢复余数除法"><a href="#6-◒补码不恢复余数除法" class="headerlink" title="(6) ◒补码不恢复余数除法"></a>(6) ◒补码不恢复余数除法</h6><p>补码一位除法的特点是，符号位与数值位一起参与运算，商符自然形成。</p><p>除法第一步根据被除数和除数的符号决定做加法还是减法；上商的原则根据余数和被除数的符号位共同决定，同号上商”1”，异号上商”0”；最后一步商恒置”1”。</p><p>加减法的交替规则如下：</p><ol><li>符号位参与运算，除数、被除数以及商和余数均用补码表示。</li><li>若被除数与除数同号，则被除数减去除数；若被除数与除数异号，则被除数加上除数。</li><li><strong>若余数与除数同号，则商上”1”，余数左移一位减去除数；若异号则商上”0”，余数左移一位加上除数。</strong></li><li>重复执行第3步n次。</li><li>若对商的精度没有要求，则一般采用”末位恒置1“法。</li></ol><p><img src="/images/计组第2章-数据的表示和运算/image-20220707095952702.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707100006747.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707100018482.png" alt=""></p><h6 id="7-除法运算电路"><a href="#7-除法运算电路" class="headerlink" title="(7) 除法运算电路"></a>(7) 除法运算电路</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220727221206654.png" alt=""></p><h5 id="5-C语言整数类型转换"><a href="#5-C语言整数类型转换" class="headerlink" title="5.C语言整数类型转换"></a>5.C语言整数类型转换</h5><h6 id="1-有符号数和无符号数的转换"><a href="#1-有符号数和无符号数的转换" class="headerlink" title="(1) 有符号数和无符号数的转换"></a>(1) 有符号数和无符号数的转换</h6><ol><li>强制类型转换的原理</li></ol><p>C语言允许在不同的数据类型之间进行强制类型转换。</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>{</span><br><span class="line">    <span class="type">short</span> x=<span class="number">-4321</span>;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">short</span> y=(<span class="type">unsigned</span> <span class="type">short</span>)x;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"x=%d, y=%u\n"</span>,x,y);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>在采用补码的机器上，上述代码会输出如下结果：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x=-4321,y=61215</span><br></pre></td></tr></tbody></table></figure><p>这两个值看似没有任何关系，不过将它们转换为二进制表示时，我们就会发现其中的规律：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x=<span class="number">11111111111111111110111100011111</span></span><br><span class="line">y=                <span class="number">1110111100011111</span></span><br></pre></td></tr></tbody></table></figure><p>可以发现x和y的二进制表示是一致的，只不过x进行了符号扩展。</p><p>因此，<strong>强制类型转换的结果保持位值不变，仅改变了解释这些位值的方式。</strong></p><ol><li>有符号数与无符号数的相互转换方式</li></ol><p>【2016统考真题】有如下C语言程序段：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">short</span> si = <span class="number">-32767</span>;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">short</span> usi = si;</span><br></pre></td></tr></tbody></table></figure><p>执行上述两条语句后，<code>usi</code>的值为（  ）。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A. -32767B. 32767C. 32768D. 32769</span><br></pre></td></tr></tbody></table></figure><p>【2019统考真题】考虑以下C语言代码：</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">short</span> usi = <span class="number">65535</span>;</span><br><span class="line"><span class="type">short</span> si = usi;</span><br></pre></td></tr></tbody></table></figure><p>执行上述程序段后，<code>si</code>的值是（  ）。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A. -1B. -32767C. -32768D. -65535</span><br></pre></td></tr></tbody></table></figure><p>【分析】：这两个题都是对无符号数与有符号数的相互转换的考察，我们要熟悉无符号数与有符号数的表示范围与转换规则。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707213217903.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707213230541.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707213451081.png" alt=""></p><h6 id="2-不同字长整数之间的转换"><a href="#2-不同字长整数之间的转换" class="headerlink" title="(2) 不同字长整数之间的转换"></a>(2) 不同字长整数之间的转换</h6><ol><li>当大字长变量向小字长变量强制类型转换时，系统把多余的高位部分直接<strong>截断</strong>，低位直接赋值，因此也是一种保持位值的方法；</li><li>短字长整数到长字长整数的转换时，不仅要使相应的位值相等，还要对高位部分进行扩展。如果原数字是无符号整数，则进行<strong>零扩展</strong>，否则进行<strong>符号扩展</strong>。</li></ol><h5 id="6-数据的存储和排列"><a href="#6-数据的存储和排列" class="headerlink" title="6.数据的存储和排列"></a>6.数据的存储和排列</h5><h6 id="1-大端法和小端法"><a href="#1-大端法和小端法" class="headerlink" title="(1) 大端法和小端法"></a>(1) 大端法和小端法</h6><p><img src="/images/计组第2章-数据的表示和运算/image-20220707135807966.png" alt=""> </p><h6 id="2-数据按边界对齐存储"><a href="#2-数据按边界对齐存储" class="headerlink" title="(2) 数据按边界对齐存储"></a>(2) 数据按边界对齐存储</h6><p>当告诉我们按字节编址时，即每个字节都有其地址；当告诉我们机器字长为32位时，即一个机器字包含4个字节，注意数据存储是否按机器字的边界对齐。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220707135940966.png" alt=""></p><p>数据以按边界对齐方式存放可以一次访存取出，所存储的数据不能恰好按边界对齐时，可以填补空白字节，使之按边界对齐，这样虽然浪费了一些存储空间，但可以提高取指令和取数的速度。</p><h5 id="7-浮点数的表示与运算"><a href="#7-浮点数的表示与运算" class="headerlink" title="7.浮点数的表示与运算"></a>7.浮点数的表示与运算</h5><p><img src="/images/计组第2章-数据的表示和运算/image-20220708175817299.png" alt=""></p><p><img src="/images/计组第2章-数据的表示和运算/image-20220708175911661.png" alt=""></p><h6 id="1-浮点数的表示格式"><a href="#1-浮点数的表示格式" class="headerlink" title="(1) 浮点数的表示格式"></a>(1) 浮点数的表示格式</h6><p>通常，浮点数表示为</p><script type="math/tex; mode=display">N=(-1)^{S}×M×R^{E}</script><p>其中，S为数符，取值0或1，用来决定浮点数的符号；</p><p>M是尾数，为二进制定点小数，一般用定点原码小数表示，尾数的位数反映浮点数的精度；</p><p>R为基数，二进制基数R=2；</p><p>E为阶码，即指数，用移码表示。阶码的值反映浮点数的小数点的实际位置，阶码的位数反映浮点数的表示范围。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220708093014957.png" alt=""></p><h6 id="2-浮点数的规格化"><a href="#2-浮点数的规格化" class="headerlink" title="(2) 浮点数的规格化"></a>(2) 浮点数的规格化</h6><p>规格化：约定尾数M的值域，使浮点数的表示代码是唯一的、确定的。</p><p>所谓规格化操作，是指通过调整一个非规格化浮点数的尾数和阶码的大小，使非零的浮点数在尾数的最高数位上保证是一个有效值（十进制），即阶码的位模式既不全为0，也不全为1。</p><p>当阶码的位模式全为0时，说明尾数M过小，尾数的最高数位不是有效位，应该对尾数M进行左规，尾数每左移一位，阶码减1（基数为2时）；</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220708102345481.png" alt=""></p><p>尾数是纯小数，M＜1，当运算结果的尾数的小数位进到小数点前面时，需要进行右规，将尾数右移一位阶码加1（基数为2时），需要右规时，只需进行一次，左规可能要进行多次。</p><p>当阶码全为1时，表明该数是一个特殊值，可能为$+∞$、$-∞$或<code>NaN</code>(Not a Number)。</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220708093703792.png" alt=""></p><h6 id="3-IEEE754标准"><a href="#3-IEEE754标准" class="headerlink" title="(3) IEEE754标准"></a>(3) IEEE754标准</h6><p>按照IEEE754标准，常用的浮点数格式如下：</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220708102215311.png" alt=""></p><p>32位单精度格式：1位符号+8位阶码+23位尾数</p><p>64位双精度格式：1位符号+11位阶码+52位尾数</p><p>IEEE754标准的长短浮点数，是尾数采取隐藏位策略的原码表示，且阶码用移码表示的浮点数。</p><p>对于规格化的二进制浮点数，数值的最高位总是”1”，既然第一位总是”1”，那么我们就不需要显式地表示它，将这个”1”隐藏，称为隐藏位，因此23位尾数可以表示出24位有效数字。</p><p>短浮点数与长浮点数都采用隐藏尾数最高数位的方法，因此可以多表示一位尾数。</p><p>对于短浮点数，偏置值为127；对于长浮点数，偏置值为1023。存储浮点数阶码之前，偏置值要先加到阶码真值上。因此，IEEE754标准中，规格化短浮点数的真值为：</p><script type="math/tex; mode=display">(-1)^{S}×1.M×2^{E-127}</script><p>规格化长浮点数的真值为：</p><script type="math/tex; mode=display">(-1)^{S}×1.M×2^{E-1023}</script><h6 id="4-定点、浮点表示的区别"><a href="#4-定点、浮点表示的区别" class="headerlink" title="(4) 定点、浮点表示的区别"></a>(4) 定点、浮点表示的区别</h6><p>若定点数与浮点数的字长相同，则浮点数所能表示的范围更大，但精度更低；</p><p>在定点运算中，当运算结果超出数的表示范围时，发生溢出；浮点运算中，运算结果超出尾数的表示范围却不一定溢出，只有当规格化后阶码超出所能表示的范围时，才发生溢出。</p><h6 id="5-浮点数的加减运算"><a href="#5-浮点数的加减运算" class="headerlink" title="(5) 浮点数的加减运算"></a>(5) 浮点数的加减运算</h6><p>浮点数加减运算的特点是阶码运算与尾数运算分开进行，浮点数运算分为以下几步：</p><ol><li><p>对阶</p><p>对阶的目的是使两个操作数的小数点位置对齐，即使得两个数的阶码相等。</p><p>为此，先求差，然后以小阶向大阶看齐的原则，将阶码小的尾数右移，每移一位阶加1，直到两个数的阶码相等为止。尾数右移时，舍弃掉有效位会产生误差，影响精度。</p></li><li><p>尾数求和</p><p>将对阶后的尾数按定点数加减法运算规则运算。尾数以原码表示，即进行原码加减法运算，或将原码转换为补码运算后，再将结果转换回原码。</p></li><li><p>规格化</p><p>运算后的尾数不一定是规格化的，需要进一步进行规格化处理。左规一次相当于乘2，右规一次相当于除以2，需要右规时，只需进行1次。</p></li><li><p>舍入</p><p>0舍1入法；</p><p>末位恒置1法；</p><p>截断法。</p></li><li><p>溢出判断</p><p><img src="/images/计组第2章-数据的表示和运算/image-20220708114926685.png" alt=""></p></li></ol><h6 id="6-C语言中的浮点数类型"><a href="#6-C语言中的浮点数类型" class="headerlink" title="(6) C语言中的浮点数类型"></a>(6) C语言中的浮点数类型</h6><p>C语言中的<code>float</code>和<code>double</code>类型分别对应于IEEE754单精度浮点数和双精度浮点数，<code>long double</code>类型对应于扩展双精度浮点数。在C程序中等式的赋值和判断中会出现强制类型转换，以<code>char-&gt;int-&gt;long-&gt;double</code>和<code>float-&gt;double</code>最为常见，从前到后范围和精度都从小到大，转换过程没有损失。</p><p><code>int</code>转换为<code>float</code>时，两者都是4个字节，不会发生溢出，但是由于<code>float</code>尾数连隐藏位一共24位，当<code>int</code>型数的第24~31位非0时，无法精确转换为24位浮点数的尾数，需要进行舍入处理，影响精度。</p><p><code>float</code>或<code>double</code>类型转换为<code>int</code>时，会直接截断，仅保留整数部分。另外<code>int</code>表示范围更小，有可能会溢出。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计组第1章-计算机系统概述</title>
      <link href="/2022/07/27/ji-zu-di-1-zhang-ji-suan-ji-xi-tong-gai-shu/"/>
      <url>/2022/07/27/ji-zu-di-1-zhang-ji-suan-ji-xi-tong-gai-shu/</url>
      
        <content type="html"><![CDATA[<h3 id="第一章-计算机系统概述"><a href="#第一章-计算机系统概述" class="headerlink" title="第一章 计算机系统概述"></a>第一章 计算机系统概述</h3><blockquote><p>计算机系统组成（硬件+软件）</p></blockquote><h4 id="冯诺依曼基本思想"><a href="#冯诺依曼基本思想" class="headerlink" title="冯诺依曼基本思想"></a>冯诺依曼基本思想</h4><p>1.采用\”<strong>存储程序</strong>\”的工作方式:将事先编制好的程序和原始数据送入主存后才能执行，一旦程序启动，就无需操作人员的干预，计算机会自动逐条执行指令，直至程序执行结束。</p><p>2.计算机硬件系统由<strong>运算器</strong>、<strong>存储器</strong>、<strong>控制器</strong>、<strong>输入设备</strong>和<strong>输出设备</strong>5大部件组成。</p><p>3.指令和数据以同等地位存储在存储器中，形式上没有区别（均为二进制数据），CPU区分它们的依据是<strong>指令周期的不同阶段</strong>。</p><p>4.指令和数据均用二进制代码表示。指令由<strong>操作码</strong>和<strong>地址码</strong>组成。</p><h4 id="计算机功能部件"><a href="#计算机功能部件" class="headerlink" title="计算机功能部件"></a>计算机功能部件</h4><p>1.输入设备：键盘，鼠标，扫描仪，摄像机等</p><p>2.输出设备：显示器，打印机</p><p>3.存储器：分为主存储器（内存）和辅助存储器（外存）。CPU能够直接访问的是主存储器。主存储器的工作方式是按存储单元的地址进行存取。 MAR位数为地址码长度，MDR位数为存储字长。</p><blockquote><p>存储体</p><p>地址寄存器MAR</p><p>数据寄存器MDR</p><p>时序控制逻辑</p></blockquote><p>4.运算器：分为算术运算和逻辑运算。（运算器和控制器集成到同一个芯片上，称为中央处理器CPU，CPU和主存构成主机，I/O设备和外存等统称为外设。）</p><blockquote><p>算术逻辑单元ALU</p><p>累加器ACC</p><p>乘商寄存器MQ</p><p>操作数寄存器X</p><p>程序状态寄存器PSW</p><p>通用寄存器</p></blockquote><p>5.控制器：计算机的指挥中心。</p><blockquote><p>程序计数器PC：存放当前欲执行指令的地址</p><p>指令寄存器IR：存放当前的指令</p><p>控制单元CU</p></blockquote><p><img src="/images/计组第1章-计算机系统概述/78B48B19BF429509004C6EC7AAF66760.png" alt="冯诺依曼机硬件组成" style="zoom:67%;"></p><h4 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h4><p>1.系统软件和应用软件</p><p>系统软件是一组保证计算机系统高效、正确运行的基础软件，通常作为系统资源提供给用户使用。</p><p>应用软件是指用户为解决某个应用领域中的各类问题而编制的程序。</p><p>2.三个级别的语言</p><p>机器语言：又称为二进制代码语言，需要编程人员记忆每条指令的二进制编码，是计算机唯一可以直接识别和执行的语言。</p><p>汇编语言：汇编语言用英文单词或其缩写代替二进制的指令代码，更容易为人们记忆和理解，汇编语言需要经过汇编程序翻译为机器语言后才能在计算机的硬件系统上执行。</p><p>高级语言：是为方便程序设计人员写出解决问题的处理方案和解题过程的程序，高级语言需要经过编译程序编译成汇编语言，再由汇编程序翻译成机器语言才能执行。</p><blockquote><p>软件和硬件具有逻辑功能等价性</p></blockquote><p><img src="/images/计组第1章-计算机系统概述/678A13280398138D415B9429E8ADA563.png" alt="计算机层次结构" style="zoom:67%;"></p><h4 id="计算机工作原理"><a href="#计算机工作原理" class="headerlink" title="计算机工作原理"></a>计算机工作原理</h4><p>1.\”存储程序\”的工作方式</p><blockquote><p>程序执行前将程序所含的指令和数据送入主存，程序执行后自动逐条完成指令的取出和执行任务，无需操作人员干预。</p></blockquote><p>2.从源程序到可执行文件</p><p>3.程序执行过程</p><blockquote><p>程序执行过程就是数据在CPU、主存储器和I/O设备之间流动的过程，所有数据的流动都是通过总线、I/O接口等进行的。</p></blockquote><p>4.指令执行过程</p><blockquote><p>根据PC取指令、对指令进行译码、计算下条指令地址、取操作数并执行、将结果送回存储器。</p></blockquote><h4 id="计算机性能指标"><a href="#计算机性能指标" class="headerlink" title="计算机性能指标"></a>计算机性能指标</h4><p><strong>字长</strong>：指计算机进行一次定点整数运算所能处理的二进制数据的位数，通常与CPU的寄存器位数和加法器保持一致。</p><p><strong>数据通路带宽</strong>：指数据总线一次所能并行传送信息的位数。</p><p><strong>主存容量</strong>：主存储器所能存储信息的最大容量。MAR的位数反映存储单元的个数，MDR的位数反映可寻址范围的最大值。</p><p><strong>运算速度</strong></p><blockquote><p>吞吐量和响应时间：吞吐量指系统在单位时间内处理请求的数量。</p><p><strong>主频和CPU时钟周期</strong>：CPU时钟周期是CPU中最小的时间单位，执行指令的最小动作至少需要一个时钟周期。主频是CPU时钟周期的倒数，单位为Hz，指CPU内核工作的时钟频率，即CPU内数字脉冲信号的振荡频率。f=1/T，主频=外频×倍频。</p><p><strong>CPI</strong>：即执行一条指令所需的时钟周期数，一般计算的是平均CPI：</p><p>​          CPI=∑(程序中各类指令的CPI×程序中该类指令的比例)。</p><p>IPC(Instruction per Clock):每个时钟周期内执行的指令条数（并行）。</p><p>CPU执行时间=CPU时钟周期数/主频=(指令条数×CPI)/主频，故CPU的性能取决于3个要素：主频、CPI、指令条数。</p><p>MIPS：即每秒钟执行多少百万条指令。 MIPS=指令条数/(执行时间×10⁶)=主频/(CPI×10⁶)</p><p>MFLOPS：即每秒钟执行多少百万次浮点运算。</p></blockquote><p><img src="/images/计组第1章-计算机系统概述/image-20220706092517384.png" alt="全性能公式" style="zoom: 67%;"></p><h4 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h4><p>计算机系统硬件组成</p><p><img src="/images/计组第1章-计算机系统概述/计算机硬件组成.jpg" alt="计算机硬件组成" style="zoom:67%;"></p><p>存储器层次结构（<strong>寄存器&gt;cache&gt;主存</strong>）</p><p><img src="/images/计组第1章-计算机系统概述/存储器层次结构.jpg" alt="存储器层次结构" style="zoom:67%;"></p><p>Amdahl定律</p><p><img src="/images/计组第1章-计算机系统概述/Amdahl定律.jpg" alt="Amdahl定律" style="zoom: 67%;"></p><p>易混淆知识点</p><blockquote><p>在CPU中，IR、MAR、和MDR对各类程序员都是透明不可见的。</p><p>bit：位或比特，一个二进制位即为一个比特，只能容纳一个0或者一个1。</p><p>Byte：字节，1Byte = 8bits。</p><p>字（word）与字长：字是指在计算机中作为一个整体被存取、传输、处理的一组二进制数据。一个字的位数即称为字长，32位计算机：1字=32位=4字节；64位计算机：1字=64位=8字节。</p><p>机器字长：CPU能一次处理（进行一次定点整数运算）的二进制数据的最大位数。</p><p>存储字长：指一个存储单元可容纳的二进制代码的位数，即存储器中MDR的位数。</p><p>指令字长：一个指令字中包含的二进制代码的位数。</p><p>各种字长都可变，但必须是字节的整数倍。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机组成原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>赤壁赋</title>
      <link href="/2022/03/19/chi-bi-fu/"/>
      <url>/2022/03/19/chi-bi-fu/</url>
      
        <content type="html"><![CDATA[<h3 id="赤壁赋"><a href="#赤壁赋" class="headerlink" title="赤壁赋"></a><a href="https://so.gushiwen.cn/shiwenv_4cac23b07849.aspx">赤壁赋</a></h3><p><a href="https://so.gushiwen.cn/authorv.aspx?name=苏轼">苏轼 </a><a href="https://so.gushiwen.cn/shiwens/default.aspx?cstr=宋代">〔宋代〕</a></p><p>　　壬戌之秋，七月既望，苏子与客泛舟游于赤壁之下。清风徐来，水波不兴。举酒属客，诵明月之诗，歌窈窕之章。少焉，月出于东山之上，徘徊于斗牛之间。白露横江，水光接天。纵一苇之所如，凌万顷之茫然。浩浩乎如冯虚御风，而不知其所止；飘飘乎如遗世独立，羽化而登仙。</p><p>　　于是饮酒乐甚，扣舷而歌之。歌曰：“桂棹兮兰桨，击空明兮溯流光。渺渺兮予怀，望美人兮天一方。”客有吹洞箫者，倚歌而和之。其声呜呜然，如怨如慕，如泣如诉；余音袅袅，不绝如缕。舞幽壑之潜蛟，泣孤舟之嫠妇。</p><p>　　苏子愀然，正襟危坐，而问客曰：“何为其然也？”客曰：“‘月明星稀，乌鹊南飞。’此非曹孟德之诗乎？西望夏口，东望武昌，山川相缪，郁乎苍苍，此非孟德之困于周郎者乎？方其破荆州，下江陵，顺流而东也，舳舻千里，旌旗蔽空，酾酒临江，横槊赋诗，固一世之雄也，而今安在哉？况吾与子渔樵于江渚之上，侣鱼虾而友麋鹿，驾一叶之扁舟，举匏樽以相属。寄蜉蝣于天地，渺沧海之一粟。哀吾生之须臾，羡长江之无穷。挟飞仙以遨游，抱明月而长终。知不可乎骤得，托遗响于悲风。”</p><p>　　苏子曰：“客亦知夫水与月乎？逝者如斯，而未尝往也；盈虚者如彼，而卒莫消长也。盖将自其变者而观之，则天地曾不能以一瞬；自其不变者而观之，则物与我皆无尽也，而又何羡乎！且夫天地之间，物各有主，苟非吾之所有，虽一毫而莫取。惟江上之清风，与山间之明月，耳得之而为声，目遇之而成色，取之无禁，用之不竭。是造物者之无尽藏也，而吾与子之所共适。”</p><p>　　客喜而笑，洗盏更酌。肴核既尽，杯盘狼籍。相与枕藉乎舟中，不知东方之既白。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 诗文 </tag>
            
            <tag> 赤壁赋 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>洛神赋</title>
      <link href="/2022/03/19/luo-shen-fu/"/>
      <url>/2022/03/19/luo-shen-fu/</url>
      
        <content type="html"><![CDATA[<h3 id="洛神赋"><a href="#洛神赋" class="headerlink" title="洛神赋"></a>洛神赋</h3><p><a href="https://so.gushiwen.cn/authorv_6c695909f577.aspx">曹植</a> <a href="https://so.gushiwen.cn/shiwens/default.aspx?cstr=两汉">〔两汉〕</a></p><p>　　黄初三年，余朝京师，还济洛川。古人有言：斯水之神，名曰宓妃。感宋玉对楚王神女之事，遂作斯赋。其词曰：</p><p>　　余从京域，言归东藩，背伊阙，越轘辕，经通谷，陵景山。日既西倾，车殆马烦。尔乃税驾乎蘅皋，秣驷乎芝田，容与乎阳林，流眄乎洛川。于是精移神骇，忽焉思散。俯则未察，仰以殊观。睹一丽人，于岩之畔。乃援御者而告之曰：“尔有觌于彼者乎？彼何人斯，若此之艳也！”御者对曰：“臣闻河洛之神，名曰宓妃。然则君王之所见，无乃是乎！其状若何？臣愿闻之。”</p><p>　　余告之曰：其形也，翩若惊鸿，婉若游龙。荣曜秋菊，华茂春松。髣髴兮若轻云之蔽月，飘飖兮若流风之回雪。远而望之，皎若太阳升朝霞；迫而察之，灼若芙蕖出渌波。秾纤得衷，修短合度。肩若削成，腰如约素。延颈秀项，皓质呈露。芳泽无加，铅华弗御。云髻峨峨，修眉联娟。丹唇外朗，皓齿内鲜。明眸善睐，靥辅承权。瓌姿艳逸，仪静体闲。柔情绰态，媚于语言。奇服旷世，骨像应图。披罗衣之璀粲兮，珥瑶碧之华琚。戴金翠之首饰，缀明珠以耀躯。践远游之文履，曳雾绡之轻裾。微幽兰之芳蔼兮，步踟蹰于山隅。于是忽焉纵体，以遨以嬉。左倚采旄，右荫桂旗。攘皓腕于神浒兮，采湍濑之玄芝。</p><p>　　余情悦其淑美兮，心振荡而不怡。无良媒以接欢兮，托微波而通辞。愿诚素之先达兮，解玉佩以要之。嗟佳人之信修兮，羌习礼而明诗。抗琼珶以和予兮，指潜渊而为期。执眷眷之款实兮，惧斯灵之我欺。感交甫之弃言兮，怅犹豫而狐疑。收和颜而静志兮，申礼防以自持。</p><p>　　于是洛灵感焉，徙倚彷徨。神光离合，乍阴乍阳。竦轻躯以鹤立，若将飞而未翔。践椒途之郁烈，步蘅薄而流芳。超长吟以永慕兮，声哀厉而弥长。尔乃众灵杂沓，命俦啸侣。或戏清流，或翔神渚，或采明珠，或拾翠羽。从南湘之二妃，携汉滨之游女。叹匏瓜之无匹兮，咏牵牛之独处。扬轻袿之猗靡兮，翳修袖以延伫。体迅飞凫，飘忽若神。凌波微步，罗袜生尘。动无常则，若危若安；进止难期，若往若还。转眄流精，光润玉颜。含辞未吐，气若幽兰。华容婀娜，令我忘餐。</p><p>　　于是屏翳收风，川后静波。冯夷鸣鼓，女娲清歌。腾文鱼以警乘，鸣玉銮以偕逝。六龙俨其齐首，载云车之容裔。鲸鲵踊而夹毂，水禽翔而为卫。于是越北沚，过南冈，纡素领，回清扬。动朱唇以徐言，陈交接之大纲。恨人神之道殊兮，怨盛年之莫当。抗罗袂以掩涕兮，泪流襟之浪浪。悼良会之永绝兮，哀一逝而异乡。无微情以效爱兮，献江南之明珰。虽潜处于太阴，长寄心于君王。忽不悟其所舍，怅神宵而蔽光。</p><p>　　于是背下陵高，足往神留。遗情想像，顾望怀愁。冀灵体之复形，御轻舟而上溯。浮长川而忘反，思绵绵而增慕。夜耿耿而不寐，沾繁霜而至曙。命仆夫而就驾，吾将归乎东路。揽騑辔以抗策，怅盘桓而不能去。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 诗文 </tag>
            
            <tag> 洛神赋 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>春江花月夜</title>
      <link href="/2022/03/19/chun-jiang-hua-yue-ye/"/>
      <url>/2022/03/19/chun-jiang-hua-yue-ye/</url>
      
        <content type="html"><![CDATA[<h3 id="春江花月夜"><a href="#春江花月夜" class="headerlink" title="春江花月夜"></a>春江花月夜</h3><p><a href="https://so.gushiwen.cn/authorv_787d4a1969b8.aspx">张若虚</a> <a href="https://so.gushiwen.cn/shiwens/default.aspx?cstr=唐代">〔唐代〕</a></p><p>春江潮水连海平，海上明月共潮生。<br>滟滟随波千万里，何处春江无月明！<br>江流宛转绕芳甸，月照花林皆似霰。<br>空里流霜不觉飞，汀上白沙看不见。<br>江天一色无纤尘，皎皎空中孤月轮。<br>江畔何人初见月？江月何年初照人？<br>人生代代无穷已，江月年年望相似。<br>不知江月待何人，但见长江送流水。<br>白云一片去悠悠，青枫浦上不胜愁。<br>谁家今夜扁舟子？何处相思明月楼？<br>可怜楼上月徘徊，应照离人妆镜台。<br>玉户帘中卷不去，捣衣砧上拂还来。<br>此时相望不相闻，愿逐月华流照君。<br>鸿雁长飞光不度，鱼龙潜跃水成文。<br>昨夜闲潭梦落花，可怜春半不还家。<br>江水流春去欲尽，江潭落月复西斜。<br>斜月沉沉藏海雾，碣石潇湘无限路。<br>不知乘月几人归，落月摇情满江树。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 诗文 </tag>
            
            <tag> 春江花月夜 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>出师表</title>
      <link href="/2022/03/19/chu-shi-biao/"/>
      <url>/2022/03/19/chu-shi-biao/</url>
      
        <content type="html"><![CDATA[<h3 id="出师表"><a href="#出师表" class="headerlink" title="出师表"></a>出师表</h3><p><a href="https://so.gushiwen.cn/authorv_e82a672a1ca9.aspx">诸葛亮</a> <a href="https://so.gushiwen.cn/shiwens/default.aspx?cstr=两汉">〔两汉〕</a></p><p>　　先帝创业未半而中道崩殂，今天下三分，益州疲弊，此诚危急存亡之秋也。然侍卫之臣不懈于内，忠志之士忘身于外者，盖追先帝之殊遇，欲报之于陛下也。诚宜开张圣听，以光先帝遗德，恢弘志士之气，不宜妄自菲薄，引喻失义，以塞忠谏之路也。</p><p>　　宫中府中，俱为一体；陟罚臧否，不宜异同。若有作奸犯科及为忠善者，宜付有司论其刑赏，以昭陛下平明之理，不宜偏私，使内外异法也。</p><p>　　侍中、侍郎郭攸之、费祎、董允等，此皆良实，志虑忠纯，是以先帝简拔以遗陛下。愚以为宫中之事，事无大小，悉以咨之，然后施行，必能裨补阙漏，有所广益。</p><p>　　将军向宠，性行淑均，晓畅军事，试用于昔日，先帝称之曰能，是以众议举宠为督。愚以为营中之事，悉以咨之，必能使行阵和睦，优劣得所。</p><p>　　亲贤臣，远小人，此先汉所以兴隆也；亲小人，远贤臣，此后汉所以倾颓也。先帝在时，每与臣论此事，未尝不叹息痛恨于桓、灵也。侍中、尚书、长史、参军，此悉贞良死节之臣，愿陛下亲之信之，则汉室之隆，可计日而待也。</p><p>　　臣本布衣，躬耕于南阳，苟全性命于乱世，不求闻达于诸侯。先帝不以臣卑鄙，猥自枉屈，三顾臣于草庐之中，咨臣以当世之事，由是感激，遂许先帝以驱驰。后值倾覆，受任于败军之际，奉命于危难之间，尔来二十有一年矣。</p><p>　　先帝知臣谨慎，故临崩寄臣以大事也。受命以来，夙夜忧叹，恐托付不效，以伤先帝之明；故五月渡泸，深入不毛。今南方已定，兵甲已足，当奖率三军，北定中原，庶竭驽钝，攘除奸凶，兴复汉室，还于旧都。此臣所以报先帝而忠陛下之职分也。至于斟酌损益，进尽忠言，则攸之、祎、允之任也。</p><p>　　愿陛下托臣以讨贼兴复之效，不效，则治臣之罪，以告先帝之灵。若无兴德之言，则责攸之、祎、允等之慢，以彰其咎；陛下亦宜自谋，以咨诹善道，察纳雅言，深追先帝遗诏。臣不胜受恩感激。今当远离，临表涕零，不知所言。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 出师表 </tag>
            
            <tag> 诗文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>陈情表</title>
      <link href="/2022/03/19/chen-qing-biao/"/>
      <url>/2022/03/19/chen-qing-biao/</url>
      
        <content type="html"><![CDATA[<h3 id="陈情表"><a href="#陈情表" class="headerlink" title="陈情表"></a>陈情表</h3><p><a href="https://so.gushiwen.cn/authorv_a0cdb7e44d9a.aspx">西晋·李密</a> <a href="https://so.gushiwen.cn/shiwens/default.aspx?cstr=魏晋">〔魏晋〕</a></p><p>　　臣密言：臣以险衅，夙遭闵凶。生孩六月，慈父见背；行年四岁，舅夺母志。祖母刘愍臣孤弱，躬亲抚养。臣少多疾病，九岁不行，零丁孤苦，至于成立。既无伯叔，终鲜兄弟，门衰祚薄，晚有儿息。外无期功强近之亲，内无应门五尺之僮，茕茕孑立，形影相吊。而刘夙婴疾病，常在床蓐，臣侍汤药，未曾废离。</p><p>　　逮奉圣朝，沐浴清化。前太守臣逵察臣孝廉；后刺史臣荣举臣秀才。臣以供养无主，辞不赴命。诏书特下，拜臣郎中，寻蒙国恩，除臣洗马。猥以微贱，当侍东宫，非臣陨首所能上报。臣具以表闻，辞不就职。诏书切峻，责臣逋慢；郡县逼迫，催臣上道；州司临门，急于星火。臣欲奉诏奔驰，则刘病日笃，欲苟顺私情，则告诉不许：臣之进退，实为狼狈。</p><p>　　伏惟圣朝以孝治天下，凡在故老，犹蒙矜育，况臣孤苦，特为尤甚。且臣少仕伪朝，历职郎署，本图宦达，不矜名节。今臣亡国贱俘，至微至陋，过蒙拔擢，宠命优渥，岂敢盘桓，有所希冀！但以刘日薄西山，气息奄奄，人命危浅，朝不虑夕。臣无祖母，无以至今日，祖母无臣，无以终余年。母孙二人，更相为命，是以区区不能废远。</p><p>　　臣密今年四十有四，祖母今年九十有六，是臣尽节于陛下之日长，报养刘之日短也。乌鸟私情，愿乞终养。臣之辛苦，非独蜀之人士及二州牧伯所见明知，皇天后土实所共鉴。愿陛下矜愍愚诚，听臣微志，庶刘侥幸，保卒余年。臣生当陨首，死当结草。臣不胜犬马怖惧之情，谨拜表以闻。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 诗文 </tag>
            
            <tag> 陈情表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>滕王阁序</title>
      <link href="/2022/03/19/teng-wang-ge-xu/"/>
      <url>/2022/03/19/teng-wang-ge-xu/</url>
      
        <content type="html"><![CDATA[<p><strong>滕王阁序</strong></p><p><a href="https://so.gushiwen.cn/authorv_e6b970da08cd.aspx">王勃</a> <a href="https://so.gushiwen.cn/shiwens/default.aspx?cstr=唐代">〔唐代〕</a></p><p>　　豫章故郡，洪都新府。星分翼轸，地接衡庐。襟三江而带五湖，控蛮荆而引瓯越。物华天宝，龙光射牛斗之墟；人杰地灵，徐孺下陈蕃之榻。雄州雾列，俊采星驰。台隍枕夷夏之交，宾主尽东南之美。都督阎公之雅望，棨戟遥临；宇文新州之懿范，襜帷暂驻。十旬休假，胜友如云；千里逢迎，高朋满座。腾蛟起凤，孟学士之词宗；紫电青霜，王将军之武库。家君作宰，路出名区；童子何知，躬逢胜饯。</p><p>　　时维九月，序属三秋。潦水尽而寒潭清，烟光凝而暮山紫。俨骖騑于上路，访风景于崇阿。临帝子之长洲，得天人之旧馆。层峦耸翠，上出重霄；飞阁流丹，下临无地。鹤汀凫渚，穷岛屿之萦回；桂殿兰宫，即冈峦之体势。</p><p>　　披绣闼，俯雕甍，山原旷其盈视，川泽纡其骇瞩。闾阎扑地，钟鸣鼎食之家；舸舰弥津，青雀黄龙之舳。云销雨霁，彩彻区明。落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨，雁阵惊寒，声断衡阳之浦。</p><p>　　遥襟甫畅，逸兴遄飞。爽籁发而清风生，纤歌凝而白云遏。睢园绿竹，气凌彭泽之樽；邺水朱华，光照临川之笔。四美具，二难并。穷睇眄于中天，极娱游于暇日。天高地迥，觉宇宙之无穷；兴尽悲来，识盈虚之有数。望长安于日下，目吴会于云间。地势极而南溟深，天柱高而北辰远。关山难越，谁悲失路之人；萍水相逢，尽是他乡之客。怀帝阍而不见，奉宣室以何年？</p><p>　　嗟乎！时运不齐，命途多舛。冯唐易老，李广难封。屈贾谊于长沙，非无圣主；窜梁鸿于海曲，岂乏明时？所赖君子见机，达人知命。老当益壮，宁移白首之心？穷且益坚，不坠青云之志。酌贪泉而觉爽，处涸辙以犹欢。北海虽赊，扶摇可接；东隅已逝，桑榆非晚。孟尝高洁，空余报国之情；阮籍猖狂，岂效穷途之哭！</p><p>　　勃，三尺微命，一介书生。无路请缨，等终军之弱冠；有怀投笔，慕宗悫之长风。舍簪笏于百龄，奉晨昏于万里。非谢家之宝树，接孟氏之芳邻。他日趋庭，叨陪鲤对；今兹捧袂，喜托龙门。杨意不逢，抚凌云而自惜；钟期既遇，奏流水以何惭？</p><p>　　呜呼！胜地不常，盛筵难再；兰亭已矣，梓泽丘墟。临别赠言，幸承恩于伟饯；登高作赋，是所望于群公。敢竭鄙怀，恭疏短引；一言均赋，四韵俱成。请洒潘江，各倾陆海云尔。<br>　　滕王高阁临江渚，佩玉鸣鸾罢歌舞。<br>　　画栋朝飞南浦云，珠帘暮卷西山雨。<br>　　闲云潭影日悠悠，物换星移几度秋。<br>　　阁中帝子今何在？槛外长江空自流。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 诗文 </tag>
            
            <tag> 滕王阁序 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
